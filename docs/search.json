[
  {
    "objectID": "zusatzmaterial/pcm_beispiel/pcm_beispiel.html",
    "href": "zusatzmaterial/pcm_beispiel/pcm_beispiel.html",
    "title": "Beispielrechnung PCM",
    "section": "",
    "text": "In der Vorlesung begegnet Ihnen eine Beispielrechnung zu den Kategorienwahrscheinlichkeiten im Partial Credit Model. Es soll berechnet werden, wie wahrscheinlich es ist, dass eine Person mit einer Fähigkeit von \\(\\theta_i = 0.5\\) in der Antwortkategorie \\(c = 2\\) einer 4-stufigen Ratingskala antwortet. Die Schwellenparameter \\(\\delta_{j1} = -1\\), \\(\\delta_{j2} = 0\\), und \\(\\delta_{j3} = 1\\) sind vorgegeben.\n\n\nAls erstes lohnt es sich zu verstehen, wie die Bezeichnungen der Antwortkategorien und Schwellenparameter gemeint sind. Dafür hilft es die Ratingskala zu skizzieren:\n\nUnter den Kästchen (Antwortkategorien) steht die Bezeichnung der Antwortkategorien. Üblicherweise zählen wir im PCM beginnend mit der \\(0\\). Eine Antwort in der \\(c=2^{\\text{ten}}\\) Kategorie entspricht also eigentlich einer Antwort in der dritthöchsten Kategorie. An dieser Stelle wurde in der Abbildung symbolisch ein Kreuz gesetzt.\nDie Schwellenparameter entsprechen den Schwierigkeiten eines “Sprungs” von einer Kategorie in die nächsthöchte. Der Schwellenparameter \\(\\delta_{j1}\\) wird für den “Sprung” von Kategorie \\(0\\) zu Kategorie \\(1\\) verwendet. Dort finden Sie ihn auch in der Abbildung. Entsprechend wurden auch die Schwellenparameter \\(\\delta_{j2}\\) und \\(\\delta_{j3}\\) eingefügt.\n\n\n\nOben ist bereits beschrieben, dass die Parameter \\(\\theta_i = 0.5\\), \\(\\delta_{j1} = -1\\), \\(\\delta_{j2} = 0\\), \\(\\delta_{j3} = 1\\), und \\(c = 2\\) gegeben sind. Aus der Abbildung der Ratingskala können wir zusätzlich ablesen, dass auch die höchste Antwortkategorie, also \\(m_j = 3\\) gegeben ist.\n\n\n\nGesucht ist die Wahrscheinlichkeit\n\\(P(u_{ij} = 2 | \\theta_i, \\delta_{j1}, \\delta_{j2}, \\delta_{j3})\\)\n\\(= \\frac{exp(\\sum_{k = 0}^{c} (\\theta_i - \\delta_{jk}))}{\\sum_{l = 0}^{m_j} exp(\\sum_{k = 0}^{l} (\\theta_i - \\delta_{jk}))}\\)\nDer Bruch wirkt eventuell zuerst erschlagend. Als kleinen ersten Schritt können wir die gegebenen Werte \\(c = 2\\) und \\(m_j = 3\\) einsetzen:\n\\(= \\frac{exp(\\sum_{k = 0}^{\\textcolor{red}{2}} (\\theta_i - \\delta_{jk}))}{\\sum_{l = 0}^{\\textcolor{red}{3}} exp(\\sum_{k = 0}^{l} (\\theta_i - \\delta_{jk}))}\\)\nAls nächstes ist es hilreich festzustellen, dass sich im Zähler, wie auch im Nenner, die Summe über Differenzen \\(\\theta_i - \\delta_{jk}\\) wiederholt. Ich markiere diese Summe im Folgenden rot:\n\\(= \\frac{exp(\\textcolor{red}{\\sum_{k = 0}^{2} (\\theta_i - \\delta_{jk})})}{\\sum_{l = 0}^{3} exp(\\textcolor{red}{\\sum_{k = 0}^{l} (\\theta_i - \\delta_{jk})})}\\)\nDie rot markierte Summe müssen Sie bei der Berechnung des PCM oft verwenden. Daher lohnt es sich, die Berechnung abzukürzen.\n\n\n\nAls Zwischenschritt nehme ich die oben rot markierte Summe heraus. Insbesondere wähle ich den schwierigsten Fall, nämlich den, in dem Sie die Summe bis \\(m_j = 3\\) berechnen müssen:\n\\(\\sum_{k = 0}^{3} (\\theta_i - \\delta_{jk})\\)\nAuflösen des Summenzeichens ergibt:\n\\(= (\\theta_i - \\delta_{j0}) + (\\theta_i - \\delta_{j1}) + (\\theta_i - \\delta_{j2}) + (\\theta_i - \\delta_{j3})\\)\nDie erste Differenz mit \\(\\delta_{j0}\\) können wir gleich wieder streichen, denn diese ist als \\(0\\) definiert.\n\\(=(\\theta_i - \\delta_{j1}) + (\\theta_i - \\delta_{j2}) + (\\theta_i - \\delta_{j3})\\)\nDa das Assoziativ- und Kommutativgesetz gelten, dürfen wir die Klammern auflösen und neu sortieren:\n\\(= 3 \\cdot \\theta_i - \\delta_{j1} - \\delta_{j2} - \\delta_{j3}\\)\nStatt das Summenzeichen aufwendig für jeden Wert von \\(k\\) aufzulösen, können Sie also gleich \\(\\theta_i\\) mit \\(3\\) multiplizieren und den ersten bis dritten Schwellenparameter abziehen. Das geht viel schneller und funktioniert im PCM bei Summen der Form \\(\\sum_{k = 0}^{l} (\\theta_i - \\delta_{jk})\\) immer dann, wenn als obere Grenze im Summenzeichen eine Zahl \\(\\ge 1\\) steht.\n\nLösen Sie auf:\n\\(\\sum_{k = 0}^{2} (\\theta_i - \\delta_{jk})\\)\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(\\sum_{k = 0}^{2} (\\theta_i - \\delta_{jk}) = 2 \\cdot \\theta_i - \\delta_{j1} - \\delta_{j2}\\)\n\n\n\nAufpassen muss man nur im Sonderfall, der als \\(0\\) definiert ist:\n\\(\\sum_{k = 0}^{0} (\\theta_i - \\delta_{jk}) := 0\\)\n\n\n\nMit diesem Wissen können wir zur Berechnung der gesamten Kategorienwahrscheinlichkeit zurückkehren:\n\\(P(u_{ij} = 2 | \\theta_i, \\delta_{j1}, \\delta_{j2}, \\delta_{j3})\\)\n\\(= \\frac{exp(\\sum_{k = 0}^{2} (\\theta_i - \\delta_{jk}))}{\\sum_{l = 0}^{3} exp(\\sum_{k = 0}^{l} (\\theta_i - \\delta_{jk}))}\\)\nDer Zähler lässt sich mit dem eben gezeigten Trick schnell berechnen:\n\\(= \\frac{exp(2 \\cdot \\theta_i - \\delta_{j1} - \\delta_{j2})}{\\sum_{l = 0}^{3} exp(\\sum_{k = 0}^{l} (\\theta_i - \\delta_{jk}))}\\)\nIm Nenner müssen Sie den Trick mehrfach anwenden, nämlich einmal für jedes \\(l\\) zwischen \\(0\\) und \\(3\\):\n\\(= \\frac{exp(2 \\cdot \\theta_i - \\delta_{j1} - \\delta_{j2})}{\n    exp(0) +\n    exp(1\\cdot \\theta_i - \\delta_{j1}) +\n    exp(2\\cdot \\theta_i - \\delta_{j1}- \\delta_{j2}) +\n    exp(3\\cdot \\theta_i - \\delta_{j1}- \\delta_{j2}- \\delta_{j3})\n}\\)\nNun kann man schon Werte einsetzen:\n\\(= \\frac{exp(2 \\cdot 0.5 - (-1) - 0)}{\n    exp(0) +\n    exp(1\\cdot 0.5 - (-1)) +\n    exp(2\\cdot 0.5 - (-1) - 0) +\n    exp(3\\cdot 0.5 - (-1) - 0 - 1)\n}\\)\nSchrittweises Ausrechnen ergibt:\n\\(= \\frac{7.39}{\n    1 +\n    4.48 +\n    7.39 +\n    4.48\n} \\approx 0.43\\)\nDie modellimplizierte Wahrscheinlichkeit im PCM, dass eine Person mit \\(\\theta_i = 0.5\\) bei einem Item mit \\(\\delta_{j1} = -1\\), \\(\\delta_{j2} = 0\\), und \\(\\delta_{j3} = 1\\) in Kategorie \\(c = 2\\) antwortet ist also \\(0.43\\)."
  },
  {
    "objectID": "zusatzmaterial/pcm_beispiel/pcm_beispiel.html#interpretation-der-parameter",
    "href": "zusatzmaterial/pcm_beispiel/pcm_beispiel.html#interpretation-der-parameter",
    "title": "Beispielrechnung PCM",
    "section": "",
    "text": "Als erstes lohnt es sich zu verstehen, wie die Bezeichnungen der Antwortkategorien und Schwellenparameter gemeint sind. Dafür hilft es die Ratingskala zu skizzieren:\n\nUnter den Kästchen (Antwortkategorien) steht die Bezeichnung der Antwortkategorien. Üblicherweise zählen wir im PCM beginnend mit der \\(0\\). Eine Antwort in der \\(c=2^{\\text{ten}}\\) Kategorie entspricht also eigentlich einer Antwort in der dritthöchsten Kategorie. An dieser Stelle wurde in der Abbildung symbolisch ein Kreuz gesetzt.\nDie Schwellenparameter entsprechen den Schwierigkeiten eines “Sprungs” von einer Kategorie in die nächsthöchte. Der Schwellenparameter \\(\\delta_{j1}\\) wird für den “Sprung” von Kategorie \\(0\\) zu Kategorie \\(1\\) verwendet. Dort finden Sie ihn auch in der Abbildung. Entsprechend wurden auch die Schwellenparameter \\(\\delta_{j2}\\) und \\(\\delta_{j3}\\) eingefügt."
  },
  {
    "objectID": "zusatzmaterial/pcm_beispiel/pcm_beispiel.html#gegebene-werte",
    "href": "zusatzmaterial/pcm_beispiel/pcm_beispiel.html#gegebene-werte",
    "title": "Beispielrechnung PCM",
    "section": "",
    "text": "Oben ist bereits beschrieben, dass die Parameter \\(\\theta_i = 0.5\\), \\(\\delta_{j1} = -1\\), \\(\\delta_{j2} = 0\\), \\(\\delta_{j3} = 1\\), und \\(c = 2\\) gegeben sind. Aus der Abbildung der Ratingskala können wir zusätzlich ablesen, dass auch die höchste Antwortkategorie, also \\(m_j = 3\\) gegeben ist."
  },
  {
    "objectID": "zusatzmaterial/pcm_beispiel/pcm_beispiel.html#gesuchte-kategorienwahrscheinlichkeit",
    "href": "zusatzmaterial/pcm_beispiel/pcm_beispiel.html#gesuchte-kategorienwahrscheinlichkeit",
    "title": "Beispielrechnung PCM",
    "section": "",
    "text": "Gesucht ist die Wahrscheinlichkeit\n\\(P(u_{ij} = 2 | \\theta_i, \\delta_{j1}, \\delta_{j2}, \\delta_{j3})\\)\n\\(= \\frac{exp(\\sum_{k = 0}^{c} (\\theta_i - \\delta_{jk}))}{\\sum_{l = 0}^{m_j} exp(\\sum_{k = 0}^{l} (\\theta_i - \\delta_{jk}))}\\)\nDer Bruch wirkt eventuell zuerst erschlagend. Als kleinen ersten Schritt können wir die gegebenen Werte \\(c = 2\\) und \\(m_j = 3\\) einsetzen:\n\\(= \\frac{exp(\\sum_{k = 0}^{\\textcolor{red}{2}} (\\theta_i - \\delta_{jk}))}{\\sum_{l = 0}^{\\textcolor{red}{3}} exp(\\sum_{k = 0}^{l} (\\theta_i - \\delta_{jk}))}\\)\nAls nächstes ist es hilreich festzustellen, dass sich im Zähler, wie auch im Nenner, die Summe über Differenzen \\(\\theta_i - \\delta_{jk}\\) wiederholt. Ich markiere diese Summe im Folgenden rot:\n\\(= \\frac{exp(\\textcolor{red}{\\sum_{k = 0}^{2} (\\theta_i - \\delta_{jk})})}{\\sum_{l = 0}^{3} exp(\\textcolor{red}{\\sum_{k = 0}^{l} (\\theta_i - \\delta_{jk})})}\\)\nDie rot markierte Summe müssen Sie bei der Berechnung des PCM oft verwenden. Daher lohnt es sich, die Berechnung abzukürzen."
  },
  {
    "objectID": "zusatzmaterial/pcm_beispiel/pcm_beispiel.html#berechnung-der-farblich-markierten-summe",
    "href": "zusatzmaterial/pcm_beispiel/pcm_beispiel.html#berechnung-der-farblich-markierten-summe",
    "title": "Beispielrechnung PCM",
    "section": "",
    "text": "Als Zwischenschritt nehme ich die oben rot markierte Summe heraus. Insbesondere wähle ich den schwierigsten Fall, nämlich den, in dem Sie die Summe bis \\(m_j = 3\\) berechnen müssen:\n\\(\\sum_{k = 0}^{3} (\\theta_i - \\delta_{jk})\\)\nAuflösen des Summenzeichens ergibt:\n\\(= (\\theta_i - \\delta_{j0}) + (\\theta_i - \\delta_{j1}) + (\\theta_i - \\delta_{j2}) + (\\theta_i - \\delta_{j3})\\)\nDie erste Differenz mit \\(\\delta_{j0}\\) können wir gleich wieder streichen, denn diese ist als \\(0\\) definiert.\n\\(=(\\theta_i - \\delta_{j1}) + (\\theta_i - \\delta_{j2}) + (\\theta_i - \\delta_{j3})\\)\nDa das Assoziativ- und Kommutativgesetz gelten, dürfen wir die Klammern auflösen und neu sortieren:\n\\(= 3 \\cdot \\theta_i - \\delta_{j1} - \\delta_{j2} - \\delta_{j3}\\)\nStatt das Summenzeichen aufwendig für jeden Wert von \\(k\\) aufzulösen, können Sie also gleich \\(\\theta_i\\) mit \\(3\\) multiplizieren und den ersten bis dritten Schwellenparameter abziehen. Das geht viel schneller und funktioniert im PCM bei Summen der Form \\(\\sum_{k = 0}^{l} (\\theta_i - \\delta_{jk})\\) immer dann, wenn als obere Grenze im Summenzeichen eine Zahl \\(\\ge 1\\) steht.\n\nLösen Sie auf:\n\\(\\sum_{k = 0}^{2} (\\theta_i - \\delta_{jk})\\)\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(\\sum_{k = 0}^{2} (\\theta_i - \\delta_{jk}) = 2 \\cdot \\theta_i - \\delta_{j1} - \\delta_{j2}\\)\n\n\n\nAufpassen muss man nur im Sonderfall, der als \\(0\\) definiert ist:\n\\(\\sum_{k = 0}^{0} (\\theta_i - \\delta_{jk}) := 0\\)"
  },
  {
    "objectID": "zusatzmaterial/pcm_beispiel/pcm_beispiel.html#berechnung-der-kategorienwahrscheinlichkeit",
    "href": "zusatzmaterial/pcm_beispiel/pcm_beispiel.html#berechnung-der-kategorienwahrscheinlichkeit",
    "title": "Beispielrechnung PCM",
    "section": "",
    "text": "Mit diesem Wissen können wir zur Berechnung der gesamten Kategorienwahrscheinlichkeit zurückkehren:\n\\(P(u_{ij} = 2 | \\theta_i, \\delta_{j1}, \\delta_{j2}, \\delta_{j3})\\)\n\\(= \\frac{exp(\\sum_{k = 0}^{2} (\\theta_i - \\delta_{jk}))}{\\sum_{l = 0}^{3} exp(\\sum_{k = 0}^{l} (\\theta_i - \\delta_{jk}))}\\)\nDer Zähler lässt sich mit dem eben gezeigten Trick schnell berechnen:\n\\(= \\frac{exp(2 \\cdot \\theta_i - \\delta_{j1} - \\delta_{j2})}{\\sum_{l = 0}^{3} exp(\\sum_{k = 0}^{l} (\\theta_i - \\delta_{jk}))}\\)\nIm Nenner müssen Sie den Trick mehrfach anwenden, nämlich einmal für jedes \\(l\\) zwischen \\(0\\) und \\(3\\):\n\\(= \\frac{exp(2 \\cdot \\theta_i - \\delta_{j1} - \\delta_{j2})}{\n    exp(0) +\n    exp(1\\cdot \\theta_i - \\delta_{j1}) +\n    exp(2\\cdot \\theta_i - \\delta_{j1}- \\delta_{j2}) +\n    exp(3\\cdot \\theta_i - \\delta_{j1}- \\delta_{j2}- \\delta_{j3})\n}\\)\nNun kann man schon Werte einsetzen:\n\\(= \\frac{exp(2 \\cdot 0.5 - (-1) - 0)}{\n    exp(0) +\n    exp(1\\cdot 0.5 - (-1)) +\n    exp(2\\cdot 0.5 - (-1) - 0) +\n    exp(3\\cdot 0.5 - (-1) - 0 - 1)\n}\\)\nSchrittweises Ausrechnen ergibt:\n\\(= \\frac{7.39}{\n    1 +\n    4.48 +\n    7.39 +\n    4.48\n} \\approx 0.43\\)\nDie modellimplizierte Wahrscheinlichkeit im PCM, dass eine Person mit \\(\\theta_i = 0.5\\) bei einem Item mit \\(\\delta_{j1} = -1\\), \\(\\delta_{j2} = 0\\), und \\(\\delta_{j3} = 1\\) in Kategorie \\(c = 2\\) antwortet ist also \\(0.43\\)."
  },
  {
    "objectID": "sections/datenmatrizen/datenmatrizen.html",
    "href": "sections/datenmatrizen/datenmatrizen.html",
    "title": "Psychometrische Datenmatrizen",
    "section": "",
    "text": "Psychometrische Datenmatrizen\nUm die später folgenden Modellgleichungen der IRT zu verstehen, ist es wichtig, flüssig mit der allgemeinen Datenmatrix umgehen zu können. In den folgenden Aufgaben üben Sie, Einträge sowie Zeilen- und Spaltenvektoren der allgemeinen Datenmatrix formal zu beschreiben.\nSie haben in der Vorlesung die allgemeine Datenmatrix kennengelernt:\n\\[\\begin{equation}\n    \\mathbf{U} =\n    \\begin{bmatrix}\n        u_{11} & \\dots & u_{1j} & \\dots & u_{1m} \\\\\n        \\vdots & \\ddots & \\vdots & \\ddots & \\vdots \\\\\n        u_{i1} & \\dots & u_{ij} & \\dots & u_{im} \\\\\n        \\vdots & \\ddots & \\vdots & \\ddots & \\vdots \\\\\n        u_{n1} & \\dots & u_{nj} & \\dots & u_{nm}\n    \\end{bmatrix}\n\\end{equation}\\]\n\nSuchen Sie Beispiele für Datenmatrizen, denen Sie im Bachelorstudium begegnet sind. Erklären Sie, wie Ihre Beispiel-Datenmatrix mit der oben abgebildeten allgemeinen Datenmatrix zusammenhängt.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nMögliches Beispiel: Fragebogendatensatz aus dem Empra.\nIn den Zeilen befanden sich \\(n = 143\\) Personen und in den Spalten befanden sich die \\(m = 60\\) Items des BFI-II. Aufgrund der Verwendung einer 5-Punkt Ratingskala, hatten die Einträge der Matrix jeweils einen der Werte \\(0, 1, 2, 3, 4\\).\n\n\n\n\nWofür stehen die Zeilen und Spalten der allgemeinen Datenmatrix bei testtheoretischen Anwendungen?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nZeilen: Personen\nSpalten: Items\n\n\n\n\nWie viele Zeilen und Spalten hat die allgemeine Datenmatrix?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(n\\) Zeilen\n\\(m\\) Spalten\nDie Antwort 3 Zeilen und 3 Spalten ist nicht richtig.\n\n\n\n\nBeschreiben Sie die folgenden Einträge der allgemeinen Datenmatrix symbolisch:\n\nDen Matrizeintrag in Zeile \\(4\\) und Spalte \\(8\\)\nDie Antwort von Person \\(102\\) auf Item \\(16\\)\nDie Antwort der ersten Person auf das erste Item\nDie Antwort der letzten Person auf das letzte Item\nDie Antwort einer beliebigen Person auf das letzte Item\nDie Antwort der letzten Person auf ein beliebiges Item\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\\(u_{48}\\)\n\\(u_{102 \\hspace{4pt} 16}\\)\n\\(u_{11}\\)\n\\(u_{nm}\\)\n\\(u_{im}\\)\n\\(u_{nj}\\)\n\n\n\n\nStatt einzelner Werte kann man auch ganze Zeilen oder Spalten der allgemeinen Datenmatrix extrahieren. Man nennt ganze Zeilen und Spalten der allgemeinen Datenmatrix auch Zeilen- und Spaltenvektoren. Beide Arten von Vektoren notieren wir mit kleinen fett gedruckten Buchstaben. \\(\\mathbf{u}_{.2}\\) bezeichnet etwa die gesamte zweite Spalte der allgemeinen Datenmatrix. Mit dem Punkt vor der \\(2\\) macht man kenntlich, dass alle Zeilenelemente extrahiert werden sollen. Umgekehrt bezeichnet \\(\\mathbf{u}_{2.}\\) die gesamte zweite Zeile der allgemeinen Datenmatrix.\nNotieren Sie die folgenden Zeilen und Spaltenvektoren der allgemeinen Datenmatrix symbolisch:\n\n\nDie erste Spalte der allgemeinen Datenmatrix\nDie dritte Zeile der allgemeinen Datenmatrix\nEine beliebige Zeile der allgemeinen Datenmatrix\nDie letzte Spalte der allgemeinen Datenmatrix\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\\(\\mathbf{u}_{.1}\\)\n\\(\\mathbf{u}_{3.}\\)\n\\(\\mathbf{u}_{i.}\\)\n\\(\\mathbf{u}_{.m}\\)\n\n\n\n\nAls abschließenden Hinweis möchten wir noch anmerken, dass die Herangehensweise, Datenvektoren und Datenmatrizen fett zu schreiben sowie Indizes bei Zeilen- und Spaltenvektoren durch Punkte zu ersetzen, nicht die eine richtige Notation ist. Andere Autor:innen definieren Vektoren zum Beispiel grundsätzlich als Spaltenvektoren, z.B. \\(x \\in \\mathbb{R}^n\\). Nur durch Transposition würde dann aus \\(x\\) ein Zeilenvektor: \\(x^T \\in \\mathbb{R}^{1 \\times n}\\).\n\n\nSummenscores\nAus der Vorlesung kennen Sie eine beispielhafte Datenmatrix für einen Fähigkeitstest mit \\(6\\) Items. Die folgende Datenmatrix ist ebenfalls eine beispielhafte Datenmatrix für einen Fähigkeitstest mit \\(6\\) Items. Sie enthält lediglich andere Werte.\n\\[\\begin{equation}\n        \\label{eq:databin}\n        \\textbf{U} =\n        \\begin{bmatrix}\n            1 & 1 & 1 & 1 & 1 & 1 \\\\\n            1 & 1 & 1 & 0 & 1 & 0 \\\\\n            0 & 1 & 1 & 1 & 1 & 1 \\\\\n            1 & 0 & 0 & 0 & 1 & 1 \\\\\n        \\end{bmatrix}\n    \\end{equation}\\]\nDer Summenscore wurde allgemein definiert als \\(\\sum_{j = 1}^{m} u_{ij} = r_{i}\\)\n\nBerechnen Sie \\(r_3\\)\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\[\nr_3 = \\sum_{j=1}^{6} u_{3j} = u_{31} + u_{32} + u_{33} + u_{34} + u_{35} + u_{36}\n\\]\n\\[\n= 0 + 1 + 1 + 1 + 1 + 1 = 5\n\\]\n\\[\nr_3 = 5\n\\]\n\n\n\n\nBerechnen Sie die Scoreverteilung und stellen Sie diese tabellarisch dar.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\[\\begin{array}{c|c}\n\\text{Person } i & r_i = \\sum_{j=1}^6 u_{ij} \\\\ \\hline\n1 & 1+1+1+1+1+1 = 6 \\\\\n2 & 1+1+1+0+1+0 = 4 \\\\\n3 & 0+1+1+1+1+1 = 5 \\\\\n4 & 1+0+0+0+1+1 = 3 \\\\\n\\end{array}\\]\n\\[\\begin{array}{c|c|c|c}\nr_i & 3 & 4 & 5 & 6 \\\\ \\hline\n\\text{Häufigkeit} & 1 & 1 & 1 & 1 \\\\\n\\end{array}\\]\n\n\n\n\nBeurteilen Sie anhand der Scoreverteilung die Passung des Tests zur Stichprobe. Verwenden Sie einen der Begriffe aus der Vorlesung: Gleichmäßig, Deckeneffekt, Bodeneffekt\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGleichmäßig\n\n\n\nSummenscores werden oft als Maß für die Fähigkeit oder Traitausprägung von Personen verwendet.\n\nWie wird diese Verrechnung in der Klassischen Testtheorie gerechtfertigt?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEs wird angenommen, dass sich die Varianz von Testantworten in einen Anteil wahrer Varianz und einen Anteil Fehlervarianz zerlegen lässt (Grundgleichung der KTT). In Verbindung mit der Annahme, dass der Erwartungswert der Fehlerverteilung Null beträgt folgt, dass der relative Einfluss des Fehlers sinkt, umso mehr Items miteinander durch Summierung der Testantworten verrechnet werden.\n\n\n\n\nFinden Sie Argumente für und gegen die Verwendung von Summenscores in der diagnostischen Praxis.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nArgumente für Summenscores:\n\nLeichte Berechnung und in der Praxis weit verbreitet\nPlausible Annahme, dass der unsystematische Fehler durch Aggregation asymptotisch gegen Null geht\nLeicht nachvollziehbar, auch für Nicht-Psycholog:innen (z. B. bei juristischer Relevanz von Testergebnissen)\n\nArgumente gegen Summenscores:\n\nAlle Items werden gleichgewichtet, auch wenn es oft plausibel erscheint, dass sich Items in ihrem Beitrag zur Merkmalsmessung unterscheiden\nAnnahme konstanter Reliabilität entlang des Fähigkeitkontinuums\nKeine Berücksichtung systematischen Fehlers\n\n\n\n\nDie Argumente gegen Summenscores motivieren die Verwendung von IRT Modellen."
  },
  {
    "objectID": "sections/pl2_pl3/pl2_pl3.html",
    "href": "sections/pl2_pl3/pl2_pl3.html",
    "title": "2PL- und 3PL-Modelle",
    "section": "",
    "text": "In der Vorlesung haben Sie das 2PL-Modell kennengelernt. Wie beim Rasch-Modell definiert auch das 2PL-Modell eine Lösungswahrscheinlichkeit, aus der sich die Likelihood-Funktion des Modells ableitet.\n\nWie unterscheidet sich die Formel der Lösungswahrscheinlichkeit im 2PL-Modell von der Formel der Lösungswahrscheinlichkeit im Rasch-Modell?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEs gibt einen Itemdiskriminationsparameter \\(\\alpha_i\\).\nImplizit gibt es den auch schon im Rasch-Modell. Er wird nur nicht frei geschätzt, sondern ist für alle Items gleich \\(1\\).\n\n\n\nDa Sie in der Prüfung mit der Formelsammlung arbeiten müssen, ist es sinnvoll, sich schon beim Bearbeiten der Übungsaufgaben in der Formelsammlung zu orientieren.\n\nSuchen Sie die Formel der Lösungswahrscheinlichkeit im 2PL-Modell in der Formelsammlung.\n\nIn der nächsten Aufgabe üben Sie, die Formel für die Lösungswahrscheinlichkeit anzuwenden. Die dritte Aufgabe setzt voraus, dass Sie, wie im Kapitel zu psychometrischen Datenmatrizen gelernt, Werte aus Datenvektoren indizieren können.\n\nBerechnen Sie\n\n\\(P(U_{ij} = 1 | \\theta_i = 0.7, \\beta_j = 0.5, \\alpha_j = 1)\\)\n\\(P(U_{ij} = 0 | \\theta_i = -2, \\beta_j = -1.5, \\alpha_j = 1.3)\\)\n\\(P(U_{i3} = u_{i3} | \\theta_i = 0, \\beta_j = -0.5, \\alpha_j = 1.2)\\), mit \\(\\mathbf{u}_{i.} = [0, 1, 1]\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nteachIRT::p_2pl(theta = 0.7, alpha = 1, beta = 0.5)\n\n[1] 0.549834\n\n\nBei der zweiten Aufgabe ist es wichtig, dass es sich um eine Nicht-Lösewahrscheinlichkeit handelt: \\(P(\\textcolor{red}{U_{ij} = 0} | \\theta_i = -2, \\beta_j = -1.5, \\alpha_j = 1.3)\\)\n\n1 - teachIRT::p_2pl(theta = -2, alpha = 1.3, beta = -1.5)\n\n[1] 0.6570105\n\n\nFür die dritten Aufgabe müssen Sie sich an das Kapitel zu psychometrischen Datenmatrizen erinnern. Hier ist die Wahrscheinlichkeit gefragt, dass eine Person \\(i\\) diejenige Antwort gibt, die wir im Antwortvektor finden. An der dritten Stelle des Antwortvektors steht eine \\(1\\). Sie müssen also die Lösungswahrscheinlichkeit berechnen.\n\nteachIRT::p_2pl(theta = 0, alpha = 1.2, beta = -0.5)\n\n[1] 0.6456563\n\n\n\n\n\nDie Abbildung zeigt ICCs von vier Items, die mit dem 2PL-Modell skaliert wurden.\n\n\n\n\n\n\n\n\n\n\nOrdnen Sie jeder Kombination von Parametern eine ICC zu.\n\n\n\\(\\beta = ?\\), \\(\\alpha = 0.4\\)\n\\(\\beta = 0.5\\), \\(\\alpha = 1\\)\n\\(\\beta = ?\\), \\(\\alpha = 1.4\\)\n\\(\\beta = -1\\), \\(\\alpha = 1\\)\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nItem 1 gehört zu c., wobei \\(\\beta_1 = 2\\)\nItem 2 gehört zu a., wobei \\(\\beta_2 = 1.5\\)\nItem 3 gehört zu d.\nItem 4 gehört zu b.\n\n\n\n\nDie ICCs aus der vorherigen Aufgabe wurden mit dem Befehl teachIRT::icc_2pl() erzeugt. Kopieren Sie den folgenden Code Chunk in Ihre eigene R Umgebung und ersetzen Sie die Parameterwerte. Geben Sie Ihrer Lerngruppe nur einen Teil der Parameter vor und lassen Sie Ihre Kommiliton:innen Items zu Parametern zuordnen.\nalpha enthält jeweils die Diskriminationsparameter und \\(\\beta\\) enthält jeweils die Schwierigkeitsparameter. Da jedes Item jeweils einen Diskriminations- und Schwierigkeitsparameter haben muss, müssen für die beiden Argumente jeweils gleich viele Werte eingetragen werden.\n\nlibrary(ggplot2)\np &lt;- teachIRT::icc_2pl(\n    alpha = c(1, 1.2, 1.4, -1),\n    beta = c(3, 2, -2, 1)\n)\np &lt;- p + ggplot2::ggtitle(\"\")\np\n\n\n\n\n\n\n\n\nSiehe auch ?teachIRT::icc_2pl.\n\nWenn Sie die vorherigen Aufgabe erledigt haben, ist die nächste für Sie ein alter Hut. Es vor Allem darum, dass Sie sehen, was passiert, wenn man für \\(\\alpha\\) Werte einsetzt, die kleiner als \\(0\\) sind.\n\nPlotten Sie ICCs eines 2PL-Modells für drei Items mit \\(\\beta_1 = \\beta_2 = \\beta_3 = 0\\) und\n\n\\(\\alpha_1 = -1\\)\n\\(\\alpha_2 = 0\\)\n\\(\\alpha_3 = 1\\)\n\nSie können diesen Befehl verwenden:\nteachIRT::icc_2pl(alpha = -1, beta = 0)\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nteachIRT::icc_2pl(alpha = c(-1, 0, 1), beta = c(0, 0, 0))\n\n\n\n\n\n\n\n\n\n\n\nNun wissen Sie, wie eine ICC mit negativer Diskrimination aussieht. Aber was bedeuten negative Diskriminationsparameter? Darum geht es in der nächsten Aufgabe.\n\nNehmen Sie an, dass die drei Items das latente Konstrukt Extraversion messen. Finden Sie je ein Beispielitem für die Werte \\(\\alpha_1\\), \\(\\alpha_2\\), und \\(\\alpha_3\\).\n\nHier noch eine Aufgabe, um ein Gefühl für den Diskriminationsparameter zu bekommen.\n\nStarten Sie mit teachIRT::icc_2pl(alpha = 0, beta = 0) und setzen Sie immer größere (/immer kleinere) Werte für \\(\\alpha\\) ein. Erklären Sie inhaltlich, welchen Effekt die Veränderung des \\(\\alpha\\)-Parameters hat.\n\nSie haben sicherlich festgestellt, dass die ICC mit höheren Werten für \\(\\alpha\\) steiler wird. \\(\\alpha\\) ist allerdings nicht direkt die Steigung der ICC, sondern proportional zu ihr. Da die ICC sigmoid ist, hängt die Steigung vom Wert auf der x-Achse, also \\(\\theta\\), ab. Diese Abhängigkeit der Steigung von \\(\\theta\\) werden wir im Kapitel zum adaptiven Testen bzw. zur Item- und Testinformation noch einmal nutzen.\n\n\nVom Rasch-Modell kennen Sie die Konzepte suffizienter Statistiken, spezifischer Objektivität und der lokalen stochastische Unabhängigkeit.\n\n\nSind die Summenscores im 2PL-Modell suffiziente Statistiken für die Personenparameter?\nGilt im 2PL-Modell die spezifische Objektivität?\nMachen wir im 2PL-Modell die Annahme lokaler stochastischer Unabhängigkeit?\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nNein\nNein\nJa\n\n\n\n\nAufgrund der Annahme lokaler stochastischer Unabhängigkeit kann man im 2PL-Modell, wie im Rasch-Modell auch, Lösungs- und Nichtlösewahrscheinlichkeiten miteinander multiplizieren. Das haben Sie in den Übungen zum Rasch-Modell schon einmal gemacht. Zur Sicherheit üben Sie das in der nächsten Übung noch einmal mit dem 2PL-Modell:\n\nBerechnen Sie die Wahrscheinlichkeit, bei einer Person mit \\(\\theta = 0.3\\) den Antwortvektor \\(\\mathbf{u}_{i.} = [1, 0, 0]\\) zu beobachten. Die Items \\(1\\), \\(2\\) und \\(3\\) haben die Itemparameter \\(\\alpha_1 = 0.4\\), \\(\\alpha_2 = 1\\), \\(\\alpha_3 = 1.2\\), \\(\\beta_1 = -1\\), \\(\\beta_2 = 1.2\\), \\(\\beta_3 = 0.3\\).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nBei Item 2 können Sie Zeit sparen, indem Sie die Formel für das Rasch-Modell verwenden. Bei Item 3 können Sie Zeit sparen, wenn Sie bemerken, dass \\(\\theta = \\beta_3\\) ist.\n\\(P(U_{i1} = 1, U_{i2} = 0, U_{i3} = 0 | \\alpha_1 = 0.4, \\alpha_2 = 1, \\alpha_3 = 1.2, \\beta_1 = -1, \\beta_2 = 1.2, \\beta_3 = 0.3)\\)\n\\(= P(U_{i1} = 1 | \\alpha_1 = 0.4, \\beta_1 = -1) \\cdot P(U_{i2} = 0 | \\alpha_2 = 1, \\beta_2 = 1.2) \\cdot P(U_{i3} = 0 | \\alpha_3 = 1.2, \\beta_3 = 0.3)\\)\n\\(= \\frac{1}{1 + e^{-\\alpha_1 (\\theta - \\beta_1)}} \\cdot \\frac{1}{1 + e^{\\theta - \\beta_2}} \\cdot \\frac{1}{1 + e^{-\\alpha_3 (\\theta - \\beta_3)}}\\)\n\\(= \\frac{1}{1 + e^{-0.4 (0.3 + 1)}} \\cdot \\frac{1}{1 + e^{0.3 - 1.2}} \\cdot 0.5\\)\n\\(\\approx .22\\)\n\ntheta &lt;- 0.3\np1 &lt;- teachIRT::p_2pl(theta = theta, alpha = 0.4, beta = -1)\np2 &lt;- teachIRT::p_rasch(theta = theta, beta = 1.2)\np3 &lt;- 0.5\n\nprint(p1 * (1-p2) * p3)\n\n[1] 0.2229352\n\n\n\n\n\nDa Sie nun wissen, dass im 2PL-Modell die lokale stochastische Unabhängigkeit wie im Rasch-Modell gilt, können Sie das Wissen direkt übertragen.\n\nSchreiben Sie formal die Likelihood des Antwortvektors einer Person \\(i\\) für das 2PL-Modell auf.\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nDen ersten Teil der Lösung finden Sie 1 zu 1 beim Rasch-Modell.\n\n\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nWenn Sie noch weiter gehen wollen und einen Wert für die Wahrscheinlichkeit im 2PL-Modell einsetzen möchten, müssen Sie eine Formel für \\(P(U_{ij} = u_{ij} | \\theta)\\) im 2PL-Modell finden. Das müssen Sie ad-hoc nicht selbst hinkriegen. Für den Fall, dass Sie es doch probieren möchten, haben wir diese Formel erst im nächsten Tipp hinterlegt.\n\n\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\n\\(P(U_j = u_j \\mid \\theta) = \\frac{\\exp(u_{ij}\\,\\alpha_j\\,(\\theta_i - \\beta_j))}{1 + \\exp(\\alpha_j\\,(\\theta_i - \\beta_j))}\\)\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Logik ist die gleiche, wie im Rasch-Modell. Um die Likelihood eines Antwortvektors zu erhalten, müssen Sie die Wahrscheinlichkeiten der beoabchteten Testantworten miteinander multiplizieren:\n\\[\\begin{equation}\n    P(U_1 = u_1, ..., U_m = u_m | \\theta) = \\prod_{j = 1}^{m} P(U_j = u_j | \\theta)\n\\end{equation}\\]\nBeim 2PL-Modell müssen Sie lediglich eine andere Warscheinlichkeit für \\(P(U_j = u_j | \\theta)\\) verwenden. Man könnte also auch schreiben:\n\\[\\begin{equation}\n    P(U_1 = u_1, ..., U_m = u_m | \\theta) = \\prod_{j = 1}^{m} \\frac{exp(u_{ij} \\alpha_j (\\theta_i - \\beta_j))}{1 + exp(\\alpha_j (\\theta_i - \\beta_j))}\n\\end{equation}\\]\nDenn der Ausdruck \\(\\frac{\\exp(u_{ij} \\alpha_j (\\theta_i - \\beta_j))}{1 + \\exp(\\alpha_j (\\theta_i - \\beta_j))}\\) wird, je nachdem, ob man für \\(u_{ij}\\) den Wert \\(1\\) oder \\(0\\) einsetzt, jeweils zur Lösungs- oder Nichtlösewahrscheinlichkeit. Probieren Sie das gerne einmal selbst aus!\n\n\n\n\n\n\n\nEin 2PL-Modell wurde auf die Daten des Mathetests im Abschnitt zum Rasch-Modell gefittet. Dazu wurde der Befehl mirt des Pakets mirt verwendet.\n\nlibrary(mirt)\n\nLoading required package: stats4\n\n\nLoading required package: lattice\n\npl2 &lt;- mirt(responses, itemtype = \"2PL\")\nprint(pl2)\n\n\nCall:\nmirt(data = responses, itemtype = \"2PL\")\n\nFull-information item factor analysis with 1 factor(s).\nConverged within 1e-04 tolerance after 13 EM iterations.\nmirt version: 1.45.1 \nM-step optimizer: BFGS \nEM acceleration: Ramsay \nNumber of rectangular quadrature: 61\nLatent density type: Gaussian \n\nLog-likelihood = -4339.257\nEstimated parameters: 40 \nAIC = 8758.513\nBIC = 8927.097; SABIC = 8800.135\nG2 (1048535) = 3160.83, p = 1\nRMSEA = 0, CFI = NaN, TLI = NaN\n\n\n\nIst das 2PL-Modell konvergiert?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nJa, das erkennen Sie an der Zeile “Converged within 1e-04 tolerance after 13 EM iterations.”\n\n\n\nMit dem Befehl coef() wurden die Parameterschätzer des 2PL-Modells extrahiert.\n\ncoef(pl2, IRTpars = TRUE, simplify = TRUE)\n\n$items\n        a      b g u\nX1  0.918 -2.261 0 1\nX2  0.964 -2.637 0 1\nX3  0.966 -0.701 0 1\nX4  1.106 -0.668 0 1\nX5  1.109 -3.085 0 1\nX6  1.082 -1.483 0 1\nX7  0.795 -2.619 0 1\nX8  1.172 -3.319 0 1\nX9  1.036 -1.596 0 1\nX10 0.797 -1.841 0 1\nX11 0.777 -2.072 0 1\nX12 0.821 -1.704 0 1\nX13 0.745 -0.777 0 1\nX14 0.855 -1.339 0 1\nX15 0.853 -2.568 0 1\nX16 1.310 -1.967 0 1\nX17 0.859 -2.069 0 1\nX18 1.085 -1.061 0 1\nX19 0.853 -2.843 0 1\nX20 1.367 -1.468 0 1\n\n$means\nF1 \n 0 \n\n$cov\n   F1\nF1  1\n\n\n\nWofür stehen die Spalten a und b?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\na ist der Diskriminationsparameter\nb ist die Itemschwierigkeit\n\n\n\n\nLesen Sie den Diskriminationsparameter des leichtesten Items ab.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncoefs &lt;- coef(pl2, IRTpars = TRUE, simplify = TRUE)\ncoefs &lt;- coefs$items\ncoefs[which.min(coefs[, \"b\"]), \"a\"]\n\n[1] 1.172313\n\n\n\n\n\n\nVergleichen Sie die geschätzten Schwierigkeitsparameter des 2PL-Modells mit denen des Rasch-Modells in der person-item map. Was könnte der Grund dafür sein, dass alle Itemschwierigkeiten im 2PL-Modell negativ sind, während sie im Rasch-Modell um \\(0\\) herum verteilt sind?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nIn mirt wird zur Identifikation der latenten Skala nicht der Mittelwert der Itemparameter, sondern der Mittelwert der erwarteten Verteilung der Personenparameter auf \\(0\\) gesetzt.\nIm folgenden Code extrahieren wir die Personenparameter und überprüfen, ob ihr Mittelwert tatsächlich \\(0\\) ist:\n\ntheta &lt;- fscores(pl2)\ncolMeans(theta)\n\n           F1 \n-0.0002373066 \n\n\nFast! Der Identifikationsconstraint wird nicht auf die geschätzten Personenparameter angewendet, sondern nur auf die latente Verteilung im Modell, sodass die individuellen Schätzungen davon abweichen können. Daher kann der Mittelwert etwas von \\(0\\) abweichen.\n\n\n\n\n\n\nSie haben in der Vorlesung das 3PL-Modell kennengelernt.\n\nWie unterscheidet sich die Formel der Lösungswahrscheinlichkeit im 3PL-Modell von der Formel der Lösungswahrscheinlichkeit im 2PL-Modell?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nZusätzlich zum Diskriminationsparameter gibt es einen Rateparameter.\n\n\n\n\nSuchen Sie die Formel der Lösungswahrscheinlichkeit im 3PL-Modell in der Formelsammlung.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\[\\begin{equation}\n    P(U_{ij} = 1 | \\theta_i, \\beta_j, \\alpha_j, \\gamma_j) =\n    \\gamma_j + (1 - \\gamma_j) \\cdot \\frac{e^{(\\alpha_j (\\theta_i - \\beta_j))}}{1 + e^{\\alpha_j (\\theta_i - \\beta_j)}}\n\\end{equation}\\]\n\n\n\n\nBerechnen Sie die Wahrscheinlichkeit des Antwortvektors \\(\\mathbf{u}_{i.} = [1, 1, 0]\\) für den folgenden Itempool bei \\(\\theta = -0.5\\):\n\n\n\nj\n\\(\\alpha\\)\n\\(\\beta\\)\n\\(\\gamma\\)\n\n\n\n\n1\n1.0\n-0.5\n0.0\n\n\n2\n0.8\n1.0\n0.2\n\n\n3\n1.2\n0.0\n0.1\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nBei Item \\(1\\) müssen Sie nicht rechnen, da \\(\\gamma = 0\\) und \\(\\theta = \\beta_1\\).\n\\[\\begin{equation}\nP(U_{i1} = 1 | \\theta_i = -0.5) = \\tfrac{1}{2}\n\\end{equation}\\]\nItems \\(2\\) und \\(3\\) erfordern die vollständige Formel des 3PL-Modells.\n\\[\\begin{equation}\nP(U_{i2} = 1 | \\theta_i = -0.5)\n\\end{equation}\\]\n\\[\\begin{equation}\n= 0.2 + 0.8 \\cdot \\frac{exp(0.8 (-0.5 - 1))}{1 + exp(0.8 (-0.5 - 1))}\n\\end{equation}\\]\nBei Item \\(3\\) müssen Sie darauf achten, dass das Item nicht gelöst wurde.\n\\[\\begin{equation}\nP(U_{i3} = 1 | \\theta_i = -0.5)\n\\end{equation}\\]\n\\[\\begin{equation}\n= 0.1 + 0.9 \\cdot \\frac{exp(1.2 (-0.5))}{1 + exp(1.2 (-0.5))}\n\\end{equation}\\]\nUnd es ist \\(P(U_{i3} = 0 | \\theta_i = -0.5) = 1 - P(U_{i3} = 1 | \\theta_i = -0.5)\\).\nZur Berechnung der Wahrscheinlichkeit des ganzen Antwortvektors verwenden wir die Annahme lokaler stochastischer Unabhängigkeit:\n\\[\\begin{equation}\nP(U_{i1} = 1, U_{i2} = 1, U_{i3} = 0 | \\theta=-0.5)\n\\end{equation}\\]\n\\[\\begin{equation}\n= \\prod_{j = 1}^{3} P(U_{ij} = u_{ij} | \\theta_i = -0.5)\n\\end{equation}\\]\n\\[\\begin{equation}\n= \\frac{1}{2} \\cdot \\Big( 0.2 + 0.8 \\cdot \\frac{exp(0.8 (-0.5 - 1))}{1 + exp(0.8 (-0.5 - 1))} \\Big) \\cdot \\Big(1 - (0.1 + 0.9 \\cdot \\frac{exp(1.2 (-0.5))}{1 + exp(1.2 (-0.5))}) \\Big)\n\\end{equation}\\]\n\\[\\begin{equation}\n\\approx .11\n\\end{equation}\\]\nWir überprüfen in R:\n\n# Fähigkeitsparameter im Objekt theta speichern\ntheta &lt;- -0.5\n\n# Die erste Lösungswahrschienlichkeit folgt aus dem Rasch-Modell bei theta = beta\np1 &lt;- 0.5\n\n# Lösungswahrscheinlichkeit von Item 2 berechnen\np2 &lt;- teachIRT::p_3pl(\n    theta = theta,\n    alpha = 0.8,\n    beta = 1,\n    gamma = 0.2\n    )\n\n# Lösungswahrscheinlichkeit von Item 3 berechnen\np3 &lt;- teachIRT::p_3pl(\n    theta = theta,\n    alpha = 1.2,\n    beta = 0,\n    gamma = 0.1\n    )\n\n# Gemeinsame Wahrscheinlichkeit des Antwortvektors berechnen\nprob &lt;- p1*p2*(1-p3)\nprint(prob)\n\n[1] 0.1119123\n\n\n\n\n\n\nIm Plot sehen Sie die ICC eines Items im 3PL-Modell mit \\(\\beta = 0\\), \\(\\alpha = 1\\), und \\(\\gamma = 0.2\\). Zeichnen Sie die Nichtlösewahrscheinlichkeit ein.\n\nteachIRT::icc_3pl(\n    beta = 0,\n    alpha = 1,\n    gamma = 0.2\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWenn Sie wissen, dass sich Wahrscheinlichkeiten \\(P(U_{ij} = 1 | \\theta_i)\\) und \\(P(U_{ij} = 0 | \\theta_i)\\) für jeden Wert von \\(\\theta_i\\) zu \\(1\\) summieren, können Sie die Nicht-Lösewahrscheinlichkeit am Graphen rekonstruieren.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWelchen Wert erhalten Sie für \\(\\lim_{\\theta_i \\to -\\infty} P(U_{ij} = 1 | \\theta_i, \\beta_j, \\alpha_j, \\gamma_j)\\)?\n\nFalls Sie keinen Ansatz finden, können Sie sich den schwierigeren Teil der Lösung vorgeben lassen. Im zweiten Teil der Lösung müssen Sie keine Formeln mehr umstellen, sondern können immer kleiner werdende Werte für \\(\\theta_i\\) einsetzen.\n\n\n\n\n\n\nLösung Teil 1\n\n\n\n\n\nGesucht ist\n\\[\\begin{equation}\n\\lim_{\\theta_i \\to -\\infty} P(U_{ij} = 1 | \\theta_i, \\beta_j, \\alpha_j, \\gamma_j)\n\\end{equation}\\]\n\\[\\begin{equation}\n= \\lim_{\\theta_i \\to -\\infty} \\gamma_j + (1 - \\gamma_j) \\cdot \\frac{e^{\\alpha_j(\\theta_i - \\beta_j)}}{1 + e^{\\alpha_j (\\theta_i - \\beta_j)}}\n\\end{equation}\\]\nDer erste Term enthält nur den Parameter \\(\\gamma_j\\). Die Berechnung des Limits beschränkt sich also auf den Bruch im zweiten Term.\n\\[\\begin{equation}\n= \\gamma_j + (1 - \\gamma_j) \\cdot \\lim_{\\theta_i \\to -\\infty} \\frac{e^{\\alpha_j(\\theta_i - \\beta_j)}}{1 + e^{\\alpha_j (\\theta_i - \\beta_j)}}\n\\end{equation}\\]\nAb hier können Sie sprachlich argumentieren bzw. immer kleinere Werte im Taschenrechner einsetzen.\n\n\n\n\n\n\n\n\n\nLösung Teil 2\n\n\n\n\n\nWenn \\(\\theta_i\\) extrem klein wird, geht \\(\\theta - \\beta_j\\) gegen \\(-\\infty\\). Somit geht der Zähler gegen \\(0\\) und der Nenner gegen \\(1\\). Daher gehen der Bruch und folglich auch das Produkt mit \\((1-\\gamma_j)\\) asymptotisch gegen \\(0\\). Es bleibt der Grenzwert \\(\\gamma_j\\).\nDas sieht man auch an den ICCs. Testweise kann man eine sehr weite \\(\\theta\\)-Achse plotten.\n\nteachIRT::icc_3pl(\n    theta_range = c(-50, 5),\n    alpha = 1,\n    beta = 0,\n    gamma = 0.2\n)\n\n\n\n\n\n\n\n\nMan sieht, dass die untere Asymptote den Wert \\(\\gamma = 0.2\\) im geplotteten Bereich nicht unterschreitet. Zuvor haben wir gezeigt, dass das auch im Unendlichen nicht passiert.\n\n\n\n\nErklären Sie mit eigenen Worten, was die untere Asymptote der ICC im 3PL-Modell inhaltlich bedeutet.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEgal wie gering die Personenfähigkeit einer Person ist, es bleibt immer eine Wahrscheinlichkeit von \\(\\gamma_j\\), das Item zu lösen.\n\n\n\n\nRecherchieren Sie: Gibt es ein 4PL-Modell? Was könnte der vierte Parameter bedeuten?\n\n\nKreuzen Sie in der folgenden Tabelle an, wenn ein Parameter im Modell frei geschätzt wird.\n\n\n\nModell\n\\(\\alpha\\)\n\\(\\beta\\)\n\\(\\gamma\\)\n\n\n\n\nRasch\n\n\n\n\n\n2PL\n\n\n\n\n\n3PL\n\n\n\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\n\nModell\n\\(\\alpha\\)\n\\(\\beta\\)\n\\(\\gamma\\)\n\n\n\n\nRasch\n\n\\(\\checkmark\\)\n\n\n\n2PL\n\\(\\checkmark\\)\n\\(\\checkmark\\)\n\n\n\n3PL\n\\(\\checkmark\\)\n\\(\\checkmark\\)\n\\(\\checkmark\\)\n\n\n\n\n\n\n\nWelche Werte können der \\(\\alpha\\), \\(\\beta\\), \\(\\gamma\\), und \\(\\theta\\) Parameter im 3PL-Modell minimal und maximal annehmen?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(\\alpha, \\beta \\in \\mathbb{R}\\)\n\\(\\gamma \\in [0, 1]\\)"
  },
  {
    "objectID": "sections/pl2_pl3/pl2_pl3.html#antwortwahrscheinlichkeiten-im-2pl-modell",
    "href": "sections/pl2_pl3/pl2_pl3.html#antwortwahrscheinlichkeiten-im-2pl-modell",
    "title": "2PL- und 3PL-Modelle",
    "section": "",
    "text": "In der Vorlesung haben Sie das 2PL-Modell kennengelernt. Wie beim Rasch-Modell definiert auch das 2PL-Modell eine Lösungswahrscheinlichkeit, aus der sich die Likelihood-Funktion des Modells ableitet.\n\nWie unterscheidet sich die Formel der Lösungswahrscheinlichkeit im 2PL-Modell von der Formel der Lösungswahrscheinlichkeit im Rasch-Modell?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEs gibt einen Itemdiskriminationsparameter \\(\\alpha_i\\).\nImplizit gibt es den auch schon im Rasch-Modell. Er wird nur nicht frei geschätzt, sondern ist für alle Items gleich \\(1\\).\n\n\n\nDa Sie in der Prüfung mit der Formelsammlung arbeiten müssen, ist es sinnvoll, sich schon beim Bearbeiten der Übungsaufgaben in der Formelsammlung zu orientieren.\n\nSuchen Sie die Formel der Lösungswahrscheinlichkeit im 2PL-Modell in der Formelsammlung.\n\nIn der nächsten Aufgabe üben Sie, die Formel für die Lösungswahrscheinlichkeit anzuwenden. Die dritte Aufgabe setzt voraus, dass Sie, wie im Kapitel zu psychometrischen Datenmatrizen gelernt, Werte aus Datenvektoren indizieren können.\n\nBerechnen Sie\n\n\\(P(U_{ij} = 1 | \\theta_i = 0.7, \\beta_j = 0.5, \\alpha_j = 1)\\)\n\\(P(U_{ij} = 0 | \\theta_i = -2, \\beta_j = -1.5, \\alpha_j = 1.3)\\)\n\\(P(U_{i3} = u_{i3} | \\theta_i = 0, \\beta_j = -0.5, \\alpha_j = 1.2)\\), mit \\(\\mathbf{u}_{i.} = [0, 1, 1]\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nteachIRT::p_2pl(theta = 0.7, alpha = 1, beta = 0.5)\n\n[1] 0.549834\n\n\nBei der zweiten Aufgabe ist es wichtig, dass es sich um eine Nicht-Lösewahrscheinlichkeit handelt: \\(P(\\textcolor{red}{U_{ij} = 0} | \\theta_i = -2, \\beta_j = -1.5, \\alpha_j = 1.3)\\)\n\n1 - teachIRT::p_2pl(theta = -2, alpha = 1.3, beta = -1.5)\n\n[1] 0.6570105\n\n\nFür die dritten Aufgabe müssen Sie sich an das Kapitel zu psychometrischen Datenmatrizen erinnern. Hier ist die Wahrscheinlichkeit gefragt, dass eine Person \\(i\\) diejenige Antwort gibt, die wir im Antwortvektor finden. An der dritten Stelle des Antwortvektors steht eine \\(1\\). Sie müssen also die Lösungswahrscheinlichkeit berechnen.\n\nteachIRT::p_2pl(theta = 0, alpha = 1.2, beta = -0.5)\n\n[1] 0.6456563\n\n\n\n\n\nDie Abbildung zeigt ICCs von vier Items, die mit dem 2PL-Modell skaliert wurden.\n\n\n\n\n\n\n\n\n\n\nOrdnen Sie jeder Kombination von Parametern eine ICC zu.\n\n\n\\(\\beta = ?\\), \\(\\alpha = 0.4\\)\n\\(\\beta = 0.5\\), \\(\\alpha = 1\\)\n\\(\\beta = ?\\), \\(\\alpha = 1.4\\)\n\\(\\beta = -1\\), \\(\\alpha = 1\\)\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nItem 1 gehört zu c., wobei \\(\\beta_1 = 2\\)\nItem 2 gehört zu a., wobei \\(\\beta_2 = 1.5\\)\nItem 3 gehört zu d.\nItem 4 gehört zu b.\n\n\n\n\nDie ICCs aus der vorherigen Aufgabe wurden mit dem Befehl teachIRT::icc_2pl() erzeugt. Kopieren Sie den folgenden Code Chunk in Ihre eigene R Umgebung und ersetzen Sie die Parameterwerte. Geben Sie Ihrer Lerngruppe nur einen Teil der Parameter vor und lassen Sie Ihre Kommiliton:innen Items zu Parametern zuordnen.\nalpha enthält jeweils die Diskriminationsparameter und \\(\\beta\\) enthält jeweils die Schwierigkeitsparameter. Da jedes Item jeweils einen Diskriminations- und Schwierigkeitsparameter haben muss, müssen für die beiden Argumente jeweils gleich viele Werte eingetragen werden.\n\nlibrary(ggplot2)\np &lt;- teachIRT::icc_2pl(\n    alpha = c(1, 1.2, 1.4, -1),\n    beta = c(3, 2, -2, 1)\n)\np &lt;- p + ggplot2::ggtitle(\"\")\np\n\n\n\n\n\n\n\n\nSiehe auch ?teachIRT::icc_2pl.\n\nWenn Sie die vorherigen Aufgabe erledigt haben, ist die nächste für Sie ein alter Hut. Es vor Allem darum, dass Sie sehen, was passiert, wenn man für \\(\\alpha\\) Werte einsetzt, die kleiner als \\(0\\) sind.\n\nPlotten Sie ICCs eines 2PL-Modells für drei Items mit \\(\\beta_1 = \\beta_2 = \\beta_3 = 0\\) und\n\n\\(\\alpha_1 = -1\\)\n\\(\\alpha_2 = 0\\)\n\\(\\alpha_3 = 1\\)\n\nSie können diesen Befehl verwenden:\nteachIRT::icc_2pl(alpha = -1, beta = 0)\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nteachIRT::icc_2pl(alpha = c(-1, 0, 1), beta = c(0, 0, 0))\n\n\n\n\n\n\n\n\n\n\n\nNun wissen Sie, wie eine ICC mit negativer Diskrimination aussieht. Aber was bedeuten negative Diskriminationsparameter? Darum geht es in der nächsten Aufgabe.\n\nNehmen Sie an, dass die drei Items das latente Konstrukt Extraversion messen. Finden Sie je ein Beispielitem für die Werte \\(\\alpha_1\\), \\(\\alpha_2\\), und \\(\\alpha_3\\).\n\nHier noch eine Aufgabe, um ein Gefühl für den Diskriminationsparameter zu bekommen.\n\nStarten Sie mit teachIRT::icc_2pl(alpha = 0, beta = 0) und setzen Sie immer größere (/immer kleinere) Werte für \\(\\alpha\\) ein. Erklären Sie inhaltlich, welchen Effekt die Veränderung des \\(\\alpha\\)-Parameters hat.\n\nSie haben sicherlich festgestellt, dass die ICC mit höheren Werten für \\(\\alpha\\) steiler wird. \\(\\alpha\\) ist allerdings nicht direkt die Steigung der ICC, sondern proportional zu ihr. Da die ICC sigmoid ist, hängt die Steigung vom Wert auf der x-Achse, also \\(\\theta\\), ab. Diese Abhängigkeit der Steigung von \\(\\theta\\) werden wir im Kapitel zum adaptiven Testen bzw. zur Item- und Testinformation noch einmal nutzen.\n\n\nVom Rasch-Modell kennen Sie die Konzepte suffizienter Statistiken, spezifischer Objektivität und der lokalen stochastische Unabhängigkeit.\n\n\nSind die Summenscores im 2PL-Modell suffiziente Statistiken für die Personenparameter?\nGilt im 2PL-Modell die spezifische Objektivität?\nMachen wir im 2PL-Modell die Annahme lokaler stochastischer Unabhängigkeit?\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nNein\nNein\nJa\n\n\n\n\nAufgrund der Annahme lokaler stochastischer Unabhängigkeit kann man im 2PL-Modell, wie im Rasch-Modell auch, Lösungs- und Nichtlösewahrscheinlichkeiten miteinander multiplizieren. Das haben Sie in den Übungen zum Rasch-Modell schon einmal gemacht. Zur Sicherheit üben Sie das in der nächsten Übung noch einmal mit dem 2PL-Modell:\n\nBerechnen Sie die Wahrscheinlichkeit, bei einer Person mit \\(\\theta = 0.3\\) den Antwortvektor \\(\\mathbf{u}_{i.} = [1, 0, 0]\\) zu beobachten. Die Items \\(1\\), \\(2\\) und \\(3\\) haben die Itemparameter \\(\\alpha_1 = 0.4\\), \\(\\alpha_2 = 1\\), \\(\\alpha_3 = 1.2\\), \\(\\beta_1 = -1\\), \\(\\beta_2 = 1.2\\), \\(\\beta_3 = 0.3\\).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nBei Item 2 können Sie Zeit sparen, indem Sie die Formel für das Rasch-Modell verwenden. Bei Item 3 können Sie Zeit sparen, wenn Sie bemerken, dass \\(\\theta = \\beta_3\\) ist.\n\\(P(U_{i1} = 1, U_{i2} = 0, U_{i3} = 0 | \\alpha_1 = 0.4, \\alpha_2 = 1, \\alpha_3 = 1.2, \\beta_1 = -1, \\beta_2 = 1.2, \\beta_3 = 0.3)\\)\n\\(= P(U_{i1} = 1 | \\alpha_1 = 0.4, \\beta_1 = -1) \\cdot P(U_{i2} = 0 | \\alpha_2 = 1, \\beta_2 = 1.2) \\cdot P(U_{i3} = 0 | \\alpha_3 = 1.2, \\beta_3 = 0.3)\\)\n\\(= \\frac{1}{1 + e^{-\\alpha_1 (\\theta - \\beta_1)}} \\cdot \\frac{1}{1 + e^{\\theta - \\beta_2}} \\cdot \\frac{1}{1 + e^{-\\alpha_3 (\\theta - \\beta_3)}}\\)\n\\(= \\frac{1}{1 + e^{-0.4 (0.3 + 1)}} \\cdot \\frac{1}{1 + e^{0.3 - 1.2}} \\cdot 0.5\\)\n\\(\\approx .22\\)\n\ntheta &lt;- 0.3\np1 &lt;- teachIRT::p_2pl(theta = theta, alpha = 0.4, beta = -1)\np2 &lt;- teachIRT::p_rasch(theta = theta, beta = 1.2)\np3 &lt;- 0.5\n\nprint(p1 * (1-p2) * p3)\n\n[1] 0.2229352\n\n\n\n\n\nDa Sie nun wissen, dass im 2PL-Modell die lokale stochastische Unabhängigkeit wie im Rasch-Modell gilt, können Sie das Wissen direkt übertragen.\n\nSchreiben Sie formal die Likelihood des Antwortvektors einer Person \\(i\\) für das 2PL-Modell auf.\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nDen ersten Teil der Lösung finden Sie 1 zu 1 beim Rasch-Modell.\n\n\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nWenn Sie noch weiter gehen wollen und einen Wert für die Wahrscheinlichkeit im 2PL-Modell einsetzen möchten, müssen Sie eine Formel für \\(P(U_{ij} = u_{ij} | \\theta)\\) im 2PL-Modell finden. Das müssen Sie ad-hoc nicht selbst hinkriegen. Für den Fall, dass Sie es doch probieren möchten, haben wir diese Formel erst im nächsten Tipp hinterlegt.\n\n\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\n\\(P(U_j = u_j \\mid \\theta) = \\frac{\\exp(u_{ij}\\,\\alpha_j\\,(\\theta_i - \\beta_j))}{1 + \\exp(\\alpha_j\\,(\\theta_i - \\beta_j))}\\)\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Logik ist die gleiche, wie im Rasch-Modell. Um die Likelihood eines Antwortvektors zu erhalten, müssen Sie die Wahrscheinlichkeiten der beoabchteten Testantworten miteinander multiplizieren:\n\\[\\begin{equation}\n    P(U_1 = u_1, ..., U_m = u_m | \\theta) = \\prod_{j = 1}^{m} P(U_j = u_j | \\theta)\n\\end{equation}\\]\nBeim 2PL-Modell müssen Sie lediglich eine andere Warscheinlichkeit für \\(P(U_j = u_j | \\theta)\\) verwenden. Man könnte also auch schreiben:\n\\[\\begin{equation}\n    P(U_1 = u_1, ..., U_m = u_m | \\theta) = \\prod_{j = 1}^{m} \\frac{exp(u_{ij} \\alpha_j (\\theta_i - \\beta_j))}{1 + exp(\\alpha_j (\\theta_i - \\beta_j))}\n\\end{equation}\\]\nDenn der Ausdruck \\(\\frac{\\exp(u_{ij} \\alpha_j (\\theta_i - \\beta_j))}{1 + \\exp(\\alpha_j (\\theta_i - \\beta_j))}\\) wird, je nachdem, ob man für \\(u_{ij}\\) den Wert \\(1\\) oder \\(0\\) einsetzt, jeweils zur Lösungs- oder Nichtlösewahrscheinlichkeit. Probieren Sie das gerne einmal selbst aus!"
  },
  {
    "objectID": "sections/pl2_pl3/pl2_pl3.html#anwendung-des-2pl-modells",
    "href": "sections/pl2_pl3/pl2_pl3.html#anwendung-des-2pl-modells",
    "title": "2PL- und 3PL-Modelle",
    "section": "",
    "text": "Ein 2PL-Modell wurde auf die Daten des Mathetests im Abschnitt zum Rasch-Modell gefittet. Dazu wurde der Befehl mirt des Pakets mirt verwendet.\n\nlibrary(mirt)\n\nLoading required package: stats4\n\n\nLoading required package: lattice\n\npl2 &lt;- mirt(responses, itemtype = \"2PL\")\nprint(pl2)\n\n\nCall:\nmirt(data = responses, itemtype = \"2PL\")\n\nFull-information item factor analysis with 1 factor(s).\nConverged within 1e-04 tolerance after 13 EM iterations.\nmirt version: 1.45.1 \nM-step optimizer: BFGS \nEM acceleration: Ramsay \nNumber of rectangular quadrature: 61\nLatent density type: Gaussian \n\nLog-likelihood = -4339.257\nEstimated parameters: 40 \nAIC = 8758.513\nBIC = 8927.097; SABIC = 8800.135\nG2 (1048535) = 3160.83, p = 1\nRMSEA = 0, CFI = NaN, TLI = NaN\n\n\n\nIst das 2PL-Modell konvergiert?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nJa, das erkennen Sie an der Zeile “Converged within 1e-04 tolerance after 13 EM iterations.”\n\n\n\nMit dem Befehl coef() wurden die Parameterschätzer des 2PL-Modells extrahiert.\n\ncoef(pl2, IRTpars = TRUE, simplify = TRUE)\n\n$items\n        a      b g u\nX1  0.918 -2.261 0 1\nX2  0.964 -2.637 0 1\nX3  0.966 -0.701 0 1\nX4  1.106 -0.668 0 1\nX5  1.109 -3.085 0 1\nX6  1.082 -1.483 0 1\nX7  0.795 -2.619 0 1\nX8  1.172 -3.319 0 1\nX9  1.036 -1.596 0 1\nX10 0.797 -1.841 0 1\nX11 0.777 -2.072 0 1\nX12 0.821 -1.704 0 1\nX13 0.745 -0.777 0 1\nX14 0.855 -1.339 0 1\nX15 0.853 -2.568 0 1\nX16 1.310 -1.967 0 1\nX17 0.859 -2.069 0 1\nX18 1.085 -1.061 0 1\nX19 0.853 -2.843 0 1\nX20 1.367 -1.468 0 1\n\n$means\nF1 \n 0 \n\n$cov\n   F1\nF1  1\n\n\n\nWofür stehen die Spalten a und b?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\na ist der Diskriminationsparameter\nb ist die Itemschwierigkeit\n\n\n\n\nLesen Sie den Diskriminationsparameter des leichtesten Items ab.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncoefs &lt;- coef(pl2, IRTpars = TRUE, simplify = TRUE)\ncoefs &lt;- coefs$items\ncoefs[which.min(coefs[, \"b\"]), \"a\"]\n\n[1] 1.172313\n\n\n\n\n\n\nVergleichen Sie die geschätzten Schwierigkeitsparameter des 2PL-Modells mit denen des Rasch-Modells in der person-item map. Was könnte der Grund dafür sein, dass alle Itemschwierigkeiten im 2PL-Modell negativ sind, während sie im Rasch-Modell um \\(0\\) herum verteilt sind?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nIn mirt wird zur Identifikation der latenten Skala nicht der Mittelwert der Itemparameter, sondern der Mittelwert der erwarteten Verteilung der Personenparameter auf \\(0\\) gesetzt.\nIm folgenden Code extrahieren wir die Personenparameter und überprüfen, ob ihr Mittelwert tatsächlich \\(0\\) ist:\n\ntheta &lt;- fscores(pl2)\ncolMeans(theta)\n\n           F1 \n-0.0002373066 \n\n\nFast! Der Identifikationsconstraint wird nicht auf die geschätzten Personenparameter angewendet, sondern nur auf die latente Verteilung im Modell, sodass die individuellen Schätzungen davon abweichen können. Daher kann der Mittelwert etwas von \\(0\\) abweichen."
  },
  {
    "objectID": "sections/pl2_pl3/pl2_pl3.html#antwortwahrscheinlichkeiten-im-3pl-modell",
    "href": "sections/pl2_pl3/pl2_pl3.html#antwortwahrscheinlichkeiten-im-3pl-modell",
    "title": "2PL- und 3PL-Modelle",
    "section": "",
    "text": "Sie haben in der Vorlesung das 3PL-Modell kennengelernt.\n\nWie unterscheidet sich die Formel der Lösungswahrscheinlichkeit im 3PL-Modell von der Formel der Lösungswahrscheinlichkeit im 2PL-Modell?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nZusätzlich zum Diskriminationsparameter gibt es einen Rateparameter.\n\n\n\n\nSuchen Sie die Formel der Lösungswahrscheinlichkeit im 3PL-Modell in der Formelsammlung.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\[\\begin{equation}\n    P(U_{ij} = 1 | \\theta_i, \\beta_j, \\alpha_j, \\gamma_j) =\n    \\gamma_j + (1 - \\gamma_j) \\cdot \\frac{e^{(\\alpha_j (\\theta_i - \\beta_j))}}{1 + e^{\\alpha_j (\\theta_i - \\beta_j)}}\n\\end{equation}\\]\n\n\n\n\nBerechnen Sie die Wahrscheinlichkeit des Antwortvektors \\(\\mathbf{u}_{i.} = [1, 1, 0]\\) für den folgenden Itempool bei \\(\\theta = -0.5\\):\n\n\n\nj\n\\(\\alpha\\)\n\\(\\beta\\)\n\\(\\gamma\\)\n\n\n\n\n1\n1.0\n-0.5\n0.0\n\n\n2\n0.8\n1.0\n0.2\n\n\n3\n1.2\n0.0\n0.1\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nBei Item \\(1\\) müssen Sie nicht rechnen, da \\(\\gamma = 0\\) und \\(\\theta = \\beta_1\\).\n\\[\\begin{equation}\nP(U_{i1} = 1 | \\theta_i = -0.5) = \\tfrac{1}{2}\n\\end{equation}\\]\nItems \\(2\\) und \\(3\\) erfordern die vollständige Formel des 3PL-Modells.\n\\[\\begin{equation}\nP(U_{i2} = 1 | \\theta_i = -0.5)\n\\end{equation}\\]\n\\[\\begin{equation}\n= 0.2 + 0.8 \\cdot \\frac{exp(0.8 (-0.5 - 1))}{1 + exp(0.8 (-0.5 - 1))}\n\\end{equation}\\]\nBei Item \\(3\\) müssen Sie darauf achten, dass das Item nicht gelöst wurde.\n\\[\\begin{equation}\nP(U_{i3} = 1 | \\theta_i = -0.5)\n\\end{equation}\\]\n\\[\\begin{equation}\n= 0.1 + 0.9 \\cdot \\frac{exp(1.2 (-0.5))}{1 + exp(1.2 (-0.5))}\n\\end{equation}\\]\nUnd es ist \\(P(U_{i3} = 0 | \\theta_i = -0.5) = 1 - P(U_{i3} = 1 | \\theta_i = -0.5)\\).\nZur Berechnung der Wahrscheinlichkeit des ganzen Antwortvektors verwenden wir die Annahme lokaler stochastischer Unabhängigkeit:\n\\[\\begin{equation}\nP(U_{i1} = 1, U_{i2} = 1, U_{i3} = 0 | \\theta=-0.5)\n\\end{equation}\\]\n\\[\\begin{equation}\n= \\prod_{j = 1}^{3} P(U_{ij} = u_{ij} | \\theta_i = -0.5)\n\\end{equation}\\]\n\\[\\begin{equation}\n= \\frac{1}{2} \\cdot \\Big( 0.2 + 0.8 \\cdot \\frac{exp(0.8 (-0.5 - 1))}{1 + exp(0.8 (-0.5 - 1))} \\Big) \\cdot \\Big(1 - (0.1 + 0.9 \\cdot \\frac{exp(1.2 (-0.5))}{1 + exp(1.2 (-0.5))}) \\Big)\n\\end{equation}\\]\n\\[\\begin{equation}\n\\approx .11\n\\end{equation}\\]\nWir überprüfen in R:\n\n# Fähigkeitsparameter im Objekt theta speichern\ntheta &lt;- -0.5\n\n# Die erste Lösungswahrschienlichkeit folgt aus dem Rasch-Modell bei theta = beta\np1 &lt;- 0.5\n\n# Lösungswahrscheinlichkeit von Item 2 berechnen\np2 &lt;- teachIRT::p_3pl(\n    theta = theta,\n    alpha = 0.8,\n    beta = 1,\n    gamma = 0.2\n    )\n\n# Lösungswahrscheinlichkeit von Item 3 berechnen\np3 &lt;- teachIRT::p_3pl(\n    theta = theta,\n    alpha = 1.2,\n    beta = 0,\n    gamma = 0.1\n    )\n\n# Gemeinsame Wahrscheinlichkeit des Antwortvektors berechnen\nprob &lt;- p1*p2*(1-p3)\nprint(prob)\n\n[1] 0.1119123\n\n\n\n\n\n\nIm Plot sehen Sie die ICC eines Items im 3PL-Modell mit \\(\\beta = 0\\), \\(\\alpha = 1\\), und \\(\\gamma = 0.2\\). Zeichnen Sie die Nichtlösewahrscheinlichkeit ein.\n\nteachIRT::icc_3pl(\n    beta = 0,\n    alpha = 1,\n    gamma = 0.2\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWenn Sie wissen, dass sich Wahrscheinlichkeiten \\(P(U_{ij} = 1 | \\theta_i)\\) und \\(P(U_{ij} = 0 | \\theta_i)\\) für jeden Wert von \\(\\theta_i\\) zu \\(1\\) summieren, können Sie die Nicht-Lösewahrscheinlichkeit am Graphen rekonstruieren.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWelchen Wert erhalten Sie für \\(\\lim_{\\theta_i \\to -\\infty} P(U_{ij} = 1 | \\theta_i, \\beta_j, \\alpha_j, \\gamma_j)\\)?\n\nFalls Sie keinen Ansatz finden, können Sie sich den schwierigeren Teil der Lösung vorgeben lassen. Im zweiten Teil der Lösung müssen Sie keine Formeln mehr umstellen, sondern können immer kleiner werdende Werte für \\(\\theta_i\\) einsetzen.\n\n\n\n\n\n\nLösung Teil 1\n\n\n\n\n\nGesucht ist\n\\[\\begin{equation}\n\\lim_{\\theta_i \\to -\\infty} P(U_{ij} = 1 | \\theta_i, \\beta_j, \\alpha_j, \\gamma_j)\n\\end{equation}\\]\n\\[\\begin{equation}\n= \\lim_{\\theta_i \\to -\\infty} \\gamma_j + (1 - \\gamma_j) \\cdot \\frac{e^{\\alpha_j(\\theta_i - \\beta_j)}}{1 + e^{\\alpha_j (\\theta_i - \\beta_j)}}\n\\end{equation}\\]\nDer erste Term enthält nur den Parameter \\(\\gamma_j\\). Die Berechnung des Limits beschränkt sich also auf den Bruch im zweiten Term.\n\\[\\begin{equation}\n= \\gamma_j + (1 - \\gamma_j) \\cdot \\lim_{\\theta_i \\to -\\infty} \\frac{e^{\\alpha_j(\\theta_i - \\beta_j)}}{1 + e^{\\alpha_j (\\theta_i - \\beta_j)}}\n\\end{equation}\\]\nAb hier können Sie sprachlich argumentieren bzw. immer kleinere Werte im Taschenrechner einsetzen.\n\n\n\n\n\n\n\n\n\nLösung Teil 2\n\n\n\n\n\nWenn \\(\\theta_i\\) extrem klein wird, geht \\(\\theta - \\beta_j\\) gegen \\(-\\infty\\). Somit geht der Zähler gegen \\(0\\) und der Nenner gegen \\(1\\). Daher gehen der Bruch und folglich auch das Produkt mit \\((1-\\gamma_j)\\) asymptotisch gegen \\(0\\). Es bleibt der Grenzwert \\(\\gamma_j\\).\nDas sieht man auch an den ICCs. Testweise kann man eine sehr weite \\(\\theta\\)-Achse plotten.\n\nteachIRT::icc_3pl(\n    theta_range = c(-50, 5),\n    alpha = 1,\n    beta = 0,\n    gamma = 0.2\n)\n\n\n\n\n\n\n\n\nMan sieht, dass die untere Asymptote den Wert \\(\\gamma = 0.2\\) im geplotteten Bereich nicht unterschreitet. Zuvor haben wir gezeigt, dass das auch im Unendlichen nicht passiert.\n\n\n\n\nErklären Sie mit eigenen Worten, was die untere Asymptote der ICC im 3PL-Modell inhaltlich bedeutet.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEgal wie gering die Personenfähigkeit einer Person ist, es bleibt immer eine Wahrscheinlichkeit von \\(\\gamma_j\\), das Item zu lösen.\n\n\n\n\nRecherchieren Sie: Gibt es ein 4PL-Modell? Was könnte der vierte Parameter bedeuten?\n\n\nKreuzen Sie in der folgenden Tabelle an, wenn ein Parameter im Modell frei geschätzt wird.\n\n\n\nModell\n\\(\\alpha\\)\n\\(\\beta\\)\n\\(\\gamma\\)\n\n\n\n\nRasch\n\n\n\n\n\n2PL\n\n\n\n\n\n3PL\n\n\n\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\n\nModell\n\\(\\alpha\\)\n\\(\\beta\\)\n\\(\\gamma\\)\n\n\n\n\nRasch\n\n\\(\\checkmark\\)\n\n\n\n2PL\n\\(\\checkmark\\)\n\\(\\checkmark\\)\n\n\n\n3PL\n\\(\\checkmark\\)\n\\(\\checkmark\\)\n\\(\\checkmark\\)\n\n\n\n\n\n\n\nWelche Werte können der \\(\\alpha\\), \\(\\beta\\), \\(\\gamma\\), und \\(\\theta\\) Parameter im 3PL-Modell minimal und maximal annehmen?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(\\alpha, \\beta \\in \\mathbb{R}\\)\n\\(\\gamma \\in [0, 1]\\)"
  },
  {
    "objectID": "sections/adaptives_testen/adaptives_testen.html",
    "href": "sections/adaptives_testen/adaptives_testen.html",
    "title": "Iteminformation und adaptives Testen",
    "section": "",
    "text": "In der Vorlesung lernen Sie Informationsmaße für das Rasch-, 2PL-, und 3PL-Modell kennen. Je nachdem, welchem Ablauf die Vorlesung folgt, kann es sinnvoll sein, diesen Abschnitt zunächst zu überspringen und wiederzukehren, wenn die Vorlesung den Themenabschnitt behandelt hat.\n\nWelchen Nutzen haben Informationsmaße für IRT-Modelle?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nInformationsmaße quantifizieren, wie stark die Unsicherheit um eine Personenparameterschätzung durch Vorgabe eines Items reduziert würde.\nDas ist z.B. nützlich zur:\n\nItemselektion\nadaptiven Vorgabe von Items\nTestkürzung\n\n\n\n\nIn der Tabelle sind die Informationsmaße aus der Vorlesung noch einmal zusammengefasst.\nInformationsmaße im Rasch- 2PL- und 3PL-Modell\n\n\n\n\n\n\n\nModell\nItem Information \\(I_j(\\theta)\\)\n\n\n\n\nRasch\n\\(P(U_{ij} = 1 | ...) P(U_{ij} = 0 | ...)\\)\n\n\n2PL\n\\(\\alpha_j^2 P(U_{ij} = 1 | ...) P(U_{ij} = 0 | ...)\\)\n\n\n3PL\n\\([\\alpha_j^2 \\frac{P(U_{ij} = 0 | ...)}{P(U_{ij} = 1 | ...)}][\\frac{(P(U_{ij} = 1 | ...) - \\gamma_j)^2}{(1-\\gamma_j)^2}]\\)\n\n\n\nDer folgende Plot zeigt die Informationsfunktion eines Rasch-skalierten Items mit einer Itemschwierigkeit von \\(\\beta = 1\\).\n\nteachIRT::inf_plot_rasch(beta = 1)\n\n\n\n\n\n\n\n\n\nWie hängt dieser Plot mit den Formeln für Informationsmaße zusammen?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEs wurde die Informationsfunktion des Rasch-Modells verwendet.\nAuf der x-Achse sieht man Fähigkeitswerte.\nAuf der y-Achse sieht man die dazugehörige Iteminformation.\n\n\n\n\nBerechnen Sie \\(I_j(-1)\\) für ein Rasch-Modell mit \\(\\beta_j = 1\\). Finden Sie den Wert im Plot aus Aufgabe (a) wieder?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben:\n\\(\\theta = -1\\)\n\\(\\beta_j = 1\\)\nGesucht:\n\\(I_j(-1) = P(U = 1 | \\theta, \\beta_j) \\cdot P(U = 0 | \\theta, \\beta_j)\\)\nEs ist\n\\(P(U = 1 | \\theta, \\beta_j) = \\frac{1}{1 + e^{2}}\\)\nUnd\n\\(P(U = 0 | \\theta, \\beta_j) = 1 - P(U = 1 | \\theta, \\beta_j)\\)\nAlso ist die Information des Items bei einer Fähigkeit von \\(\\theta = -1\\):\n\\(I_j(-1) = \\frac{1}{1 + e^{2}} \\cdot (1 - \\frac{1}{1 + e^{2}}) \\approx .10\\)\nÜberprüfung mit teachIRT:\n\nteachIRT::inf_rasch(theta = -1, beta = 1)\n\n[1] 0.1049936\n\n\n\n\n\nKopieren Sie den folgenden Code in Ihre R IDE:\n\nlibrary(patchwork)\n    \nalpha &lt;- 1\nbeta &lt;- 0\ngamma &lt;- 0\n\np1 &lt;- teachIRT::icc_3pl(\nalpha = alpha,\nbeta = beta,\ngamma = gamma\n)\n\np2 &lt;- teachIRT::inf_plot_3pl(\nalpha = alpha,\nbeta = beta,\ngamma = gamma\n)\n\np1 / p2\n\n\n\n\n\n\n\n\n\nVerändern Sie die Parameterwerte von \\(\\alpha\\), \\(\\beta\\) und \\(\\gamma\\) und führen Sie den Code erneut durch. Versuchen Sie durch systematisches Austauschen der Parameterwerte zu erkennen, wie die Parameter jeweils die ICC und die Informationsfunktion beeinflussen. Notieren Sie Ihre Beobachtung.\n\n\nBerechnen Sie die Information eines Items mit Hilfe des 3PL-Modells bei \\(\\theta_i = -0.5\\). Der Rateparameter hat einen Wert von \\(0.2\\). Der Itemdiskriminationsparameter hat einen Wert von \\(-1\\). Der Itemschwierigkeitsparameter hat einen Wert von \\(0.5\\).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben:\n\\(\\theta_i = -0.5\\)\n\\(\\alpha_j = -1\\)\n\\(\\beta_j = 0.5\\)\n\\(\\gamma_j = 0.2\\)\nGesucht:\n\\(I_j(\\theta) = I_j(-0.5)\\)\nEs ist\n\\(P(U_{ij} = 1 | \\theta_i, \\alpha_j, \\beta_j, \\gamma_j)\\)\n\\(=\\gamma_j + (1 - \\gamma_j) \\cdot \\frac{e^{(\\alpha_j (\\theta_i - \\beta_j))}}{1 + e^{\\alpha_j (\\theta_i - \\beta_j)}}\\)\n\\(=0.2 + 0.8 \\cdot \\frac{e}{1 + e}\\)\n\\(\\approx .78\\)\nZur Kontrolle:\n\nteachIRT::p_3pl(\n    theta = -0.5,\n    alpha = -1,\n    beta = 0.5, \n    gamma = 0.2\n    )\n\n[1] 0.7848469\n\n\nDer Übersicht halber arbeiten wir mit dem gerundeten Zwischenergebnis weiter.\nEs ist\n\\(I_j(-0.5)\\)\n\\(=[\\alpha_j^2 \\frac{P(U_{ij} = 0 | ...)}{P(U_{ij} = 1 | ...)}][\\frac{(P(U_{ij} = 1 | ...) - \\gamma_j)^2}{(1-\\gamma_j)^2}]\\)\n\\(=[(-1)^2 \\frac{(1-0.78)}{0.78}][\\frac{(0.78 - 0.2)^2}{0.8^2}]\\)\n\\(\\approx 0.15\\)\n\nteachIRT::inf_3pl(\n    theta = -0.5,\n    alpha = -1,\n    beta = 0.5,\n    gamma = 0.2\n)\n\n[1] 0.1465099\n\n\n\n\n\n\nVersuchen Sie zu antizipieren, wie die ICC und Informationsfunktion des Items aus der vorherigen Aufgabe aussehen. Überprüfen Sie Ihre Vermutung mit teachIRT::teachIRT::icc_3pl() und teachIRT::inf_plot_3pl().\nSie können sich die Argumente der Funktionen anzeigen lassen, indem Sie ein Fragezeichen davor setzen, z.B. ?teachIRT::inf_plot_3pl().\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nICC\n\nteachIRT::icc_3pl(\n    alpha = -1,\n    beta = 0.5,\n    gamma = 0.2\n)\n\n\n\n\n\n\n\n\nInformation\n\nteachIRT::inf_plot_3pl(\n    alpha = -1,\n    beta = 0.5,\n    gamma = 0.2\n)\n\n\n\n\n\n\n\n\n\n\n\n\nWelche Formel würden Sie nutzen, um die Iteminformation eines Items im 3PL-Modell zu berechnen, dessen Itemparameter \\(\\alpha = 1\\), \\(\\beta = -0.5\\), und \\(\\gamma = 0\\) sind?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nMan könnte die Informationsfunktion des Rasch-Modells verwenden, denn das 3PL-Modell wird für \\(\\alpha = 1\\) und \\(\\gamma = 0\\) zum Rasch-Modell.\nErinnern Sie sich zurück, wie aufwendig es war, bei den vorherigen Aufgaben die Information eines Items im 3PL-Modell zu berechnen. Mit diesem Trick können Sie beim händischen Rechnen viel Zeit sparen.\n\n\n\nWenn Sie ganz sicher gehen wollen, können Sie noch selbst zeigen, dass Sie in diesem speziellen Fall die Rasch-Information nutzen können. Diese Aufgabe ist eher für Studierende gedacht, die Spaß an einer zusätzlichen Matheaufgabe haben.\n\nZeigen Sie, dass die Information im 3PL Modell für \\(\\alpha = 1\\) und \\(\\gamma = 0\\) zur Information im Rasch-Modell wird.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDer Übersicht halber nennen wir die Lösewahrscheinlichkeit \\(p\\) und die Nichtlösewahrscheinlichkeit \\(q\\).\nDie Information im 3PL-Modell ist\n\\([\\alpha_j^2 \\frac{P(U_{ij} = 0 | ...)}{P(U_{ij} = 1 | ...)}][\\frac{(P(U_{ij} = 1 | ...) - \\gamma_j)^2}{(1-\\gamma_j)^2}]\\)\n\\(=[\\alpha_j^2 \\frac{q}{p}][\\frac{(p - \\gamma_j)^2}{(1-\\gamma_j)^2}]\\) (Mit der Definition von \\(p\\) und \\(q\\))\n\\(=[1^2 \\frac{q}{p}][\\frac{(p - 0)^2}{(1-0)^2}]\\) (\\(\\alpha = 1\\) und \\(\\gamma = 0\\) einsetzen)\n\\(=\\frac{q}{p} \\cdot \\frac{p^2}{1}\\)\n\\(=\\frac{p^2q}{p}\\)\n\\(=pq\\)\n\\(=P(U_{ij} = 1 | ...) \\cdot P(U_{ij} = 0 | ...)\\) (Wieder einsetzen)\nDie letzte Zeile entspricht der Information im Rasch-Modell.\n\n\n\n\n\nZwei nützliche Eigenschaften der Item- und Testinformation sind ihre Additivität und ihr direkter Bezug zum Standardfehler einer Personenparameterschätzung.\nIn der Formel zur Testinformation wird die Eigenschaft der Additivität genutzt. Die Iteminformationen an einem Punkt der \\(\\theta\\)-Achse lässt sich für jedes Item einzeln berechnen, \\(I_j(\\theta)\\). Summiert man alle Iteminformationen, so erhält man die Testinformation bei \\(\\theta\\):\n\\[\\begin{equation}\n    I(\\theta) = \\sum_{j = 1}^{m} I_j(\\theta)\n\\end{equation}\\]\n\nEin Test enthält drei Items. Eine Reihe von Informationsschätzern ist bekannt: \\(I_1(-1) = 0.18\\), \\(I_1(0.8) = 0.1\\), \\(I_2(-1) = 0.2\\), \\(I_3(2) = 0.2\\), und \\(I_3(-1) = 0.25\\)\nBerechnen Sie die Information des Tests bei \\(\\theta = -1\\).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(I(-1)\\)\n\\(= I_1(-1) + I_2(-1) + I_3(-1)\\)\n\\(=0.18 + 0.2 + 0.25\\)\n\\(=0.63\\)\n\n\n\nIn der folgenden Formel können Sie sehen, dass der Standardfehler das inverse Konzept zur Iteminformation ist.\n\\[\\begin{equation}\n    SE(\\hat{\\theta}) = \\frac{1}{\\sqrt{I(\\hat{\\theta})}}\n\\end{equation}\\]\nMan kann die Umformung zwischen Information und Standardfehlern in R plotten:\n\n\n\n\n\n\n\n\n\n\nWas passiert mit dem Standardfehler einer Personenparameterschätzung, wenn die Information gegen \\(0\\) (vs. \\(\\infty\\)) geht? Welche Konsequenz hätte das für das Konfidenzintervall um eine Personenparameterschätzung?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWenn die Information gegen \\(0\\) geht, geht der Standardfehler gegen \\(\\infty\\).\nWenn die Information gegen \\(\\infty\\) geht, geht der Standardfehler gegen \\(0\\).\n\n\n\nDer obere Plot der folgenden Abbildung zeigt die Informationsfunktion eines Items im 2PL-Modell mit \\(\\alpha = 1.2\\) und \\(\\beta = 0\\). Im unteren Plot finden Sie die dazugehörigen Standardfehler. Die Standardfehler wurden mit der Umformungsfunktion berechnet.\n\n\n\n\n\n\n\n\n\n\nFinden Sie den Verlauf der Plots plausibel? Versuchen Sie intuitiv nachzuvollziehen, wie die beiden Plots miteinander in Verbindung stehen.\n\nDer Standardfehler um einen Personenparameter kann genutzt werden, um Konfidenzintervalle zu berechnen:\n\\[\\begin{equation}\n    KI = \\hat{\\theta} \\pm z_{\\alpha/2} \\cdot SE(\\hat{\\theta})\n\\end{equation}\\]\n\nDie Testinformation bei \\(\\hat{\\theta} = 1\\) beträgt \\(I(1) = 3\\). Berechnen Sie das zweiseitige \\(95\\%\\) Konfidenzintervall um den Personenparameter.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben:\n\\(\\hat{\\theta} = 1\\)\n\\(I(\\hat{\\theta}) = I(1) = 3\\)\nGesucht:\n\\(KI = \\hat{\\theta} \\pm z_{\\alpha/2} \\cdot SE(\\hat{\\theta})\\)\nAls erstes berechnen wir den Standardfehler:\n\\(SE(\\hat{\\theta}) = \\frac{1}{\\sqrt{I(\\hat{\\theta})}} = \\frac{1}{\\sqrt{3}}\\)\nBei einem zweiseitigen \\(95%\\) Konfidenzintervall rechnen wir mit dem z-Wert \\(1.96\\) bzw. \\(-1.96\\) für die untere Grenze:\n\nteachIRT::get_z(ci_alpha = 0.05, ci_direction = \"both\")\n\n    lower     upper \n-1.959964  1.959964 \n\n\nEingesetzt erhalten wir für die obere Grenze\n\\(KI_o = 1 + 1.96 \\cdot \\frac{1}{\\sqrt{3}} \\approx 2.13\\)\nund für die untere Grenze\n\\(KI_u = 1 - 1.96 \\cdot \\frac{1}{\\sqrt{3}} \\approx -0.13\\)\nZur Ergebniskontrolle können wir teachIRT verwenden:\n\nteachIRT:::ci_general(\n    theta = 1,\n    inf = 3,\n    ci_alpha = 0.05,\n    ci_direction = \"both\"\n)\n\n     lower      upper \n-0.1315857  2.1315857 \n\n\n\n\n\n\n\n\nIn der Vorlesung haben Sie einen Algorithmus zum adaptiven Testen kennengelernt (Prozessdiagramm mit lila Kästchen, “Ablauf des adaptiven Tests”). Die nächsten beiden Aufgaben beziehen sich auf diesen Algorithmus. Ich empfehle Ihnen sehr, diese Aufgaben nicht zu überspringen, denn hier kommt noch einmal vieles zusammen, was Sie im Laufe der Veranstaltung über IRT gelernt haben.\nVerwenden Sie zur Bearbeitung beider Aufgaben den folgenden Itempool:\n\n\n\n\\(j\\)\n\\(\\alpha_j\\)\n\\(\\beta_j\\)\n\\(\\gamma_j\\)\n\n\n\n\n1\n\\(0.8\\)\n\\(-1.2\\)\n\\(0.4\\)\n\n\n2\n\\(1.2\\)\n\\(0.5\\)\n\\(0.1\\)\n\n\n3\n\\(0.9\\)\n\\(-0.8\\)\n\\(0.2\\)\n\n\n4\n\\(1.0\\)\n\\(0.3\\)\n\\(0\\)\n\n\n\n\n\n\nSie befinden sich in Schritt 2. des Testalgorithmus (“Wähle und zeige das optimale nächste Item”). Welches Item sollte der adaptive Testalgorithmus als nächstes präsentieren?\nAktueller Fähigkeitsschätzer: \\(\\hat{\\theta}_i = 0.5\\)\n\nDiese Aufgabe benötigt etwas Zeit. Lassen Sie sich nicht verunsichern, wenn Sie hier etwas länger dran arbeiten.\n\n\n\n\n\n\nTipp: Beschreibung des Lösungswegs\n\n\n\n\n\nUm diese Aufgabe zu lösen, müssen Sie für alle vier Items in der Tabelle berechnen, wie groß die Iteminformation bei \\(\\hat{\\theta}_i = 0.5\\) ist. Zu berechnen sind also \\(I_1(0.5)\\), \\(I_2(0.5)\\), \\(I_3(0.5)\\) und \\(I_4(0.5)\\). Dazu können Sie die Formeln für die Iteminformation verwenden. Bei einem der Items können Sie etwas Zeit sparen, wenn Sie erkennen, dass Sie die Formel des Rasch-Modells verwenden können. Bei den anderen Items müssen Sie mit der Formel für das 3PL-Modell arbeiten. Zuletzt können Sie vergleichen, welches der Items den höchsten Informationswert beim vorläufigen Fähigkeitsschätzer aufweist. Dieses Item sollte der adaptive Testalgorithmus als nächstes präsentieren.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDas optimale nächste Item ist in der IRT dasjenige, das beim aktuellen Fähigkeitsschätzer den höchsten Wert in der Informationsfunktion hat.\nEs ist \\(\\hat{\\theta}_i = 0.5\\) gegeben.\nWir können die Parameter im vorgegebenen Itempool verwenden, um die Iteminformation beim gegebenen vorläufigen Fähigkeitsschätzer zu berechnen.\nItem 1\nZunächst lohnt sich der Blick auf die Itemparameter. Item 1 hat einen Diskriminationsparameter, der ungleich 1 ist und einen Rateparameter, der ungleich Null ist. Entsprechend muss man hier die Informationsfunktion des 3PL-Modells verwenden. Los geht’s:\n\\[I_1(0.5)\\]\n\\[= [\\alpha_1^2 \\frac{P(U_{i1} = 0 | ...)}{P(U_{i1} = 1 | ...)}][\\frac{(P(U_{i1} = 1 | ...) - \\gamma_1)^2}{(1-\\gamma_1)^2}]\\]\nDie Formel erfordert eine Lösungwahrscheinlichkeit. Hier müssen wir die Formel aus dem 3PL-Modell verwenden.\n\\[P(U_{i1} = 1 | \\theta_i = 0.5, \\alpha_1, \\beta_1, \\gamma_1)\\]\n\\[= \\gamma_1 + (1 - \\gamma_1) \\cdot \\frac{e^{\\alpha_1 (\\theta_i - \\beta_1)}}{1+ e^{\\alpha_1 (\\theta_i - \\beta_1)}}\\]\n\\[= 0.4 + (1 - 0.4) \\cdot \\frac{e^{0.8 (0.5 - (-1.2))}}{1+ e^{0.8 (0.5 - (-1.2))}}\\]\n\\[\\approx 0.877\\]\nDieses Zwischenergebnis runde ich der Übersicht halber. Es lohnt sich natürlich, die berechnete Lösungswahrscheinlichkeit mit teachIRT zu überprüfen:\n\nteachIRT::p_3pl(theta = 0.5, alpha = 0.8, beta = -1.2, gamma = 0.4)\n\n[1] 0.8774558\n\n\nDas Ergebnis scheint zu stimmen. Aus der eben berechneten Lösungswahrscheinlichkeit ergibt sich leicht die Nichtlösewahrscheinlichkeit des Items.\n\\[P(U_{i1} = 0 | \\theta_i = 0.5, \\alpha_1, \\beta_1, \\gamma_1)\\]\n\\[= 1 - P(U_{i1} = 1 | \\theta_i = 0.5, \\alpha_1, \\beta_1, \\gamma_1)\\]\n\\[\\approx 1 - 0.877 = 0.123\\]\nAuch dieses Zwischenergebnis können wir schnell mit teachIRT überprüfen:\n\n1 - teachIRT::p_3pl(theta = 0.5, alpha = 0.8, beta = -1.2, gamma = 0.4)\n\n[1] 0.1225442\n\n\nDer Rundungsfehler tradiert sich natürlich auch in die Nichtlösewahrscheinlichkeit.\nDie gerundete Löse- und Nichlösewahrscheinlichkeit kann man nun in die Informationsfunktion des 3PL-Modells einsetzen:\n\\[I_1(0.5)\\]\n\\[= [\\alpha_1^2 \\frac{P(U_{i1} = 0 | ...)}{P(U_{i1} = 1 | ...)}][\\frac{(P(U_{i1} = 1 | ...) - \\gamma_1)^2}{(1-\\gamma_1)^2}]\\]\n\\[= [\\alpha_1^2 \\frac{0.123}{0.877}][\\frac{(0.877 - \\gamma_1)^2}{(1-\\gamma_1)^2}]\\]\n(Löse- und Nichtlösewahrscheinlichkeiten einsetzen)\n\\[= [0.8^2 \\frac{0.123}{0.877}][\\frac{(0.877 - 0.4)^2}{(1-0.4)^2}]\\]\n(Itemparameter einsetzen)\n\\[\\approx 0.06\\]\nDas Endergebnis kann man wieder mit teachIRT überprüfen.\n\nteachIRT::inf_3pl(theta = 0.5, alpha = 0.8, beta = -1.2, gamma = 0.4)\n\n[1] 0.05659933\n\n\nDamit haben wir die Information von Item 1 beim vorläufigen Fähigkeitsschätzer \\(\\hat{\\theta}_i = 0.5\\) berechnet.\nItem 2\nWeiter geht es mit Item 2. Auch hier liegen ein Diskriminationsparameter ungleich 1 und ein Rateparameter ungleich 0 vor. Entsprechend muss man auch hier die Informationsfunktion des 3PL-Modells verwenden. Die Schritte sind also die gleichen wie bei Item 1, nur die Itemparameter ändern sich.\n\\[I_2(0.5) =\\]\n\\[= [\\alpha_2^2 \\frac{P(U_{i2} = 0 | ...)}{P(U_{i2} = 1 | ...)}][\\frac{(P(U_{i2} = 1 | ...) - \\gamma_2)^2}{(1-\\gamma_2)^2}]\\]\nWieder ist eine Lösungswahrscheinlichkeit erforderlich. Diesmal hat die Lösungswahrscheinlichkeit eine viel schönere Form und wir erhalten auch ohne Taschenrechner ein exaktes Ergebnis:\n\\[P(U_{i2} = 1 | \\theta_i = 0.5, \\alpha_2, \\beta_2, \\gamma_2)\\]\n\\[= \\gamma_2 + (1 - \\gamma_2) \\cdot \\frac{e^{\\alpha_2 (\\theta_i - \\beta_2)}}{1+ e^{\\alpha_2 (\\theta_i - \\beta_2)}}\\]\n\\[= 0.1 + (1 - 0.1) \\cdot \\frac{e^{1.2 (0.5 - 0.5)}}{1+ e^{1.2 (0.5 - 0.5)}}\\]\n\\[= 0.1 + 0.9 \\cdot \\frac{1}{2}\\]\n\\[= 0.1 + \\frac{0.9}{2}\\]\n\\[= 0.1 + 0.45\\]\n\\[= 0.55\\]\nDie Überprüfung mit teachIRT bestätigt das Ergebnis:\n\nteachIRT::p_3pl(theta = 0.5, alpha = 1.2, beta = 0.5, gamma = 0.1)\n\n[1] 0.55\n\n\nDie exakte Nichtlösewahrscheinlichkeit beträgt\n\\[P(U_{i2} = 0 | \\theta_i = 0.5, \\alpha_2, \\beta_2, \\gamma_2) = 1 - 0.55 = 0.45\\]\n\n1 - teachIRT::p_3pl(theta = 0.5, alpha = 1.2, beta = 0.5, gamma = 0.1)\n\n[1] 0.45\n\n\nDie Lösungs- und Nichlösewahrscheinlichkeiten kann man nun in die Formel für die Iteminformation einsetzen:\n\\[I_2(0.5)\\]\n\\[= [\\alpha_2^2 \\frac{P(U_{i2} = 0 | ...)}{P(U_{i2} = 1 | ...)}][\\frac{(P(U_{i2} = 1 | ...) - \\gamma_2)^2}{(1-\\gamma_2)^2}]\\]\n\\[= [\\alpha_2^2 \\frac{0.45}{0.55}][\\frac{(0.55 - \\gamma_2)^2}{(1-\\gamma_2)^2}]\\]\n\\[= [1.2^2 \\frac{0.45}{0.55}][\\frac{(0.55 - 0.1)^2}{(1-0.1)^2}]\\]\n\\[\\approx 0.29\\]\n\nteachIRT::inf_3pl(theta = 0.5, alpha = 1.2, beta = 0.5, gamma = 0.1)\n\n[1] 0.2945455\n\n\nDamit haben wir auch die Information von Item 2 beim vorläufigen Fähigkeitsschätzer berechnet.\nItem 3\nDas Vorgehen bei Item 3 ist das gleiche wie bei Items 1 und 2. Die gesuchte Iteminformation ist:\n\\[I_3(0.5) = \\]\n\\[= [\\alpha_3^2 \\frac{P(U_{i3} = 0 | ...)}{P(U_{i3} = 1 | ...)}][\\frac{(P(U_{i3} = 1 | ...) - \\gamma_3)^2}{(1-\\gamma_3)^2}]\\]\nDie Lösungswahrscheinlichkeit ist\n\\[P(U_{i3} = 1 | \\theta_i = 0.5, \\alpha_3, \\beta_3, \\gamma_3)\\]\n\\[= \\gamma_3 + (1 - \\gamma_3) \\cdot \\frac{e^{\\alpha_3 (\\theta_i - \\beta_3)}}{1+ e^{\\alpha_3 (\\theta_i - \\beta_3)}}\\]\n\\[= 0.2 + (1 - 0.2) \\cdot \\frac{e^{0.9 (0.5 - (-0.8))}}{1+ e^{0.9 (0.5 - (-0.8))}}\\]\n\\[\\approx 0.81\\]\nÜberprüfung mit teachIRT:\n\nteachIRT::p_3pl(theta = 0.5, alpha = 0.9, beta = -0.8, gamma = 0.2)\n\n[1] 0.810516\n\n\nDie gerundete Nichtlösewahrscheinlichkeit ist entsprechend\n\\[P(U_{i3} = 0 | \\theta_i = 0.5, \\alpha_3, \\beta_3, \\gamma_3)\\]\n\\[1 - P(U_{i3} = 1 | \\theta_i = 0.5, \\alpha_3, \\beta_3, \\gamma_3)\\]\n\\[\\approx 1 - 0.81 = 0.19\\]\nSetzt man die gerundeten Lösungs- und Nichtlösewahrscheinlichkeiten sowie die Itemparameter in die Informationsfunktion ein, so erhält man die Iteminformation von Item 3 beim vorläufigen Fähigkeitsschätzer:\n\\[I_3(0.5) = \\]\n\\[= [\\alpha_3^2 \\frac{P(U_{i3} = 0 | ...)}{P(U_{i3} = 1 | ...)}][\\frac{(P(U_{i3} = 1 | ...) - \\gamma_3)^2}{(1-\\gamma_3)^2}]\\]\n\\[= [\\alpha_3^2 \\frac{0.19}{0.81}][\\frac{(0.81 - \\gamma_3)^2}{(1-\\gamma_3)^2}]\\]\n\\[= [0.9^2 \\frac{0.19}{0.81}][\\frac{(0.81 - 0.2)^2}{(1-0.2)^2}]\\]\n\\[\\approx 0.11\\]\nDie Überprüfung mit teachIRT bestätigt das Ergebnis:\n\nteachIRT::inf_3pl(theta = 0.5, alpha = 0.9, beta = -0.8, gamma = 0.2)\n\n[1] 0.1102834\n\n\nItem 4\nBei Item 4 ist der Diskriminationsparameter gleich 1 und der Rateparameter gleich 0. Entsprechend vereinfacht sich die Informationsfunktion des 3PL-Modells zur Informationsfunktion des Rasch-Modells. Das haben Sie in einer vorherigen Aufgabe sogar schon selbst gezeigt. Hier können wir dieses Ergebnis verwenden.\n\\[I_4(0.5)\\]\n\\[= P(U_{i4} = 1 | ...) P(U_{i4} = 0 | ...)\\]\n\\[= \\frac{e^{\\theta_i - \\beta_j}}{1 + e^{\\theta_i - \\beta_j}} \\cdot \\frac{1}{1 + e^{\\theta_i - \\beta_j}}\\]\n\\[= \\frac{e^{0.5 - 0.3}}{1 + e^{0.5 - 0.3}} \\cdot \\frac{1}{1 + e^{0.5 - 0.3}}\\]\n\\[\\approx 0.25\\]\nDie Überprüfung mit teachIRT bestätigt das Ergebnis:\n\nteachIRT::inf_rasch(theta = 0.5, beta = 0.3)\n\n[1] 0.2475166\n\n\nSehr Misstrauische können natürlich auch die Informationsfunktion vom 3PL-Modell zur Überprüfung verwenden:\n\nteachIRT::inf_3pl(theta = 0.5, alpha = 1, beta = 0.3, gamma = 0)\n\n[1] 0.2475166\n\n\nDamit liegt nun auch die letzte Iteminformation beim vorläufigen Fähigkeitsschätzer vor.\nVergleich der Items\nWir haben nun die Iteminformation aller Items beim vorläufigen Fähigkeitsschätzer berechnet:\n\\[I_1(0.5) \\approx 0.06\\]\n\\[I_2(0.5) \\approx 0.29\\]\n\\[I_3(0.5) \\approx 0.11\\]\n\\[I_4(0.5) \\approx 0.25\\]\nDen höchsten Informationsgewinn kann man also erwarten, wenn man der Person als nächstes Item 2 vorgibt.\n\n\n\n\nSie befinden sich in Schritt 5. des Algorithmus zum adaptiven Testen. Ist das Abbruchkriterium erfüllt? Verwenden Sie die berechneten Iteminformationen aus der vorherigen Aufgabe.\nAktueller Fähigkeitsschätzer: \\(\\hat{\\theta} = 0.5\\)\nAbbruchkriterium mit \\(95\\%\\) CI beidseitig: \\(|CI_{\\text{unten}} - CI_{\\text{oben}}| &lt;= 2\\)\nBisher dargebotene Items: \\([2, 3, 4]\\)\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nIn dieser Aufgabe müssen wir ein Konfidenzintervall um den vorläufigen Fähigkeitsschätzer berechnen und überprüfen, ob die Intervallänge kleiner oder gleich \\(2\\) ist.\nErneut ist \\(\\hat{\\theta} = 0.5\\) vorgegeben.\nDas Konfidenzintervall berechnet man in der IRT so:\n\\[KI = \\hat{\\theta} \\pm z_{\\alpha/2} \\cdot SE(\\hat{\\theta})\\]\nWir benötigen also noch den z-Wert und den Standardfehler \\(SE(\\hat{\\theta})\\).\nDen z-Wert kann man in einer z-Tabelle nachschlagen. Hier verwende ich die Funktion get_z aus teachIRT:\n\nteachIRT::get_z(ci_alpha = 0.05, ci_direction = \"both\")\n\n    lower     upper \n-1.959964  1.959964 \n\n\nDer gerundete z-Wert beträgt \\(1.96\\).\nDie Formel für den Standardfehler ist\n\\[SE(\\hat{\\theta})\\]\n\\[=\\frac{1}{\\sqrt{I(\\hat{\\theta})}}\\]\nIm Nenner dieser Formel steht die Testinformation. Diese ergibt sich aus der Summe der Itemformationen. Aus der Aufgabe kann man entnehmen, dass bisher die Items 2, 3 und 4 vorgegeben wurden. Entsprechend kann man einsetzen\n\\[=\\frac{1}{\\sqrt{I_2(\\hat{\\theta}) + I_3(\\hat{\\theta}) + I_4(\\hat{\\theta})}}\\]\nDie Informationswerte bei \\(\\hat{\\theta} = 0.5\\) haben Sie schon in der vorherigen Aufgabe berechnet. Diese setze ich hier nun ein:\n\\[=\\frac{1}{\\sqrt{I_2(0.5) + I_3(\\hat{0.5}) + I_4(\\hat{0.5})}}\\]\n\\[=\\frac{1}{\\sqrt{0.29 + 0.11 + 0.25}}\\]\n\\[=\\frac{1}{\\sqrt{0.65}}\\]\nNun haben wir alle Bestandteile, die zur Berechnung des Konfidenzintervalls benötigt werden:\n\\[KI = \\hat{\\theta} \\pm z_{\\alpha/2} \\cdot SE(\\hat{\\theta})\\]\n\\[= 0.5 \\pm 1.96 \\cdot \\frac{1}{\\sqrt{0.65}}\\]\nEs resultiert das Intervall \\([-1.94, 2.94]\\) (konservativ gerundet).\nDas Konfidenzintervall können wir mit teachIRT überprüfen:\n\nteachIRT::ci_3pl(\n  theta = 0.5,\n  alpha = c(1.2, 0.9, 1),\n  beta = c(0.5, -0.8, 0.3),\n  gamma = c(0.1, 0.2, 0),\n  ci_alpha = 0.05,\n  ci_direction = \"both\"\n)\n\n    lower     upper \n-1.926662  2.926662 \n\n\nDie Abweichung ergibt sich erstens dadurch, dass die eingesetzen Testinformationswerte aus der vorherigen Aufgabe bereits gerundet sind und zweitens daraus, dass die Funktion teachIRT::ci_3pl exakt rechnet, statt konservativ zu runden.\nMit dem berechneten Intervall kann man nun überprüfen, ob das Abbruchkriterium erfüllt ist. Wir berechnen daher die Länge des Konfidenzintervalls. Es ist\n\\[|CI_{unten} - CI_{oben}|\\]\n\\[=|-1.94 - 2.93|\\]\n\\[=|-4.87|\\]\n\\[=4.87 &gt; 2\\]\nDas Intervall ist nach Vorgabe der drei Items länger als \\(2\\). Das Abbruchkriterium ist daher noch nicht erfüllt. Der adaptive Testalgorithmus sieht also vor, weitere Items vorzugeben.\n\n\n\nDas waren die letzten Aufgaben zur IRT in diesem Übungsheft. Wenn Sie bis hierhin alle Aufgaben bearbeitet haben, ist das schon ein toller Meilenstein! :-)"
  },
  {
    "objectID": "sections/adaptives_testen/adaptives_testen.html#testinformation",
    "href": "sections/adaptives_testen/adaptives_testen.html#testinformation",
    "title": "Iteminformation und adaptives Testen",
    "section": "",
    "text": "Zwei nützliche Eigenschaften der Item- und Testinformation sind ihre Additivität und ihr direkter Bezug zum Standardfehler einer Personenparameterschätzung.\nIn der Formel zur Testinformation wird die Eigenschaft der Additivität genutzt. Die Iteminformationen an einem Punkt der \\(\\theta\\)-Achse lässt sich für jedes Item einzeln berechnen, \\(I_j(\\theta)\\). Summiert man alle Iteminformationen, so erhält man die Testinformation bei \\(\\theta\\):\n\\[\\begin{equation}\n    I(\\theta) = \\sum_{j = 1}^{m} I_j(\\theta)\n\\end{equation}\\]\n\nEin Test enthält drei Items. Eine Reihe von Informationsschätzern ist bekannt: \\(I_1(-1) = 0.18\\), \\(I_1(0.8) = 0.1\\), \\(I_2(-1) = 0.2\\), \\(I_3(2) = 0.2\\), und \\(I_3(-1) = 0.25\\)\nBerechnen Sie die Information des Tests bei \\(\\theta = -1\\).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(I(-1)\\)\n\\(= I_1(-1) + I_2(-1) + I_3(-1)\\)\n\\(=0.18 + 0.2 + 0.25\\)\n\\(=0.63\\)\n\n\n\nIn der folgenden Formel können Sie sehen, dass der Standardfehler das inverse Konzept zur Iteminformation ist.\n\\[\\begin{equation}\n    SE(\\hat{\\theta}) = \\frac{1}{\\sqrt{I(\\hat{\\theta})}}\n\\end{equation}\\]\nMan kann die Umformung zwischen Information und Standardfehlern in R plotten:\n\n\n\n\n\n\n\n\n\n\nWas passiert mit dem Standardfehler einer Personenparameterschätzung, wenn die Information gegen \\(0\\) (vs. \\(\\infty\\)) geht? Welche Konsequenz hätte das für das Konfidenzintervall um eine Personenparameterschätzung?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWenn die Information gegen \\(0\\) geht, geht der Standardfehler gegen \\(\\infty\\).\nWenn die Information gegen \\(\\infty\\) geht, geht der Standardfehler gegen \\(0\\).\n\n\n\nDer obere Plot der folgenden Abbildung zeigt die Informationsfunktion eines Items im 2PL-Modell mit \\(\\alpha = 1.2\\) und \\(\\beta = 0\\). Im unteren Plot finden Sie die dazugehörigen Standardfehler. Die Standardfehler wurden mit der Umformungsfunktion berechnet.\n\n\n\n\n\n\n\n\n\n\nFinden Sie den Verlauf der Plots plausibel? Versuchen Sie intuitiv nachzuvollziehen, wie die beiden Plots miteinander in Verbindung stehen.\n\nDer Standardfehler um einen Personenparameter kann genutzt werden, um Konfidenzintervalle zu berechnen:\n\\[\\begin{equation}\n    KI = \\hat{\\theta} \\pm z_{\\alpha/2} \\cdot SE(\\hat{\\theta})\n\\end{equation}\\]\n\nDie Testinformation bei \\(\\hat{\\theta} = 1\\) beträgt \\(I(1) = 3\\). Berechnen Sie das zweiseitige \\(95\\%\\) Konfidenzintervall um den Personenparameter.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben:\n\\(\\hat{\\theta} = 1\\)\n\\(I(\\hat{\\theta}) = I(1) = 3\\)\nGesucht:\n\\(KI = \\hat{\\theta} \\pm z_{\\alpha/2} \\cdot SE(\\hat{\\theta})\\)\nAls erstes berechnen wir den Standardfehler:\n\\(SE(\\hat{\\theta}) = \\frac{1}{\\sqrt{I(\\hat{\\theta})}} = \\frac{1}{\\sqrt{3}}\\)\nBei einem zweiseitigen \\(95%\\) Konfidenzintervall rechnen wir mit dem z-Wert \\(1.96\\) bzw. \\(-1.96\\) für die untere Grenze:\n\nteachIRT::get_z(ci_alpha = 0.05, ci_direction = \"both\")\n\n    lower     upper \n-1.959964  1.959964 \n\n\nEingesetzt erhalten wir für die obere Grenze\n\\(KI_o = 1 + 1.96 \\cdot \\frac{1}{\\sqrt{3}} \\approx 2.13\\)\nund für die untere Grenze\n\\(KI_u = 1 - 1.96 \\cdot \\frac{1}{\\sqrt{3}} \\approx -0.13\\)\nZur Ergebniskontrolle können wir teachIRT verwenden:\n\nteachIRT:::ci_general(\n    theta = 1,\n    inf = 3,\n    ci_alpha = 0.05,\n    ci_direction = \"both\"\n)\n\n     lower      upper \n-0.1315857  2.1315857"
  },
  {
    "objectID": "sections/adaptives_testen/adaptives_testen.html#aufgaben-zum-algorithmus-adaptiven-testens",
    "href": "sections/adaptives_testen/adaptives_testen.html#aufgaben-zum-algorithmus-adaptiven-testens",
    "title": "Iteminformation und adaptives Testen",
    "section": "",
    "text": "In der Vorlesung haben Sie einen Algorithmus zum adaptiven Testen kennengelernt (Prozessdiagramm mit lila Kästchen, “Ablauf des adaptiven Tests”). Die nächsten beiden Aufgaben beziehen sich auf diesen Algorithmus. Ich empfehle Ihnen sehr, diese Aufgaben nicht zu überspringen, denn hier kommt noch einmal vieles zusammen, was Sie im Laufe der Veranstaltung über IRT gelernt haben.\nVerwenden Sie zur Bearbeitung beider Aufgaben den folgenden Itempool:\n\n\n\n\\(j\\)\n\\(\\alpha_j\\)\n\\(\\beta_j\\)\n\\(\\gamma_j\\)\n\n\n\n\n1\n\\(0.8\\)\n\\(-1.2\\)\n\\(0.4\\)\n\n\n2\n\\(1.2\\)\n\\(0.5\\)\n\\(0.1\\)\n\n\n3\n\\(0.9\\)\n\\(-0.8\\)\n\\(0.2\\)\n\n\n4\n\\(1.0\\)\n\\(0.3\\)\n\\(0\\)\n\n\n\n\n\n\nSie befinden sich in Schritt 2. des Testalgorithmus (“Wähle und zeige das optimale nächste Item”). Welches Item sollte der adaptive Testalgorithmus als nächstes präsentieren?\nAktueller Fähigkeitsschätzer: \\(\\hat{\\theta}_i = 0.5\\)\n\nDiese Aufgabe benötigt etwas Zeit. Lassen Sie sich nicht verunsichern, wenn Sie hier etwas länger dran arbeiten.\n\n\n\n\n\n\nTipp: Beschreibung des Lösungswegs\n\n\n\n\n\nUm diese Aufgabe zu lösen, müssen Sie für alle vier Items in der Tabelle berechnen, wie groß die Iteminformation bei \\(\\hat{\\theta}_i = 0.5\\) ist. Zu berechnen sind also \\(I_1(0.5)\\), \\(I_2(0.5)\\), \\(I_3(0.5)\\) und \\(I_4(0.5)\\). Dazu können Sie die Formeln für die Iteminformation verwenden. Bei einem der Items können Sie etwas Zeit sparen, wenn Sie erkennen, dass Sie die Formel des Rasch-Modells verwenden können. Bei den anderen Items müssen Sie mit der Formel für das 3PL-Modell arbeiten. Zuletzt können Sie vergleichen, welches der Items den höchsten Informationswert beim vorläufigen Fähigkeitsschätzer aufweist. Dieses Item sollte der adaptive Testalgorithmus als nächstes präsentieren.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDas optimale nächste Item ist in der IRT dasjenige, das beim aktuellen Fähigkeitsschätzer den höchsten Wert in der Informationsfunktion hat.\nEs ist \\(\\hat{\\theta}_i = 0.5\\) gegeben.\nWir können die Parameter im vorgegebenen Itempool verwenden, um die Iteminformation beim gegebenen vorläufigen Fähigkeitsschätzer zu berechnen.\nItem 1\nZunächst lohnt sich der Blick auf die Itemparameter. Item 1 hat einen Diskriminationsparameter, der ungleich 1 ist und einen Rateparameter, der ungleich Null ist. Entsprechend muss man hier die Informationsfunktion des 3PL-Modells verwenden. Los geht’s:\n\\[I_1(0.5)\\]\n\\[= [\\alpha_1^2 \\frac{P(U_{i1} = 0 | ...)}{P(U_{i1} = 1 | ...)}][\\frac{(P(U_{i1} = 1 | ...) - \\gamma_1)^2}{(1-\\gamma_1)^2}]\\]\nDie Formel erfordert eine Lösungwahrscheinlichkeit. Hier müssen wir die Formel aus dem 3PL-Modell verwenden.\n\\[P(U_{i1} = 1 | \\theta_i = 0.5, \\alpha_1, \\beta_1, \\gamma_1)\\]\n\\[= \\gamma_1 + (1 - \\gamma_1) \\cdot \\frac{e^{\\alpha_1 (\\theta_i - \\beta_1)}}{1+ e^{\\alpha_1 (\\theta_i - \\beta_1)}}\\]\n\\[= 0.4 + (1 - 0.4) \\cdot \\frac{e^{0.8 (0.5 - (-1.2))}}{1+ e^{0.8 (0.5 - (-1.2))}}\\]\n\\[\\approx 0.877\\]\nDieses Zwischenergebnis runde ich der Übersicht halber. Es lohnt sich natürlich, die berechnete Lösungswahrscheinlichkeit mit teachIRT zu überprüfen:\n\nteachIRT::p_3pl(theta = 0.5, alpha = 0.8, beta = -1.2, gamma = 0.4)\n\n[1] 0.8774558\n\n\nDas Ergebnis scheint zu stimmen. Aus der eben berechneten Lösungswahrscheinlichkeit ergibt sich leicht die Nichtlösewahrscheinlichkeit des Items.\n\\[P(U_{i1} = 0 | \\theta_i = 0.5, \\alpha_1, \\beta_1, \\gamma_1)\\]\n\\[= 1 - P(U_{i1} = 1 | \\theta_i = 0.5, \\alpha_1, \\beta_1, \\gamma_1)\\]\n\\[\\approx 1 - 0.877 = 0.123\\]\nAuch dieses Zwischenergebnis können wir schnell mit teachIRT überprüfen:\n\n1 - teachIRT::p_3pl(theta = 0.5, alpha = 0.8, beta = -1.2, gamma = 0.4)\n\n[1] 0.1225442\n\n\nDer Rundungsfehler tradiert sich natürlich auch in die Nichtlösewahrscheinlichkeit.\nDie gerundete Löse- und Nichlösewahrscheinlichkeit kann man nun in die Informationsfunktion des 3PL-Modells einsetzen:\n\\[I_1(0.5)\\]\n\\[= [\\alpha_1^2 \\frac{P(U_{i1} = 0 | ...)}{P(U_{i1} = 1 | ...)}][\\frac{(P(U_{i1} = 1 | ...) - \\gamma_1)^2}{(1-\\gamma_1)^2}]\\]\n\\[= [\\alpha_1^2 \\frac{0.123}{0.877}][\\frac{(0.877 - \\gamma_1)^2}{(1-\\gamma_1)^2}]\\]\n(Löse- und Nichtlösewahrscheinlichkeiten einsetzen)\n\\[= [0.8^2 \\frac{0.123}{0.877}][\\frac{(0.877 - 0.4)^2}{(1-0.4)^2}]\\]\n(Itemparameter einsetzen)\n\\[\\approx 0.06\\]\nDas Endergebnis kann man wieder mit teachIRT überprüfen.\n\nteachIRT::inf_3pl(theta = 0.5, alpha = 0.8, beta = -1.2, gamma = 0.4)\n\n[1] 0.05659933\n\n\nDamit haben wir die Information von Item 1 beim vorläufigen Fähigkeitsschätzer \\(\\hat{\\theta}_i = 0.5\\) berechnet.\nItem 2\nWeiter geht es mit Item 2. Auch hier liegen ein Diskriminationsparameter ungleich 1 und ein Rateparameter ungleich 0 vor. Entsprechend muss man auch hier die Informationsfunktion des 3PL-Modells verwenden. Die Schritte sind also die gleichen wie bei Item 1, nur die Itemparameter ändern sich.\n\\[I_2(0.5) =\\]\n\\[= [\\alpha_2^2 \\frac{P(U_{i2} = 0 | ...)}{P(U_{i2} = 1 | ...)}][\\frac{(P(U_{i2} = 1 | ...) - \\gamma_2)^2}{(1-\\gamma_2)^2}]\\]\nWieder ist eine Lösungswahrscheinlichkeit erforderlich. Diesmal hat die Lösungswahrscheinlichkeit eine viel schönere Form und wir erhalten auch ohne Taschenrechner ein exaktes Ergebnis:\n\\[P(U_{i2} = 1 | \\theta_i = 0.5, \\alpha_2, \\beta_2, \\gamma_2)\\]\n\\[= \\gamma_2 + (1 - \\gamma_2) \\cdot \\frac{e^{\\alpha_2 (\\theta_i - \\beta_2)}}{1+ e^{\\alpha_2 (\\theta_i - \\beta_2)}}\\]\n\\[= 0.1 + (1 - 0.1) \\cdot \\frac{e^{1.2 (0.5 - 0.5)}}{1+ e^{1.2 (0.5 - 0.5)}}\\]\n\\[= 0.1 + 0.9 \\cdot \\frac{1}{2}\\]\n\\[= 0.1 + \\frac{0.9}{2}\\]\n\\[= 0.1 + 0.45\\]\n\\[= 0.55\\]\nDie Überprüfung mit teachIRT bestätigt das Ergebnis:\n\nteachIRT::p_3pl(theta = 0.5, alpha = 1.2, beta = 0.5, gamma = 0.1)\n\n[1] 0.55\n\n\nDie exakte Nichtlösewahrscheinlichkeit beträgt\n\\[P(U_{i2} = 0 | \\theta_i = 0.5, \\alpha_2, \\beta_2, \\gamma_2) = 1 - 0.55 = 0.45\\]\n\n1 - teachIRT::p_3pl(theta = 0.5, alpha = 1.2, beta = 0.5, gamma = 0.1)\n\n[1] 0.45\n\n\nDie Lösungs- und Nichlösewahrscheinlichkeiten kann man nun in die Formel für die Iteminformation einsetzen:\n\\[I_2(0.5)\\]\n\\[= [\\alpha_2^2 \\frac{P(U_{i2} = 0 | ...)}{P(U_{i2} = 1 | ...)}][\\frac{(P(U_{i2} = 1 | ...) - \\gamma_2)^2}{(1-\\gamma_2)^2}]\\]\n\\[= [\\alpha_2^2 \\frac{0.45}{0.55}][\\frac{(0.55 - \\gamma_2)^2}{(1-\\gamma_2)^2}]\\]\n\\[= [1.2^2 \\frac{0.45}{0.55}][\\frac{(0.55 - 0.1)^2}{(1-0.1)^2}]\\]\n\\[\\approx 0.29\\]\n\nteachIRT::inf_3pl(theta = 0.5, alpha = 1.2, beta = 0.5, gamma = 0.1)\n\n[1] 0.2945455\n\n\nDamit haben wir auch die Information von Item 2 beim vorläufigen Fähigkeitsschätzer berechnet.\nItem 3\nDas Vorgehen bei Item 3 ist das gleiche wie bei Items 1 und 2. Die gesuchte Iteminformation ist:\n\\[I_3(0.5) = \\]\n\\[= [\\alpha_3^2 \\frac{P(U_{i3} = 0 | ...)}{P(U_{i3} = 1 | ...)}][\\frac{(P(U_{i3} = 1 | ...) - \\gamma_3)^2}{(1-\\gamma_3)^2}]\\]\nDie Lösungswahrscheinlichkeit ist\n\\[P(U_{i3} = 1 | \\theta_i = 0.5, \\alpha_3, \\beta_3, \\gamma_3)\\]\n\\[= \\gamma_3 + (1 - \\gamma_3) \\cdot \\frac{e^{\\alpha_3 (\\theta_i - \\beta_3)}}{1+ e^{\\alpha_3 (\\theta_i - \\beta_3)}}\\]\n\\[= 0.2 + (1 - 0.2) \\cdot \\frac{e^{0.9 (0.5 - (-0.8))}}{1+ e^{0.9 (0.5 - (-0.8))}}\\]\n\\[\\approx 0.81\\]\nÜberprüfung mit teachIRT:\n\nteachIRT::p_3pl(theta = 0.5, alpha = 0.9, beta = -0.8, gamma = 0.2)\n\n[1] 0.810516\n\n\nDie gerundete Nichtlösewahrscheinlichkeit ist entsprechend\n\\[P(U_{i3} = 0 | \\theta_i = 0.5, \\alpha_3, \\beta_3, \\gamma_3)\\]\n\\[1 - P(U_{i3} = 1 | \\theta_i = 0.5, \\alpha_3, \\beta_3, \\gamma_3)\\]\n\\[\\approx 1 - 0.81 = 0.19\\]\nSetzt man die gerundeten Lösungs- und Nichtlösewahrscheinlichkeiten sowie die Itemparameter in die Informationsfunktion ein, so erhält man die Iteminformation von Item 3 beim vorläufigen Fähigkeitsschätzer:\n\\[I_3(0.5) = \\]\n\\[= [\\alpha_3^2 \\frac{P(U_{i3} = 0 | ...)}{P(U_{i3} = 1 | ...)}][\\frac{(P(U_{i3} = 1 | ...) - \\gamma_3)^2}{(1-\\gamma_3)^2}]\\]\n\\[= [\\alpha_3^2 \\frac{0.19}{0.81}][\\frac{(0.81 - \\gamma_3)^2}{(1-\\gamma_3)^2}]\\]\n\\[= [0.9^2 \\frac{0.19}{0.81}][\\frac{(0.81 - 0.2)^2}{(1-0.2)^2}]\\]\n\\[\\approx 0.11\\]\nDie Überprüfung mit teachIRT bestätigt das Ergebnis:\n\nteachIRT::inf_3pl(theta = 0.5, alpha = 0.9, beta = -0.8, gamma = 0.2)\n\n[1] 0.1102834\n\n\nItem 4\nBei Item 4 ist der Diskriminationsparameter gleich 1 und der Rateparameter gleich 0. Entsprechend vereinfacht sich die Informationsfunktion des 3PL-Modells zur Informationsfunktion des Rasch-Modells. Das haben Sie in einer vorherigen Aufgabe sogar schon selbst gezeigt. Hier können wir dieses Ergebnis verwenden.\n\\[I_4(0.5)\\]\n\\[= P(U_{i4} = 1 | ...) P(U_{i4} = 0 | ...)\\]\n\\[= \\frac{e^{\\theta_i - \\beta_j}}{1 + e^{\\theta_i - \\beta_j}} \\cdot \\frac{1}{1 + e^{\\theta_i - \\beta_j}}\\]\n\\[= \\frac{e^{0.5 - 0.3}}{1 + e^{0.5 - 0.3}} \\cdot \\frac{1}{1 + e^{0.5 - 0.3}}\\]\n\\[\\approx 0.25\\]\nDie Überprüfung mit teachIRT bestätigt das Ergebnis:\n\nteachIRT::inf_rasch(theta = 0.5, beta = 0.3)\n\n[1] 0.2475166\n\n\nSehr Misstrauische können natürlich auch die Informationsfunktion vom 3PL-Modell zur Überprüfung verwenden:\n\nteachIRT::inf_3pl(theta = 0.5, alpha = 1, beta = 0.3, gamma = 0)\n\n[1] 0.2475166\n\n\nDamit liegt nun auch die letzte Iteminformation beim vorläufigen Fähigkeitsschätzer vor.\nVergleich der Items\nWir haben nun die Iteminformation aller Items beim vorläufigen Fähigkeitsschätzer berechnet:\n\\[I_1(0.5) \\approx 0.06\\]\n\\[I_2(0.5) \\approx 0.29\\]\n\\[I_3(0.5) \\approx 0.11\\]\n\\[I_4(0.5) \\approx 0.25\\]\nDen höchsten Informationsgewinn kann man also erwarten, wenn man der Person als nächstes Item 2 vorgibt.\n\n\n\n\nSie befinden sich in Schritt 5. des Algorithmus zum adaptiven Testen. Ist das Abbruchkriterium erfüllt? Verwenden Sie die berechneten Iteminformationen aus der vorherigen Aufgabe.\nAktueller Fähigkeitsschätzer: \\(\\hat{\\theta} = 0.5\\)\nAbbruchkriterium mit \\(95\\%\\) CI beidseitig: \\(|CI_{\\text{unten}} - CI_{\\text{oben}}| &lt;= 2\\)\nBisher dargebotene Items: \\([2, 3, 4]\\)\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nIn dieser Aufgabe müssen wir ein Konfidenzintervall um den vorläufigen Fähigkeitsschätzer berechnen und überprüfen, ob die Intervallänge kleiner oder gleich \\(2\\) ist.\nErneut ist \\(\\hat{\\theta} = 0.5\\) vorgegeben.\nDas Konfidenzintervall berechnet man in der IRT so:\n\\[KI = \\hat{\\theta} \\pm z_{\\alpha/2} \\cdot SE(\\hat{\\theta})\\]\nWir benötigen also noch den z-Wert und den Standardfehler \\(SE(\\hat{\\theta})\\).\nDen z-Wert kann man in einer z-Tabelle nachschlagen. Hier verwende ich die Funktion get_z aus teachIRT:\n\nteachIRT::get_z(ci_alpha = 0.05, ci_direction = \"both\")\n\n    lower     upper \n-1.959964  1.959964 \n\n\nDer gerundete z-Wert beträgt \\(1.96\\).\nDie Formel für den Standardfehler ist\n\\[SE(\\hat{\\theta})\\]\n\\[=\\frac{1}{\\sqrt{I(\\hat{\\theta})}}\\]\nIm Nenner dieser Formel steht die Testinformation. Diese ergibt sich aus der Summe der Itemformationen. Aus der Aufgabe kann man entnehmen, dass bisher die Items 2, 3 und 4 vorgegeben wurden. Entsprechend kann man einsetzen\n\\[=\\frac{1}{\\sqrt{I_2(\\hat{\\theta}) + I_3(\\hat{\\theta}) + I_4(\\hat{\\theta})}}\\]\nDie Informationswerte bei \\(\\hat{\\theta} = 0.5\\) haben Sie schon in der vorherigen Aufgabe berechnet. Diese setze ich hier nun ein:\n\\[=\\frac{1}{\\sqrt{I_2(0.5) + I_3(\\hat{0.5}) + I_4(\\hat{0.5})}}\\]\n\\[=\\frac{1}{\\sqrt{0.29 + 0.11 + 0.25}}\\]\n\\[=\\frac{1}{\\sqrt{0.65}}\\]\nNun haben wir alle Bestandteile, die zur Berechnung des Konfidenzintervalls benötigt werden:\n\\[KI = \\hat{\\theta} \\pm z_{\\alpha/2} \\cdot SE(\\hat{\\theta})\\]\n\\[= 0.5 \\pm 1.96 \\cdot \\frac{1}{\\sqrt{0.65}}\\]\nEs resultiert das Intervall \\([-1.94, 2.94]\\) (konservativ gerundet).\nDas Konfidenzintervall können wir mit teachIRT überprüfen:\n\nteachIRT::ci_3pl(\n  theta = 0.5,\n  alpha = c(1.2, 0.9, 1),\n  beta = c(0.5, -0.8, 0.3),\n  gamma = c(0.1, 0.2, 0),\n  ci_alpha = 0.05,\n  ci_direction = \"both\"\n)\n\n    lower     upper \n-1.926662  2.926662 \n\n\nDie Abweichung ergibt sich erstens dadurch, dass die eingesetzen Testinformationswerte aus der vorherigen Aufgabe bereits gerundet sind und zweitens daraus, dass die Funktion teachIRT::ci_3pl exakt rechnet, statt konservativ zu runden.\nMit dem berechneten Intervall kann man nun überprüfen, ob das Abbruchkriterium erfüllt ist. Wir berechnen daher die Länge des Konfidenzintervalls. Es ist\n\\[|CI_{unten} - CI_{oben}|\\]\n\\[=|-1.94 - 2.93|\\]\n\\[=|-4.87|\\]\n\\[=4.87 &gt; 2\\]\nDas Intervall ist nach Vorgabe der drei Items länger als \\(2\\). Das Abbruchkriterium ist daher noch nicht erfüllt. Der adaptive Testalgorithmus sieht also vor, weitere Items vorzugeben.\n\n\n\nDas waren die letzten Aufgaben zur IRT in diesem Übungsheft. Wenn Sie bis hierhin alle Aufgaben bearbeitet haben, ist das schon ein toller Meilenstein! :-)"
  },
  {
    "objectID": "sections/rechenkompetenzen/rechenkompetenzen.html",
    "href": "sections/rechenkompetenzen/rechenkompetenzen.html",
    "title": "Grundlegende Rechenkompetenzen",
    "section": "",
    "text": "Um die Übungsaufgaben in diesem Heft zu bearbeiten, ist es notwendig eine Reihe grundlegender Rechenkompetenzen zu beherrschen. Auf dem ersten Blick wirken die hier gesammelten Zusammenhänge auf Sie eventuell etwas zusammengewürfelt. Im Laufe der Veranstaltung werden Sie aber feststellen, dass Sie auf die hier vermittelten Kompetenzen immer wieder zurückgreifen müssen.\nWenn Sie sich in diesem Bereich sicher fühlen, können Sie diesen Abschnitt gerne überspringen. Falls Sie aus der Übung gekommen sind, lohnt es sich aber, Ihr Wissen mit den folgenden Aufgaben aufzufrischen und Wissenslücken zu füllen.\n\n\nIn der Prüfungs müssen Sie, wenn nicht anders verlangt, kaufmännisch auf zwei Nachkommastellen runden. Da sich an dieser Stelle immer wieder vermeidbare Fehler einschleichen, beginnen wir zur Erinnerung mit einer Aufgabe zum kaufmännischen Runden.\n\nRunden Sie auf zwei Nachkommastellen. Wir verwenden einen Punkt als Dezimaltrennzeichen.\n\n\\(23.4567\\)\n\\(58.295\\)\n\\(0.053\\)\n\\(12.599\\)\n\\(74.125\\)\n\\(25.1235\\)\n\\(P(X = 1) = 0.835\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\\(23.46\\)\n\\(58.30\\)\n\\(0.05\\)\n\\(12.60\\)\n\\(74.13\\)\n\\(25.12\\)\n\\(P(X = 1) = .84\\)\n\nTipp: {r} round(x, 2) rundet nicht kaufmännisch. Sie können diese Funktion daher nicht zur Ergebniskontrolle verwenden.\n\n\n\nVielleicht haben Sie die Wahrscheinlichkeit \\(P(X=1)=0.835\\) zunächst in eine Prozentzahl umgerechnet und anschließend gerundet. In diesem Fall ergibt sich \\(83.50\\%\\). Eine andere Möglichkeit besteht darin, die Wahrscheinlichkeit zuerst auf zwei Nachkommastellen zu runden und erst dann in Prozent umzurechnen – das führt zu \\(84\\%\\).\nBeide Vorgehensweisen sind rechnerisch nicht per se falsch. In der Stochastik ist es jedoch üblich, Wahrscheinlichkeiten nicht neu zu skalieren, sondern als Zahl zwischen \\(0\\) und \\(1\\) anzugeben. Darüber hinaus entspricht eine auf zwei Nachkommastellen gerundete Prozentzahl, z.B. \\(13.56\\%\\), einer Angabe von Wahrscheinlichkeiten auf vier Nachkommastellen, hier \\(.1356\\). Eine so genaue Angabe ist in den meisten psychologischen Anwendungen nicht sinnvoll.\n\n\n\nDiese Übung ist vor allem als Erinnerung an die ‘Punkt-vor-Strich’-Regel zu verstehen. Wir wissen natürlich, dass das für Sie ein uralter Hut ist. Leider gehen in der Prüfung trotzdem viele Punkte verloren, da Studierende diese Konvention vergessen.\n\nBerechnen Sie ohne Taschenrechner\n\n\\(1 + 4 ((6-8.2)-(-8-3.8))\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\\(39.4\\)\n\n\n\n\nBei Brüchen muss man besonders aufpassen. Hier eine Übung mit dem Taschenrechner.\n\nBerechnen Sie mit dem Taschenrechner\n\n\\(\\frac{34 + 65}{96}\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\\(1.03\\)\n\nWenn Sie \\(34.68\\) herausbekommen, haben Sie vermutlich vergessen Klammern zu setzen.\n\n\n\n\n\n\nIn dieser Veranstaltung kommen Sie weitestgehend mit drei Zahlenmengen aus. Bei Indizes (z.B. das \\(i\\) in \\(x_i\\)) benötigen Sie natürliche Zahlen:\n\nNatürliche Zahlen bezeichnet man mit \\(\\mathbb{N}\\). Das sind die Zahlen \\(1, 2, 3, ...\\).\nNatürliche Zahlen inklusive der Null bezeichnet man mit \\(\\mathbb{N}_0\\). Das sind die Zahlen \\(0, 1, 2, 3, ...\\).\n\nBei Parametern (z.B. Personenfähigkeiten im Rasch-Modell) arbeiten Sie oft mit reellen Zahlen.\n\nReelle Zahlen \\(\\mathbb{R}\\): Die lückenlose Zahlengerade\n\nDiese Bezeichnungen sollten Sie auswendig kennen.\n\n\n\n\n\nDie Exponentialfunktion wird Ihnen in der Item Response Theorie (IRT) noch oft begegnen.\n\nBerechnen Sie\n\n\\(e^1 - e^0\\)\n\\(exp(1) - exp(0)\\)\n\nAllgemein gilt \\(x^0 = 1\\) für alle reellen Zahlen ungleich \\(0\\). Der Fall \\(0^0\\) ist in der Programmiersprache R ebenfalls als \\(1\\) hinterlegt, kann je nach Konvention aber auch anders definiert sein.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\\(1.72\\)\n\\(1.72\\)\n\nBei a. und b. handelt es sich lediglich um unterschiedliche Schreibweisen.\n\n\n\n\n\n\nDie Funktion mit der Vorschrift \\(f(x) = \\frac{e^x}{1 + e^x}\\) für alle reellwertigen \\(x\\) nennt man logistische Funktion. Die logistische Funktion transformiert reelle Zahlen (x-Achse im Plot) in Werte zwischen 0 und 1 (z.B. Wahrscheinlichkeiten; y-Achse im Plot). Formal drückt man das so aus: \\(f: \\mathbb{R} \\rightarrow (0, 1)\\). Die logistische Funktion wird Ihnen in der IRT noch oft begegnen.\n\n\n\n\n\n\n\n\n\nMit der Gleichung\n\\(\\frac{e^x}{1 + e^x} = \\frac{1}{1 + e^{-x}}\\)\nkönnen Sie bei Aufgaben zur IRT oft Zeit sparen, da Sie \\(x\\) (hier steht später ein aufwendigerer Ausdruck) nur einmal im Taschenrechner eingeben müssen.\nFür das Modul reicht es völlig aus den Zusammenhang auswendig zu lernen. Als Zusatzübung (optional), können Sie versuchen, die Gleichheit der Ausdrücke selbst zu zeigen.\n\nStellen Sie \\(\\frac{e^x}{1 + e^x}\\) nach \\(\\frac{1}{1 + e^{-x}}\\) um.\n\nSollte Ihre letzte Begegnung mit solchen Aufgaben schon etwas länger her sein, wird Ihnen diese Aufgabe vermutlich sehr schwer fallen. Das ist überhaupt nicht schlimm. Versuchen Sie es zuerst mit den Tipps. Falls das nicht klappt, können Sie versuchen, die Schritte mit der Lösung nachzuvollziehen.\n\n\n\n\n\n\nTipp\n\n\n\n\n\nMit diesen Schritten gelangen Sie zum Ziel:\n\n\\(e^x\\) ausklammern\n\\(e^x\\) kürzen\nNutzen, dass \\(e^0 = 1\\) ist\nRechenregel \\(\\frac{e^m}{e^n} = e^{m-n}\\)\nKommutativtesetz anwenden\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(\\frac{e^x}{1 + e^x}\\)\n\\(= \\frac{e^x}{e^x(\\frac{1}{e^x} + 1)}\\) (\\(e^x\\) ausklammern)\n\\(= \\frac{1}{\\frac{1}{e^x} + 1}\\) (\\(e^x\\) kürzen)\n\\(= \\frac{1}{\\frac{e^0}{e^x} + 1}\\) (nutze, dass \\(e^0 = 1\\) ist)\n\\(= \\frac{1}{e^{0-x} + 1}\\) (Rechenregel \\(\\frac{e^m}{e^n} = e^{m-n}\\))\n\\(= \\frac{1}{e^{-x} + 1}\\)\n\\(= \\frac{1}{1 + e^{-x}}\\) (Kommutativtesetz)\n\n\n\n\n\n\n\nDen Umgang mit Summenzeichen müssen Sie als Psycholog:innen sicher beherrschen. Summen spielen insbesondere bei Operationen auf Datensätzen eine zentrale Rolle und werden Ihnen in der Vorlesung und dem Übungsheft noch oft begegnen. Daher legen wir hier einen besonderen Wert darauf, dass Sie mit den Symbolen \\(\\sum\\) (Summenzeichen) und \\(\\prod\\) (Produktzeichen) sicher umgehen können.\n\nBerechnen Sie\n\n\\(\\sum_{n = 1}^{3} n\\)\n\\(\\sum_{m = 2}^{4} m^2\\)\n\\(\\sum_{l = 3}^{6} (2 + l)\\)\n\\(\\sum_{i = 1}^{5} x_i\\), mit \\(\\boldsymbol{x} = [1, 3, 4, 3, 0]\\)\n\\(\\sum_{l=0}^{2}\\sum_{k=0}^{l}(2k)\\)\n\\(\\sum_{j = 1}^{2} \\sum_{j' = 1}^{3} (x_j + y_{j'})\\), mit \\(\\boldsymbol{x} = [1, 4, 3, 8]\\), \\(\\boldsymbol{y} = [3, 0, 1]\\)\n\\(\\sum_{i = 51}^{100}x_i + \\sum_{i = 20}^{50}x_i\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\\(\\sum_{n=1}^{3} n = 1+2+3 = 6\\)\n\\(\\sum_{m=2}^{4} m^2 = 2^2+3^2+4^2 = 4+9+16 = 29\\)\n\\(\\sum_{l=3}^{6} (2+l) = \\sum_{l=3}^{6}2 + \\sum_{l=3}^{6}l = 8 + (3+4+5+6) = 8+18 = 26\\)\n\\(\\sum_{i=1}^{5} x_i = 1+3+4+3+0 = 11\\)\n\\(\\sum_{l=0}^{2}\\sum_{k=0}^{l}(2k) = (0) + (0+2) + (0+2+4) = 8\\)\n\\(\\sum_{j=1}^{2}\\sum_{j'=1}^{3} (x_j + y_{j'})\n= \\sum_{j=1}^{2} \\big(3x_j + \\sum_{j'=1}^{3}y_{j'}\\big)\n= \\sum_{j=1}^{2} (3x_j + 4)\n= 3(1+4) + 8 = 23\\)\n\\(\\sum_{i=51}^{100}x_i + \\sum_{i=20}^{50}x_i = \\sum_{i=20}^{100}x_i\\)\n\n\n\n\n\n\n\nDas multiplikative Analogon zum Summenzeichen ist das Produktzeichen.\n\nBerechnen Sie\n\n\\(\\prod_{i = 1}^{2} i\\)\n\\(\\prod_{i = 1}^{3} (i + 2)\\)\n\\(\\prod_{n = 2}^{5} x_n\\), mit \\(\\boldsymbol{x} = [4, 2, 1, 3, 4]\\)\n\\(\\prod_{i = 1}^{100} log(i)\\)\n\\(\\prod_{j = 2}^{3} \\prod_{k = 1}^{2} (j + k)\\)\n\\(\\prod_{i = 1}^{2}\\prod_{n=2}^{3}(i + n)\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\\(\\prod_{i=1}^{2} i = 1 \\cdot 2 = 2\\)\n\\(\\prod_{i=1}^{3} (i+2) = (1+2)(2+2)(3+2) = 3 \\cdot 4 \\cdot 5 = 60\\)\n\\(\\prod_{n=2}^{5} x_n = x_2 \\cdot x_3 \\cdot x_4 \\cdot x_5 = 2 \\cdot 1 \\cdot 3 \\cdot 4 = 24\\)\n\\(\\prod_{i=1}^{100} \\log(i) = 0\\)\n\\(\\prod_{j=2}^{3}\\prod_{k=1}^{2}(j+k)\n= ((2+1)(2+2)) \\cdot ((3+1)(3+2))\n= (3 \\cdot 4)(4 \\cdot 5)\n= 12 \\cdot 20 = 240\\)\n\\(\\prod_{i=1}^{2}\\prod_{n=2}^{3}(i+n)\n= ((1+2)(1+3)) \\cdot ((2+2)(2+3))\n= (3 \\cdot 4)(4 \\cdot 5)\n= 12 \\cdot 20 = 240\\)\n\n\n\n\n\n\n\nMan kann Summen- und Produktzeichen auch kombinieren.\n\n\n\\(\\sum_{j = 1}^{3} \\prod_{i = 1}^{j} i\\)\n\\(\\prod_{i = 1}^{2} \\sum_{j = i}^{3} j\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\\(\\sum_{j=1}^{3}\\prod_{i=1}^{j} i\n= (1) + (1 \\cdot 2) + (1 \\cdot 2 \\cdot 3)\n= 1 + 2 + 6 = 9\\)\n\\(\\prod_{i=1}^{2}\\sum_{j=i}^{3} j\n= \\left(\\sum_{j=1}^{3} j\\right) \\cdot \\left(\\sum_{j=2}^{3} j\\right)\n= (1+2+3)(2+3)\n= 6 \\cdot 5 = 30\\)\n\n\n\n\n\n\n\nIn diesem Abschnitt geht es vor allem um Notation, die Ihnen im Übungsheft noch begegnen wird.\n\nBeschreiben Sie in eigenen Worten\n\n\\(P(A \\cap B) = P(A)P(B)\\)\n\\(P(A|B)\\)\n\\(X \\sim N(50, 10)\\)\n\\(Y \\sim U(10, 50)\\)\n\n\n\n\n\nDieses Thema wird ausführlich im Kapitel zu psychometrischen Datenmatrizen eingeführt. Die Aufgaben sind an keinerlei Voraussetzungen geknüpft. Wenn Sie vorarbeiten möchten, könnten Sie diesen Abschnitt bereits bearbeiten."
  },
  {
    "objectID": "sections/rechenkompetenzen/rechenkompetenzen.html#kaufmännisches-runden",
    "href": "sections/rechenkompetenzen/rechenkompetenzen.html#kaufmännisches-runden",
    "title": "Grundlegende Rechenkompetenzen",
    "section": "",
    "text": "In der Prüfungs müssen Sie, wenn nicht anders verlangt, kaufmännisch auf zwei Nachkommastellen runden. Da sich an dieser Stelle immer wieder vermeidbare Fehler einschleichen, beginnen wir zur Erinnerung mit einer Aufgabe zum kaufmännischen Runden.\n\nRunden Sie auf zwei Nachkommastellen. Wir verwenden einen Punkt als Dezimaltrennzeichen.\n\n\\(23.4567\\)\n\\(58.295\\)\n\\(0.053\\)\n\\(12.599\\)\n\\(74.125\\)\n\\(25.1235\\)\n\\(P(X = 1) = 0.835\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\\(23.46\\)\n\\(58.30\\)\n\\(0.05\\)\n\\(12.60\\)\n\\(74.13\\)\n\\(25.12\\)\n\\(P(X = 1) = .84\\)\n\nTipp: {r} round(x, 2) rundet nicht kaufmännisch. Sie können diese Funktion daher nicht zur Ergebniskontrolle verwenden.\n\n\n\nVielleicht haben Sie die Wahrscheinlichkeit \\(P(X=1)=0.835\\) zunächst in eine Prozentzahl umgerechnet und anschließend gerundet. In diesem Fall ergibt sich \\(83.50\\%\\). Eine andere Möglichkeit besteht darin, die Wahrscheinlichkeit zuerst auf zwei Nachkommastellen zu runden und erst dann in Prozent umzurechnen – das führt zu \\(84\\%\\).\nBeide Vorgehensweisen sind rechnerisch nicht per se falsch. In der Stochastik ist es jedoch üblich, Wahrscheinlichkeiten nicht neu zu skalieren, sondern als Zahl zwischen \\(0\\) und \\(1\\) anzugeben. Darüber hinaus entspricht eine auf zwei Nachkommastellen gerundete Prozentzahl, z.B. \\(13.56\\%\\), einer Angabe von Wahrscheinlichkeiten auf vier Nachkommastellen, hier \\(.1356\\). Eine so genaue Angabe ist in den meisten psychologischen Anwendungen nicht sinnvoll."
  },
  {
    "objectID": "sections/rechenkompetenzen/rechenkompetenzen.html#operatorrangfolge",
    "href": "sections/rechenkompetenzen/rechenkompetenzen.html#operatorrangfolge",
    "title": "Grundlegende Rechenkompetenzen",
    "section": "",
    "text": "Diese Übung ist vor allem als Erinnerung an die ‘Punkt-vor-Strich’-Regel zu verstehen. Wir wissen natürlich, dass das für Sie ein uralter Hut ist. Leider gehen in der Prüfung trotzdem viele Punkte verloren, da Studierende diese Konvention vergessen.\n\nBerechnen Sie ohne Taschenrechner\n\n\\(1 + 4 ((6-8.2)-(-8-3.8))\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\\(39.4\\)\n\n\n\n\nBei Brüchen muss man besonders aufpassen. Hier eine Übung mit dem Taschenrechner.\n\nBerechnen Sie mit dem Taschenrechner\n\n\\(\\frac{34 + 65}{96}\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\\(1.03\\)\n\nWenn Sie \\(34.68\\) herausbekommen, haben Sie vermutlich vergessen Klammern zu setzen."
  },
  {
    "objectID": "sections/rechenkompetenzen/rechenkompetenzen.html#zahlenmengen",
    "href": "sections/rechenkompetenzen/rechenkompetenzen.html#zahlenmengen",
    "title": "Grundlegende Rechenkompetenzen",
    "section": "",
    "text": "In dieser Veranstaltung kommen Sie weitestgehend mit drei Zahlenmengen aus. Bei Indizes (z.B. das \\(i\\) in \\(x_i\\)) benötigen Sie natürliche Zahlen:\n\nNatürliche Zahlen bezeichnet man mit \\(\\mathbb{N}\\). Das sind die Zahlen \\(1, 2, 3, ...\\).\nNatürliche Zahlen inklusive der Null bezeichnet man mit \\(\\mathbb{N}_0\\). Das sind die Zahlen \\(0, 1, 2, 3, ...\\).\n\nBei Parametern (z.B. Personenfähigkeiten im Rasch-Modell) arbeiten Sie oft mit reellen Zahlen.\n\nReelle Zahlen \\(\\mathbb{R}\\): Die lückenlose Zahlengerade\n\nDiese Bezeichnungen sollten Sie auswendig kennen."
  },
  {
    "objectID": "sections/rechenkompetenzen/rechenkompetenzen.html#rechnen-mit-exponentialfunktionen",
    "href": "sections/rechenkompetenzen/rechenkompetenzen.html#rechnen-mit-exponentialfunktionen",
    "title": "Grundlegende Rechenkompetenzen",
    "section": "",
    "text": "Die Exponentialfunktion wird Ihnen in der Item Response Theorie (IRT) noch oft begegnen.\n\nBerechnen Sie\n\n\\(e^1 - e^0\\)\n\\(exp(1) - exp(0)\\)\n\nAllgemein gilt \\(x^0 = 1\\) für alle reellen Zahlen ungleich \\(0\\). Der Fall \\(0^0\\) ist in der Programmiersprache R ebenfalls als \\(1\\) hinterlegt, kann je nach Konvention aber auch anders definiert sein.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\\(1.72\\)\n\\(1.72\\)\n\nBei a. und b. handelt es sich lediglich um unterschiedliche Schreibweisen.\n\n\n\n\n\n\nDie Funktion mit der Vorschrift \\(f(x) = \\frac{e^x}{1 + e^x}\\) für alle reellwertigen \\(x\\) nennt man logistische Funktion. Die logistische Funktion transformiert reelle Zahlen (x-Achse im Plot) in Werte zwischen 0 und 1 (z.B. Wahrscheinlichkeiten; y-Achse im Plot). Formal drückt man das so aus: \\(f: \\mathbb{R} \\rightarrow (0, 1)\\). Die logistische Funktion wird Ihnen in der IRT noch oft begegnen.\n\n\n\n\n\n\n\n\n\nMit der Gleichung\n\\(\\frac{e^x}{1 + e^x} = \\frac{1}{1 + e^{-x}}\\)\nkönnen Sie bei Aufgaben zur IRT oft Zeit sparen, da Sie \\(x\\) (hier steht später ein aufwendigerer Ausdruck) nur einmal im Taschenrechner eingeben müssen.\nFür das Modul reicht es völlig aus den Zusammenhang auswendig zu lernen. Als Zusatzübung (optional), können Sie versuchen, die Gleichheit der Ausdrücke selbst zu zeigen.\n\nStellen Sie \\(\\frac{e^x}{1 + e^x}\\) nach \\(\\frac{1}{1 + e^{-x}}\\) um.\n\nSollte Ihre letzte Begegnung mit solchen Aufgaben schon etwas länger her sein, wird Ihnen diese Aufgabe vermutlich sehr schwer fallen. Das ist überhaupt nicht schlimm. Versuchen Sie es zuerst mit den Tipps. Falls das nicht klappt, können Sie versuchen, die Schritte mit der Lösung nachzuvollziehen.\n\n\n\n\n\n\nTipp\n\n\n\n\n\nMit diesen Schritten gelangen Sie zum Ziel:\n\n\\(e^x\\) ausklammern\n\\(e^x\\) kürzen\nNutzen, dass \\(e^0 = 1\\) ist\nRechenregel \\(\\frac{e^m}{e^n} = e^{m-n}\\)\nKommutativtesetz anwenden\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(\\frac{e^x}{1 + e^x}\\)\n\\(= \\frac{e^x}{e^x(\\frac{1}{e^x} + 1)}\\) (\\(e^x\\) ausklammern)\n\\(= \\frac{1}{\\frac{1}{e^x} + 1}\\) (\\(e^x\\) kürzen)\n\\(= \\frac{1}{\\frac{e^0}{e^x} + 1}\\) (nutze, dass \\(e^0 = 1\\) ist)\n\\(= \\frac{1}{e^{0-x} + 1}\\) (Rechenregel \\(\\frac{e^m}{e^n} = e^{m-n}\\))\n\\(= \\frac{1}{e^{-x} + 1}\\)\n\\(= \\frac{1}{1 + e^{-x}}\\) (Kommutativtesetz)"
  },
  {
    "objectID": "sections/rechenkompetenzen/rechenkompetenzen.html#summenzeichen",
    "href": "sections/rechenkompetenzen/rechenkompetenzen.html#summenzeichen",
    "title": "Grundlegende Rechenkompetenzen",
    "section": "",
    "text": "Den Umgang mit Summenzeichen müssen Sie als Psycholog:innen sicher beherrschen. Summen spielen insbesondere bei Operationen auf Datensätzen eine zentrale Rolle und werden Ihnen in der Vorlesung und dem Übungsheft noch oft begegnen. Daher legen wir hier einen besonderen Wert darauf, dass Sie mit den Symbolen \\(\\sum\\) (Summenzeichen) und \\(\\prod\\) (Produktzeichen) sicher umgehen können.\n\nBerechnen Sie\n\n\\(\\sum_{n = 1}^{3} n\\)\n\\(\\sum_{m = 2}^{4} m^2\\)\n\\(\\sum_{l = 3}^{6} (2 + l)\\)\n\\(\\sum_{i = 1}^{5} x_i\\), mit \\(\\boldsymbol{x} = [1, 3, 4, 3, 0]\\)\n\\(\\sum_{l=0}^{2}\\sum_{k=0}^{l}(2k)\\)\n\\(\\sum_{j = 1}^{2} \\sum_{j' = 1}^{3} (x_j + y_{j'})\\), mit \\(\\boldsymbol{x} = [1, 4, 3, 8]\\), \\(\\boldsymbol{y} = [3, 0, 1]\\)\n\\(\\sum_{i = 51}^{100}x_i + \\sum_{i = 20}^{50}x_i\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\\(\\sum_{n=1}^{3} n = 1+2+3 = 6\\)\n\\(\\sum_{m=2}^{4} m^2 = 2^2+3^2+4^2 = 4+9+16 = 29\\)\n\\(\\sum_{l=3}^{6} (2+l) = \\sum_{l=3}^{6}2 + \\sum_{l=3}^{6}l = 8 + (3+4+5+6) = 8+18 = 26\\)\n\\(\\sum_{i=1}^{5} x_i = 1+3+4+3+0 = 11\\)\n\\(\\sum_{l=0}^{2}\\sum_{k=0}^{l}(2k) = (0) + (0+2) + (0+2+4) = 8\\)\n\\(\\sum_{j=1}^{2}\\sum_{j'=1}^{3} (x_j + y_{j'})\n= \\sum_{j=1}^{2} \\big(3x_j + \\sum_{j'=1}^{3}y_{j'}\\big)\n= \\sum_{j=1}^{2} (3x_j + 4)\n= 3(1+4) + 8 = 23\\)\n\\(\\sum_{i=51}^{100}x_i + \\sum_{i=20}^{50}x_i = \\sum_{i=20}^{100}x_i\\)"
  },
  {
    "objectID": "sections/rechenkompetenzen/rechenkompetenzen.html#produktzeichen",
    "href": "sections/rechenkompetenzen/rechenkompetenzen.html#produktzeichen",
    "title": "Grundlegende Rechenkompetenzen",
    "section": "",
    "text": "Das multiplikative Analogon zum Summenzeichen ist das Produktzeichen.\n\nBerechnen Sie\n\n\\(\\prod_{i = 1}^{2} i\\)\n\\(\\prod_{i = 1}^{3} (i + 2)\\)\n\\(\\prod_{n = 2}^{5} x_n\\), mit \\(\\boldsymbol{x} = [4, 2, 1, 3, 4]\\)\n\\(\\prod_{i = 1}^{100} log(i)\\)\n\\(\\prod_{j = 2}^{3} \\prod_{k = 1}^{2} (j + k)\\)\n\\(\\prod_{i = 1}^{2}\\prod_{n=2}^{3}(i + n)\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\\(\\prod_{i=1}^{2} i = 1 \\cdot 2 = 2\\)\n\\(\\prod_{i=1}^{3} (i+2) = (1+2)(2+2)(3+2) = 3 \\cdot 4 \\cdot 5 = 60\\)\n\\(\\prod_{n=2}^{5} x_n = x_2 \\cdot x_3 \\cdot x_4 \\cdot x_5 = 2 \\cdot 1 \\cdot 3 \\cdot 4 = 24\\)\n\\(\\prod_{i=1}^{100} \\log(i) = 0\\)\n\\(\\prod_{j=2}^{3}\\prod_{k=1}^{2}(j+k)\n= ((2+1)(2+2)) \\cdot ((3+1)(3+2))\n= (3 \\cdot 4)(4 \\cdot 5)\n= 12 \\cdot 20 = 240\\)\n\\(\\prod_{i=1}^{2}\\prod_{n=2}^{3}(i+n)\n= ((1+2)(1+3)) \\cdot ((2+2)(2+3))\n= (3 \\cdot 4)(4 \\cdot 5)\n= 12 \\cdot 20 = 240\\)"
  },
  {
    "objectID": "sections/rechenkompetenzen/rechenkompetenzen.html#summen--und-produktzeichen",
    "href": "sections/rechenkompetenzen/rechenkompetenzen.html#summen--und-produktzeichen",
    "title": "Grundlegende Rechenkompetenzen",
    "section": "",
    "text": "Man kann Summen- und Produktzeichen auch kombinieren.\n\n\n\\(\\sum_{j = 1}^{3} \\prod_{i = 1}^{j} i\\)\n\\(\\prod_{i = 1}^{2} \\sum_{j = i}^{3} j\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\\(\\sum_{j=1}^{3}\\prod_{i=1}^{j} i\n= (1) + (1 \\cdot 2) + (1 \\cdot 2 \\cdot 3)\n= 1 + 2 + 6 = 9\\)\n\\(\\prod_{i=1}^{2}\\sum_{j=i}^{3} j\n= \\left(\\sum_{j=1}^{3} j\\right) \\cdot \\left(\\sum_{j=2}^{3} j\\right)\n= (1+2+3)(2+3)\n= 6 \\cdot 5 = 30\\)"
  },
  {
    "objectID": "sections/rechenkompetenzen/rechenkompetenzen.html#wahrscheinlichkeiten-und-verteilungen",
    "href": "sections/rechenkompetenzen/rechenkompetenzen.html#wahrscheinlichkeiten-und-verteilungen",
    "title": "Grundlegende Rechenkompetenzen",
    "section": "",
    "text": "In diesem Abschnitt geht es vor allem um Notation, die Ihnen im Übungsheft noch begegnen wird.\n\nBeschreiben Sie in eigenen Worten\n\n\\(P(A \\cap B) = P(A)P(B)\\)\n\\(P(A|B)\\)\n\\(X \\sim N(50, 10)\\)\n\\(Y \\sim U(10, 50)\\)"
  },
  {
    "objectID": "sections/rechenkompetenzen/rechenkompetenzen.html#umgang-mit-datenmatrizen",
    "href": "sections/rechenkompetenzen/rechenkompetenzen.html#umgang-mit-datenmatrizen",
    "title": "Grundlegende Rechenkompetenzen",
    "section": "",
    "text": "Dieses Thema wird ausführlich im Kapitel zu psychometrischen Datenmatrizen eingeführt. Die Aufgaben sind an keinerlei Voraussetzungen geknüpft. Wenn Sie vorarbeiten möchten, könnten Sie diesen Abschnitt bereits bearbeiten."
  },
  {
    "objectID": "sections/mitwirkende/mitwirkende.html",
    "href": "sections/mitwirkende/mitwirkende.html",
    "title": "Mitwirkende",
    "section": "",
    "text": "Mitwirkende\nDas Übungsheft enthält Aufgaben von:\n\nJan Killisch\nDr. Laurits Bromme"
  },
  {
    "objectID": "sections/konfidenzintervalle/konfidenzintervalle.html",
    "href": "sections/konfidenzintervalle/konfidenzintervalle.html",
    "title": "Konfidenzintervalle",
    "section": "",
    "text": "Das Konfidenzintervall ist ein Intervall, das so konstruiert ist, dass es den wahren Wert erwartungsgemäß in \\(((1-\\alpha) \\times 100)\\%\\) der Fälle umschließt.\nDas Konfidenzintervall ist von der Form:\n\\[\nKI = \\textcolor{blue}{X} \\;\\pm\\;\n\\textcolor{red}{z_{\\alpha/2}} \\cdot\n\\textcolor{green}{s_e}\n\\]\n\n\\(\\textcolor{blue}{X}\\): Testwert\n\n\\(\\textcolor{red}{z_{\\alpha/2}}\\): z-Wert\n\n\\(\\textcolor{green}{s_e}\\): Standardfehler\n\nIn der KTT, nicht aber in der IRT, ist der Standardfehler \\(s_e = SD_X \\cdot \\sqrt{1 - Rel_X}\\). Durch Einsetzen folgt daher:\n\\[\nKI = \\textcolor{blue}{X} \\;\\pm\\;\n\\textcolor{red}{z_{\\alpha/2}} \\cdot\n\\textcolor{green}{SD_x \\cdot\n\\sqrt{1 - Rel_x}}\n\\]\n\n\\(SD_x\\): Standardabweichung\n\n\\(Rel_x\\): Reliabilität\n\n\n\n\n\\(X\\) und \\(SD_x\\) müssen der gleichen Metrik folgen. Ist der Testwert etwa ein T-Wert, so muss die Standardabweichung gleich \\(10\\) sein. Ist der Testwert IQ-skaliert, so ist die Standardabweichung der Testwerte \\(15\\).\nSie können die Funktion teachIRT::get_z() verwenden, um schnell z-Werte nachzuschauen:\n\n\\(\\alpha = .05\\), beidseitig\n\nteachIRT::get_z(ci_alpha = 0.05, ci_direction = \"both\")\n\n    lower     upper \n-1.959964  1.959964 \n\n\n\\(\\alpha = .05\\), untere Grenze\n\nteachIRT::get_z(ci_alpha = 0.05, ci_direction = \"lower\")\n\n    lower     upper \n-1.644854       Inf \n\n\n\\(\\alpha = .05\\), obere Grenze\n\nteachIRT::get_z(ci_alpha = 0.05, ci_direction = \"upper\")\n\n   lower    upper \n    -Inf 1.644854 \n\n\n\nAm R-Code von 2. sehen Sie, dass Sie bei einseitigen Intervallen einen finiten und einen infiniten z-Wert erhalten. Durch die Multiplikation mit diesen z-Werten resultiert in R dann auch ein Intervall, bei dem eine Grenze finit und eine infinit ist. Zur Illustration ist es sinnvoll, das einmal gesehen zu haben. Rein mathematisch ist es allerdings nicht ganz sauber, \\(\\infty\\) für \\(z\\) einzusetzen. Das liegt daran, dass \\(z \\in \\mathbb{R}\\) eine relle Zahl ist, aber es ist \\(\\infty \\notin \\mathbb{R}\\) keine Zahl, sondern ein Symbol. Stattdessen kann man mit einem Doppelpunkt und einem Gleichheitszeichen klarmachen, dass die jeweils infinite Grenze definitorisch ist, also entweder \\(K_o := \\infty\\) oder \\(K_u := -\\infty\\).\nMan kann die Grenzen des Konfidenzintervalls “konservativ” runden. Damit ist gemeint, dass man die Grenzen des Intervalls so rundet, dass durch das Runden ein größeres Intervall entsteht. Erhalten Sie etwa die Werte \\(KI_{u} = -4.5734\\) und \\(KI_{o} = -1.4354\\) für die jeweils untere und obere Grenze eines Konfidenzintervalls, könnten Sie auf das Intervall \\([-4.58, -1.43]\\) runden. Beachten Sie dass Sie in diesem Beispiel zweimal genau gegenteilig zum kaufmännischen Runden vorgehen. Das Rational hinter dieser Überlegung ist es, keine Sicherheit durch das Runden zu suggerieren, die in den ungerundeten Werten garnicht vorhanden wäre. Wenn Sie auf zwei Nachkommastellen runden, wird der Unterschied zwischen den Rundungsverfahren in den meisten Metriken allerdings vernachlässigbar sein.\n\n\n\n\nWenn \\(X=110\\), \\(SD_x=5.6\\), \\(Rel_x=0.8\\) und \\(\\alpha = 5\\%\\), so sind \\(KI_{o} = 110 + 1.96 \\cdot 5.6 \\cdot \\sqrt{1-0.8} \\approx 114.91\\) und \\(KI_{u} = 110 - 1.96 \\cdot 5.6 \\cdot \\sqrt{1-0.8} \\approx 105.09\\) die Grenzen des zweiseitigen Intervalls, das erwartungsgemäß in \\(95\\%\\) der Fälle, in denen es berechnet wird, den wahren Wert umschließt. Also ist \\(KI = [105.09, 114.91]\\).\nÜberprüfung mit teachIRT:\n\nX &lt;- 110\nSD_x &lt;- 5.6\nRel_x &lt;- 0.8\nalpha &lt;- 0.05\n\nz &lt;- teachIRT::get_z(ci_alpha = alpha, ci_direction = \"both\")\nprint(z)\n\n    lower     upper \n-1.959964  1.959964 \n\nKI &lt;- X + z * SD_x * sqrt(1 - Rel_x)\nprint(KI)\n\n   lower    upper \n105.0915 114.9085 \n\n\nIn der Prüfung können Sie Ihr Ergebnis natürlich nicht mit teachIRT überprüfen. Sie sollten nach dem Rechnen dennoch mindestens noch einmal überprüfen, ob \\(KI_u &lt; X &lt; KI_o\\) gilt.\n\n\n\nWenn \\(X=110\\), \\(SD_x=5.6\\), \\(Rel_x=0.8\\) und \\(\\alpha = 5\\%\\), so sind \\(KI_{o} := \\infty\\) und \\(KI_{u} = 110 - 1.64 \\cdot 5.6 \\cdot \\sqrt{1-0.8} \\approx 105.88\\) die Grenzen des einseitigen Intervalls, das erwartungsgemäß in \\(95\\%\\) der Fälle, in denen es berechnet wird, den wahren Wert umschließt. Also ist \\(KI = [105.88, \\infty)\\).\n\nX &lt;- 110\nSD_x &lt;- 5.6\nRel_x &lt;- 0.8\nalpha &lt;- 0.05\n\nz &lt;- teachIRT::get_z(ci_alpha = alpha, ci_direction = \"lower\")\nprint(z)\n\n    lower     upper \n-1.644854       Inf \n\nKI &lt;- X + z * SD_x * sqrt(1 - Rel_x)\nprint(KI)\n\n   lower    upper \n105.8806      Inf \n\n\n\n\n\n\nTheo erzielt in einer Begutachtung zur Abklärung von Hochbegabung einen IQ-Wert von \\(139\\). Für die interne Konsistenz in einer vergleichbaren Normstichprobe wird im Manual ein Wert von \\(0.92\\) angegeben. Für die Test-Retest-Reliabilität liegen keine Werte vor. Berechnen Sie ein einseitiges \\(95\\%\\)-Konfidenzintervall um Theos Testwert.\nInterpretieren Sie das Intervall im Hinblick auf den typischen Schwellenwert von \\(130\\) IQ-Punkten in der Diagnostik von Hochbegabung.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben:\n\n\\(X = 139\\)\n\\(Rel_x = 0.92\\)\n\\(\\alpha = .05\\)\n\\(SD_x = 15\\)\n\\(KI_{o}=\\infty\\)\n\nGesucht:\n\\(KI_{u} = X - z_{1-\\alpha} \\cdot SD_x \\cdot \\sqrt{1-Rel_x}\\)\nVerwende \\(z_{1-\\alpha} \\approx 1.64\\), da einseitig 5% der Standardnormalverteilung abgeschnitten werden sollen.\n\\(KI_{u} = 139 - 1.64 \\cdot 15 \\cdot \\sqrt{1-0.92} \\approx 132.04\\)\nDie obere Intervallgrenze \\(KI_{o} := +\\infty\\) ist definiert.\nDen Wert \\(139\\) umgibt das einseitige \\(95\\%\\)-Konfidenzintervall \\([132.04, +\\infty)\\). Die untere Schwelle des Intervalls, das in \\(95\\%\\) der Fälle den wahren Wert umschließt, liegt über dem üblichen Cutoff von \\(130\\) IQ-Punkten. Das Testergebnis spricht dafür, dass Theo hochbegabt ist.\nÜberprüfung in R:\n\n# Gegeben:\nX &lt;- 139 # (IQ-Wert)\nRel_x &lt;- 0.92\nalpha &lt;- 0.05\nSD_x &lt;- 15\n\n# Konfidenzintervall berechnen\nz &lt;- teachIRT::get_z(ci_alpha = alpha, ci_direction = \"lower\")\nKI &lt;- X + z * SD_x * sqrt(1-Rel_x)\n\nprint(KI)\n\n   lower    upper \n132.0215      Inf \n\n\nDie Abweichung resultiert daraus, dass der z-Wert im R-Script nicht gerundet wurde:\n\nz[1] &lt;- -1.64\nKI &lt;- X + z * SD_x * sqrt(1-Rel_x)\n\nprint(KI)\n\n   lower    upper \n132.0421      Inf \n\n\n\n\n\n\nZur Abklärung der Fahrtauglichkeit soll mit einem Konfidenzkoeffizienten von 95% geklärt werden, ob der 57-jährige Andonis M. ausreichend gewissenhaft ist. Die Hypothese lautet:\n\nLiegt Herr M.s Gewissenhaftigkeitswert im BFI-2, verglichen mit einer Normstichprobe von Personen, die einen gültigen Führerschein besitzen, mindestens im durchschnittlichen Bereich (\\(T \\ge 40\\))?\n\nHerr M.s Rohwert beträgt \\(3.5\\). Personen in der Vergleichsgruppe erzielten im Mittel einen Testwert von \\(3.75\\) mit einer Standardabweichung von \\(0.5\\). Für den BFI-II liegt eine Schätzung von \\(.84\\) für McDonald’s Omega vor. Berechnen Sie den T-Wert und das passende Konfidenzintervall um die Hypothese zu prüfen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben:\n\nRohwert \\(X = 3.5\\)\nReliabilität \\(Rel_x = .84\\)\nAlpha-Fehler \\(\\alpha = .05\\)\nObere Konfidenzgrenze \\(KI_{o} = \\infty\\)\nMittelwert in der Normstichprobe \\(\\mu = 3.75\\)\nStandardabweichung in der Normstichprobe \\(\\sigma = 0.5\\)\n\nGesucht:\n\\(KI_{u} = T - z_{1-\\alpha} \\cdot SD_T \\cdot \\sqrt{1-Rel_x}\\)\n\nTransformation von \\(X\\) in die \\(T\\)-Metrik:\n\n\\(T = 50 + 10 \\cdot z_x = 50 + 10 \\cdot \\frac{X - \\mu}{\\sigma} = \\frac{3.5 - 3.75}{0.5} = 45\\)\n\nBerechnung der unteren Konfidenzgrenze:\n\n\\(z_{1-\\alpha} \\approx 1.64\\), \\(SD_T = 10\\)\n\\(KI_{u} = T - z_{1-\\alpha} \\cdot SD_T \\cdot \\sqrt{1-Rel_x} \\approx 45 - 1.64 \\cdot 10 \\cdot \\sqrt{1-.84} \\approx 38.44\\)\nDie obere Intervallgrenze \\(KI_{o} := +\\infty\\) ist definiert.\nDen T-Wert \\(45\\) umgibt das einseitige \\(95\\%\\)-Konfidenzintervall \\([38.44, +\\infty)\\). Die untere Schwelle des Intervalls, das in \\(95\\%\\) der Fälle den wahren Wert umschließt, liegt nicht über dem Cutoff von \\(40\\). Es lässt sich nicht mit ausreichender Sicherheit sagen, dass Herr M. ausreichend gewissenhaft ist.\nÜberprüfung in R\n\n# Gegeben\nX &lt;- 3.5\nRel_x &lt;- .84\nalpha &lt;- .05\nmu &lt;- 3.75\nsigma &lt;- 0.5\n\n# 1. Transformation in die T-Metrik\nzx &lt;- (X - mu) / sigma\nTx &lt;- 50 + 10*zx\n\n# 2. Berechnung des Konfidenzintervalls\nz &lt;- teachIRT::get_z(ci_alpha = alpha, ci_direction = \"lower\")\nKI &lt;- Tx + z * 10 * sqrt(1-Rel_x)\n\nprint(KI)\n\n   lower    upper \n38.42059      Inf \n\n\nDie Abweichung in der zweiten Nachkommastelle entsteht durch das Runden des z-Werts:\n\nz[1] &lt;- -1.64\nKI &lt;- Tx + z * 10 * sqrt(1-Rel_x)\n\nprint(KI)\n\nlower upper \n38.44   Inf \n\n\n\n\n\n\nFür eine Studie sollen weibliche Jugendliche ausgewählt werden, deren Prüfungsangst in einem hier als normal definierten Bereich liegt (Mittelwert \\(\\pm\\) 2 SD). Es wird ein Konfidenzkoeffizient von 99% angelegt. Die Hypothese lautet:\n\nLiegt der beobachtete z-Wert auf der Multidimensional Test Anxiety Scale (MTAS) im Vergleich zu gleichaltrigen Mädchen im durchschnittlichen Bereich (\\(-2 \\le z \\le +2\\))?\n\nDer Rohwert einer 15-jährigen Kandidatin beträgt 42. Transformieren Sie den Rohwert in einen z-Wert. Berechnen Sie anschließend das passende Konfidenzintervall um den z-Wert um die diagnostiche Hypothese zu überprüfen. Die Reliabilität des MTAS wurde auf .80 geschätzt. Mittelwert und Standardabweichung in der Referenzstichprobe betragen jeweils \\(47.9\\) und \\(10\\).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben:\nRohwert \\(X = 42\\)\nAlpha-Fehler \\(\\alpha = .01\\)\nReliabilität \\(Rel_x = .80\\)\nMittelwert in der Referenzstichprobe \\(\\mu = 47.9\\)\nStandardabweichung in der Referenzstichprobe \\(\\sigma = 10\\)\nGesucht:\n\\(KI = z_x \\pm z_{\\alpha/2} \\cdot \\sqrt{1 - Rel_x}\\)\nDie Standardabweichung wurde hier ausgelassen, da z-Werte qua Definition eine Standardabweichung von \\(1\\) haben. Die Multiplikation mit \\(1\\) würde das Intervall nicht verändern.\n\nTransformation des Rohwerts in einem z-Wert\n\n\\(z_x = \\frac{X - \\mu}{\\sigma} = \\frac{42 - 47.9}{10} = -0.59\\)\n\nBerechnung des zweiseitigen Konfidenzintevalls\n\n\\(KI_{o} = -0.59 + 2.58 \\cdot \\sqrt{1-0.8} \\approx 0.57\\)\n\\(KI_{u} = -0.59 - 2.58 \\cdot \\sqrt{1-0.8} \\approx -1.75\\)\nDie Konfidenzgrenzen wurde konservativ gerundet, sodass ein größeres Intervall resultiert.\nDen z-transformierten Testwert von \\(-0.59\\) umgibt das \\(99\\%\\) Konfidenzintervall \\([-1.75, 0.57]\\). Die untere Schwelle des Intervalls überschreitet den unteren Cutoff von \\(-2\\) und die obere Grenze des Intervalls unterschreitet den oberen Cutoff von \\(+2\\). Es kann mit ausreichender Sicherheit davon ausgegangen werden, dass der Testwert der Kandidatin im als durchschnittlich definierten Bereich liegt.\nÜberprüfung in R\n\n# Gegeben\nX &lt;- 42\nalpha &lt;- 0.01\nRel_x &lt;- 0.80\nmu &lt;- 47.9\nsigma &lt;- 10\n\n# Transformation des Rohwerts in einen z-Wert\nzx &lt;- (X - mu) / sigma\nprint(zx)\n\n[1] -0.59\n\n# Berechnung des zweiseitigen Konfidenzintervalls\nz &lt;- teachIRT::get_z(ci_alpha = alpha, ci_direction = \"both\")\nKI &lt;- zx + z*sqrt(1-Rel_x)\n\nprint(KI)\n\n     lower      upper \n-1.7419459  0.5619459 \n\n\n\n\n\nDer Abschnitt zu Konfidenzintervallen ist hier vorerst abgeschlossen. Im Abschnitt zum adaptiven Testen werden Sie später zusätzlich lernen, wie man Konfidenzintervalle für Personenparameter der IRT berechnet."
  },
  {
    "objectID": "sections/konfidenzintervalle/konfidenzintervalle.html#tipps",
    "href": "sections/konfidenzintervalle/konfidenzintervalle.html#tipps",
    "title": "Konfidenzintervalle",
    "section": "",
    "text": "\\(X\\) und \\(SD_x\\) müssen der gleichen Metrik folgen. Ist der Testwert etwa ein T-Wert, so muss die Standardabweichung gleich \\(10\\) sein. Ist der Testwert IQ-skaliert, so ist die Standardabweichung der Testwerte \\(15\\).\nSie können die Funktion teachIRT::get_z() verwenden, um schnell z-Werte nachzuschauen:\n\n\\(\\alpha = .05\\), beidseitig\n\nteachIRT::get_z(ci_alpha = 0.05, ci_direction = \"both\")\n\n    lower     upper \n-1.959964  1.959964 \n\n\n\\(\\alpha = .05\\), untere Grenze\n\nteachIRT::get_z(ci_alpha = 0.05, ci_direction = \"lower\")\n\n    lower     upper \n-1.644854       Inf \n\n\n\\(\\alpha = .05\\), obere Grenze\n\nteachIRT::get_z(ci_alpha = 0.05, ci_direction = \"upper\")\n\n   lower    upper \n    -Inf 1.644854 \n\n\n\nAm R-Code von 2. sehen Sie, dass Sie bei einseitigen Intervallen einen finiten und einen infiniten z-Wert erhalten. Durch die Multiplikation mit diesen z-Werten resultiert in R dann auch ein Intervall, bei dem eine Grenze finit und eine infinit ist. Zur Illustration ist es sinnvoll, das einmal gesehen zu haben. Rein mathematisch ist es allerdings nicht ganz sauber, \\(\\infty\\) für \\(z\\) einzusetzen. Das liegt daran, dass \\(z \\in \\mathbb{R}\\) eine relle Zahl ist, aber es ist \\(\\infty \\notin \\mathbb{R}\\) keine Zahl, sondern ein Symbol. Stattdessen kann man mit einem Doppelpunkt und einem Gleichheitszeichen klarmachen, dass die jeweils infinite Grenze definitorisch ist, also entweder \\(K_o := \\infty\\) oder \\(K_u := -\\infty\\).\nMan kann die Grenzen des Konfidenzintervalls “konservativ” runden. Damit ist gemeint, dass man die Grenzen des Intervalls so rundet, dass durch das Runden ein größeres Intervall entsteht. Erhalten Sie etwa die Werte \\(KI_{u} = -4.5734\\) und \\(KI_{o} = -1.4354\\) für die jeweils untere und obere Grenze eines Konfidenzintervalls, könnten Sie auf das Intervall \\([-4.58, -1.43]\\) runden. Beachten Sie dass Sie in diesem Beispiel zweimal genau gegenteilig zum kaufmännischen Runden vorgehen. Das Rational hinter dieser Überlegung ist es, keine Sicherheit durch das Runden zu suggerieren, die in den ungerundeten Werten garnicht vorhanden wäre. Wenn Sie auf zwei Nachkommastellen runden, wird der Unterschied zwischen den Rundungsverfahren in den meisten Metriken allerdings vernachlässigbar sein."
  },
  {
    "objectID": "sections/konfidenzintervalle/konfidenzintervalle.html#beispiel-zweiseitig",
    "href": "sections/konfidenzintervalle/konfidenzintervalle.html#beispiel-zweiseitig",
    "title": "Konfidenzintervalle",
    "section": "",
    "text": "Wenn \\(X=110\\), \\(SD_x=5.6\\), \\(Rel_x=0.8\\) und \\(\\alpha = 5\\%\\), so sind \\(KI_{o} = 110 + 1.96 \\cdot 5.6 \\cdot \\sqrt{1-0.8} \\approx 114.91\\) und \\(KI_{u} = 110 - 1.96 \\cdot 5.6 \\cdot \\sqrt{1-0.8} \\approx 105.09\\) die Grenzen des zweiseitigen Intervalls, das erwartungsgemäß in \\(95\\%\\) der Fälle, in denen es berechnet wird, den wahren Wert umschließt. Also ist \\(KI = [105.09, 114.91]\\).\nÜberprüfung mit teachIRT:\n\nX &lt;- 110\nSD_x &lt;- 5.6\nRel_x &lt;- 0.8\nalpha &lt;- 0.05\n\nz &lt;- teachIRT::get_z(ci_alpha = alpha, ci_direction = \"both\")\nprint(z)\n\n    lower     upper \n-1.959964  1.959964 \n\nKI &lt;- X + z * SD_x * sqrt(1 - Rel_x)\nprint(KI)\n\n   lower    upper \n105.0915 114.9085 \n\n\nIn der Prüfung können Sie Ihr Ergebnis natürlich nicht mit teachIRT überprüfen. Sie sollten nach dem Rechnen dennoch mindestens noch einmal überprüfen, ob \\(KI_u &lt; X &lt; KI_o\\) gilt."
  },
  {
    "objectID": "sections/konfidenzintervalle/konfidenzintervalle.html#beispiel-einseitig-mit-unterer-grenze",
    "href": "sections/konfidenzintervalle/konfidenzintervalle.html#beispiel-einseitig-mit-unterer-grenze",
    "title": "Konfidenzintervalle",
    "section": "",
    "text": "Wenn \\(X=110\\), \\(SD_x=5.6\\), \\(Rel_x=0.8\\) und \\(\\alpha = 5\\%\\), so sind \\(KI_{o} := \\infty\\) und \\(KI_{u} = 110 - 1.64 \\cdot 5.6 \\cdot \\sqrt{1-0.8} \\approx 105.88\\) die Grenzen des einseitigen Intervalls, das erwartungsgemäß in \\(95\\%\\) der Fälle, in denen es berechnet wird, den wahren Wert umschließt. Also ist \\(KI = [105.88, \\infty)\\).\n\nX &lt;- 110\nSD_x &lt;- 5.6\nRel_x &lt;- 0.8\nalpha &lt;- 0.05\n\nz &lt;- teachIRT::get_z(ci_alpha = alpha, ci_direction = \"lower\")\nprint(z)\n\n    lower     upper \n-1.644854       Inf \n\nKI &lt;- X + z * SD_x * sqrt(1 - Rel_x)\nprint(KI)\n\n   lower    upper \n105.8806      Inf"
  },
  {
    "objectID": "sections/konfidenzintervalle/konfidenzintervalle.html#aufgaben-zum-konfidenzintervall-in-der-ktt",
    "href": "sections/konfidenzintervalle/konfidenzintervalle.html#aufgaben-zum-konfidenzintervall-in-der-ktt",
    "title": "Konfidenzintervalle",
    "section": "",
    "text": "Theo erzielt in einer Begutachtung zur Abklärung von Hochbegabung einen IQ-Wert von \\(139\\). Für die interne Konsistenz in einer vergleichbaren Normstichprobe wird im Manual ein Wert von \\(0.92\\) angegeben. Für die Test-Retest-Reliabilität liegen keine Werte vor. Berechnen Sie ein einseitiges \\(95\\%\\)-Konfidenzintervall um Theos Testwert.\nInterpretieren Sie das Intervall im Hinblick auf den typischen Schwellenwert von \\(130\\) IQ-Punkten in der Diagnostik von Hochbegabung.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben:\n\n\\(X = 139\\)\n\\(Rel_x = 0.92\\)\n\\(\\alpha = .05\\)\n\\(SD_x = 15\\)\n\\(KI_{o}=\\infty\\)\n\nGesucht:\n\\(KI_{u} = X - z_{1-\\alpha} \\cdot SD_x \\cdot \\sqrt{1-Rel_x}\\)\nVerwende \\(z_{1-\\alpha} \\approx 1.64\\), da einseitig 5% der Standardnormalverteilung abgeschnitten werden sollen.\n\\(KI_{u} = 139 - 1.64 \\cdot 15 \\cdot \\sqrt{1-0.92} \\approx 132.04\\)\nDie obere Intervallgrenze \\(KI_{o} := +\\infty\\) ist definiert.\nDen Wert \\(139\\) umgibt das einseitige \\(95\\%\\)-Konfidenzintervall \\([132.04, +\\infty)\\). Die untere Schwelle des Intervalls, das in \\(95\\%\\) der Fälle den wahren Wert umschließt, liegt über dem üblichen Cutoff von \\(130\\) IQ-Punkten. Das Testergebnis spricht dafür, dass Theo hochbegabt ist.\nÜberprüfung in R:\n\n# Gegeben:\nX &lt;- 139 # (IQ-Wert)\nRel_x &lt;- 0.92\nalpha &lt;- 0.05\nSD_x &lt;- 15\n\n# Konfidenzintervall berechnen\nz &lt;- teachIRT::get_z(ci_alpha = alpha, ci_direction = \"lower\")\nKI &lt;- X + z * SD_x * sqrt(1-Rel_x)\n\nprint(KI)\n\n   lower    upper \n132.0215      Inf \n\n\nDie Abweichung resultiert daraus, dass der z-Wert im R-Script nicht gerundet wurde:\n\nz[1] &lt;- -1.64\nKI &lt;- X + z * SD_x * sqrt(1-Rel_x)\n\nprint(KI)\n\n   lower    upper \n132.0421      Inf \n\n\n\n\n\n\nZur Abklärung der Fahrtauglichkeit soll mit einem Konfidenzkoeffizienten von 95% geklärt werden, ob der 57-jährige Andonis M. ausreichend gewissenhaft ist. Die Hypothese lautet:\n\nLiegt Herr M.s Gewissenhaftigkeitswert im BFI-2, verglichen mit einer Normstichprobe von Personen, die einen gültigen Führerschein besitzen, mindestens im durchschnittlichen Bereich (\\(T \\ge 40\\))?\n\nHerr M.s Rohwert beträgt \\(3.5\\). Personen in der Vergleichsgruppe erzielten im Mittel einen Testwert von \\(3.75\\) mit einer Standardabweichung von \\(0.5\\). Für den BFI-II liegt eine Schätzung von \\(.84\\) für McDonald’s Omega vor. Berechnen Sie den T-Wert und das passende Konfidenzintervall um die Hypothese zu prüfen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben:\n\nRohwert \\(X = 3.5\\)\nReliabilität \\(Rel_x = .84\\)\nAlpha-Fehler \\(\\alpha = .05\\)\nObere Konfidenzgrenze \\(KI_{o} = \\infty\\)\nMittelwert in der Normstichprobe \\(\\mu = 3.75\\)\nStandardabweichung in der Normstichprobe \\(\\sigma = 0.5\\)\n\nGesucht:\n\\(KI_{u} = T - z_{1-\\alpha} \\cdot SD_T \\cdot \\sqrt{1-Rel_x}\\)\n\nTransformation von \\(X\\) in die \\(T\\)-Metrik:\n\n\\(T = 50 + 10 \\cdot z_x = 50 + 10 \\cdot \\frac{X - \\mu}{\\sigma} = \\frac{3.5 - 3.75}{0.5} = 45\\)\n\nBerechnung der unteren Konfidenzgrenze:\n\n\\(z_{1-\\alpha} \\approx 1.64\\), \\(SD_T = 10\\)\n\\(KI_{u} = T - z_{1-\\alpha} \\cdot SD_T \\cdot \\sqrt{1-Rel_x} \\approx 45 - 1.64 \\cdot 10 \\cdot \\sqrt{1-.84} \\approx 38.44\\)\nDie obere Intervallgrenze \\(KI_{o} := +\\infty\\) ist definiert.\nDen T-Wert \\(45\\) umgibt das einseitige \\(95\\%\\)-Konfidenzintervall \\([38.44, +\\infty)\\). Die untere Schwelle des Intervalls, das in \\(95\\%\\) der Fälle den wahren Wert umschließt, liegt nicht über dem Cutoff von \\(40\\). Es lässt sich nicht mit ausreichender Sicherheit sagen, dass Herr M. ausreichend gewissenhaft ist.\nÜberprüfung in R\n\n# Gegeben\nX &lt;- 3.5\nRel_x &lt;- .84\nalpha &lt;- .05\nmu &lt;- 3.75\nsigma &lt;- 0.5\n\n# 1. Transformation in die T-Metrik\nzx &lt;- (X - mu) / sigma\nTx &lt;- 50 + 10*zx\n\n# 2. Berechnung des Konfidenzintervalls\nz &lt;- teachIRT::get_z(ci_alpha = alpha, ci_direction = \"lower\")\nKI &lt;- Tx + z * 10 * sqrt(1-Rel_x)\n\nprint(KI)\n\n   lower    upper \n38.42059      Inf \n\n\nDie Abweichung in der zweiten Nachkommastelle entsteht durch das Runden des z-Werts:\n\nz[1] &lt;- -1.64\nKI &lt;- Tx + z * 10 * sqrt(1-Rel_x)\n\nprint(KI)\n\nlower upper \n38.44   Inf \n\n\n\n\n\n\nFür eine Studie sollen weibliche Jugendliche ausgewählt werden, deren Prüfungsangst in einem hier als normal definierten Bereich liegt (Mittelwert \\(\\pm\\) 2 SD). Es wird ein Konfidenzkoeffizient von 99% angelegt. Die Hypothese lautet:\n\nLiegt der beobachtete z-Wert auf der Multidimensional Test Anxiety Scale (MTAS) im Vergleich zu gleichaltrigen Mädchen im durchschnittlichen Bereich (\\(-2 \\le z \\le +2\\))?\n\nDer Rohwert einer 15-jährigen Kandidatin beträgt 42. Transformieren Sie den Rohwert in einen z-Wert. Berechnen Sie anschließend das passende Konfidenzintervall um den z-Wert um die diagnostiche Hypothese zu überprüfen. Die Reliabilität des MTAS wurde auf .80 geschätzt. Mittelwert und Standardabweichung in der Referenzstichprobe betragen jeweils \\(47.9\\) und \\(10\\).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben:\nRohwert \\(X = 42\\)\nAlpha-Fehler \\(\\alpha = .01\\)\nReliabilität \\(Rel_x = .80\\)\nMittelwert in der Referenzstichprobe \\(\\mu = 47.9\\)\nStandardabweichung in der Referenzstichprobe \\(\\sigma = 10\\)\nGesucht:\n\\(KI = z_x \\pm z_{\\alpha/2} \\cdot \\sqrt{1 - Rel_x}\\)\nDie Standardabweichung wurde hier ausgelassen, da z-Werte qua Definition eine Standardabweichung von \\(1\\) haben. Die Multiplikation mit \\(1\\) würde das Intervall nicht verändern.\n\nTransformation des Rohwerts in einem z-Wert\n\n\\(z_x = \\frac{X - \\mu}{\\sigma} = \\frac{42 - 47.9}{10} = -0.59\\)\n\nBerechnung des zweiseitigen Konfidenzintevalls\n\n\\(KI_{o} = -0.59 + 2.58 \\cdot \\sqrt{1-0.8} \\approx 0.57\\)\n\\(KI_{u} = -0.59 - 2.58 \\cdot \\sqrt{1-0.8} \\approx -1.75\\)\nDie Konfidenzgrenzen wurde konservativ gerundet, sodass ein größeres Intervall resultiert.\nDen z-transformierten Testwert von \\(-0.59\\) umgibt das \\(99\\%\\) Konfidenzintervall \\([-1.75, 0.57]\\). Die untere Schwelle des Intervalls überschreitet den unteren Cutoff von \\(-2\\) und die obere Grenze des Intervalls unterschreitet den oberen Cutoff von \\(+2\\). Es kann mit ausreichender Sicherheit davon ausgegangen werden, dass der Testwert der Kandidatin im als durchschnittlich definierten Bereich liegt.\nÜberprüfung in R\n\n# Gegeben\nX &lt;- 42\nalpha &lt;- 0.01\nRel_x &lt;- 0.80\nmu &lt;- 47.9\nsigma &lt;- 10\n\n# Transformation des Rohwerts in einen z-Wert\nzx &lt;- (X - mu) / sigma\nprint(zx)\n\n[1] -0.59\n\n# Berechnung des zweiseitigen Konfidenzintervalls\nz &lt;- teachIRT::get_z(ci_alpha = alpha, ci_direction = \"both\")\nKI &lt;- zx + z*sqrt(1-Rel_x)\n\nprint(KI)\n\n     lower      upper \n-1.7419459  0.5619459 \n\n\n\n\n\nDer Abschnitt zu Konfidenzintervallen ist hier vorerst abgeschlossen. Im Abschnitt zum adaptiven Testen werden Sie später zusätzlich lernen, wie man Konfidenzintervalle für Personenparameter der IRT berechnet."
  },
  {
    "objectID": "sections/thurstonian_irt/thurstonian_irt.html",
    "href": "sections/thurstonian_irt/thurstonian_irt.html",
    "title": "Thurstonian Item Response Modell",
    "section": "",
    "text": "Sie haben in der Vorlesung das multidimensionale forced-choice (MFC) Format und das Thurstonian IRT Modell kennengelernt.\n\n\nIm Folgenden sehen Sie die Datenmatrix eines forced-choice Tests mit zwei multidimensionalen Triplets.\n\\[\\begin{equation}\n    \\mathbf{U} =\n    \\begin{bmatrix}\n        1 & 1 & 0 & 0 & 1 & 1 \\\\\n        1 & 0 & 0 & 0 & 0 & 0 \\\\\n        0 & 0 & 1 & 1 & 0 & 0\\\\\n    \\end{bmatrix}\n\\end{equation}\\]\n\nWas bedeuten jeweils die Zeilen und Spalten der Datenmatrix?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nJede Zeile enthält die Antworten einer Person.\nJede Spalte entspricht einem binären Paarvergleich.\n\n\n\n\nIn welche Reihenfolge hat Person \\(3\\) die Items von Triplet \\(2\\) sortiert?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Spalten entsprechen von links nach rechts den folgenden Paarvergleichen:\nTriplet 1\n\nItem 1 aus Triplet 1 vs. Item 2 aus Triplet 1\nItem 1 aus Triplet 1 vs. Item 3 aus Triplet 1\nItem 2 aus Triplet 1 vs. Item 3 aus Triplet 1\n\nTriplet 2\n\nItem 1 aus Triplet 2 vs. Item 2 aus Triplet 2\nItem 1 aus Triplet 2 vs. Item 3 aus Triplet 2\nItem 2 aus Triplet 2 vs. Item 3 aus Triplet 2\n\nUm herauszufinden, in welche Reihenfolge Person \\(3\\) die Items von Triplet \\(2\\) sortiert hat, muss man also die Matrixeinträge in Zeile \\(3\\) und Spalten \\(4\\)-\\(6\\) betrachten.\nEs sind \\(u_{34} = 1\\), \\(u_{35} = 0\\), und \\(u_{36} = 0\\) die beobachteten Wert von Person \\(3\\) auf Triplet \\(2\\). Die Person muss die Items des Blocks also in die Reihenfolge \\(312\\) gebracht haben.\n\n\n\n\nEine vierte Person hat die beiden Triplets jeweils in die Reihenfolgen \\(132\\) und \\(312\\) sortiert. Ergänzen Sie die vierte Zeile der Datenmatrix.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nTriplet 1:\nDie Rangfolge ist \\(132\\).\nEs wurde Item 1 über Item 2 bevorzugt (1).\nEs wurde Item 1 über Item 3 bevorzugt (1).\nEs wurde nicht Item 3 über Item 2 bevorzugt (0).\nTriplet 2:\nDie Rangfolge ist \\(312\\).\nEs wurde Item 1 über Item 2 bevorzugt (1).\nEs wurde nicht Item 1 über Item 3 bevorzugt (0).\nEs wurde nicht Item 2 über Item 3 bevorzugt (0).\nDie ergänzte Matrix ist also\n\\[\\begin{equation}\n    \\mathbf{U} =\n    \\begin{bmatrix}\n        1 & 1 & 0 & 0 & 1 & 1 \\\\\n        1 & 0 & 0 & 0 & 0 & 0 \\\\\n        0 & 0 & 1 & 1 & 0 & 0 \\\\\n        1 & 1 & 0 & 1 & 0 & 0\n    \\end{bmatrix}\n\\end{equation}\\]\n\n\n\n\nWarum ist die Auswertung von forced-choice Daten mit Hilfe der Klassischen Testtheorie suboptimal?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie resultierenden Summenscores sind ipsativ.\n\n\n\n\n\n\nEine der Klassichen Testtheorie überlegene Auswertungsmethode für MFC Testantworten ist die Auswertung mit Hilfe spezialisierter Item Response Modelle. In der Vorlesung haben Sie das Thurstonian IRT Modell kennengelernt.\n\nAus dem Thurstonian IRT Modell lassen sich blockweise abhängige Item Characteristic Surface Functions (ICSs) herleiten. Suchen Sie die Formel für die ICS des Thurstonian IRT Modells in der Formelsammlung.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nBedingte Wahrscheinlichkeit, Item \\(i\\) gegenüber Item \\(k\\) zu bevorzugen:\n\\[\\begin{equation}\n\nP_l(y_l = 1 | \\theta_a, \\theta_b) = \\Phi \\Big( \\frac{\\mu_i - \\mu_k + \\lambda_i \\theta_a - \\lambda_k \\theta_b}{\\sqrt{\\psi^2_i + \\psi^2_k}} \\Big)\n\n\\end{equation}\\]\n\n\n\n\nDie Notation der Vorlesung weicht bei diesem Modell von den vorherigen IRT-Modellen ab. Es lohnt sich daher, die Bestandteile der Formel einzeln zu betrachten.\n1. Indices\nWas bedeuten hier die Indices \\(l\\), \\(a\\), \\(b\\), \\(i\\), und \\(k\\)?\n2. Daten\nWie steht \\(y_l\\) mit der bereits etablierten Datenmatrix \\(\\mathbf{U}\\) im Zusammenhang?\n3. Parameter\nWas bedeuten \\(\\theta_a\\), \\(\\theta_b\\), \\(\\mu_i\\), \\(\\mu_k\\), \\(\\lambda_i\\), \\(\\lambda_k\\), \\(\\psi_i\\), und \\(\\psi_k\\)?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(l\\): Paarvergleich\n\\(a\\): Erster Trait\n\\(b\\): Zweiter Trait\n\\(i\\): Erstes Item\n\\(k\\): Zweites Item\nDas \\(l\\) kodiert die Spalte der Datenmatrix. Es gibt keinen Personenparameter. Es geht also um eine beliebige Person.\n\\(\\theta_a\\): Traitwert auf dem ersten Trait (gemessen durch Item \\(i\\))\n\\(\\theta_b\\): Traitwert auf dem zweiten Trait (gemessen durch Item \\(k\\))\n\\(\\mu_i\\): Mittelwertsparameter von Item \\(i\\)\n\\(\\mu_k\\): Mittelwertsparameter von Item \\(k\\)\n\\(\\lambda_i\\): Faktorladung von Item \\(i\\) auf Trait \\(a\\)\n\\(\\lambda_k\\): Faktorladung von Item \\(k\\) auf Trait \\(b\\)\n\\(\\psi_i\\): Residual-Standardabweichung von Item \\(i\\)\n\\(\\psi_k\\): Residual-Standardabweichung von Item \\(k\\)\n\n\n\n\nWas bedeutet die Wahrscheinlichkeit \\(P(y_2 = 1 | \\theta_a, \\theta_b)\\) inhaltlich?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Wahrscheinlichkeit, dass eine Person mit den Traitwerten \\(\\theta_a\\) und \\(\\theta_b\\) auf dem zweiten Paarvergleich das erste Item von beiden bevorzugt.\n\n\n\n\nEine Person mit \\(\\theta_a = 0.5\\) und \\(\\theta_b = 0\\) bearbeitet ein MFC Paar. Die Itemparameter des MFC Paars sind \\(\\mu_j = 0.5\\), \\(\\mu_k = -1\\), \\(\\lambda_j = 1\\), \\(\\lambda_k = -0.9\\), \\(\\psi_j = 1\\), und \\(\\psi_k = 0.9\\). Berechnen Sie die Wahrscheinlichkeit, dass die Person Item \\(j\\) gegenüber Item \\(k\\) bevorzugt.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben:\n\\(\\theta_a = 0.5\\), \\(\\theta_b = 0\\)\n\\(\\mu_j = 0.5\\), \\(\\mu_k = -1\\)\n\\(\\lambda_j = 1\\), \\(\\lambda_k = -0.9\\)\n\\(\\psi_j = 1\\), \\(\\psi_k = 0.9\\)\nGesucht:\nDie Wahrscheinlichkeit, dass die Person Item \\(j\\) gegenüber Item \\(k\\) bevorzugt.\n\\[\\begin{equation}\n    P(y_l = 1 | \\theta_a, \\theta_b)\n\\end{equation}\\]\n\\[\\begin{equation}\n    = \\Phi(\n        \\frac{\n                \\mu_j - \\mu_k + \\lambda_j \\theta_a  - \\lambda_k \\theta_b\n            }{\n                \\sqrt{\\psi_j^2 + \\psi_k^2}\n            }\n    )\n\\end{equation}\\] \\[\\begin{equation}\n    = \\Phi(\n        \\frac{\n                0.5 + 1 + 0.5\n            }{\n                \\sqrt{1^2 + 0.9^2}\n            }\n    )\n\\end{equation}\\] \\[\\begin{equation}\n    = \\Phi(\\frac{2}{\\sqrt{1.81}})\n\\end{equation}\\] \\[\\begin{equation}\n    \\approx .93\n\\end{equation}\\]\n\\(\\Phi\\) steht hier für die kumulative Dichteverteilung (CDF) der Standardnormalverteilung. Die Vorschrift von \\(\\Phi\\) ist\n\\[\\begin{equation}\n    \\Phi(x) = \\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{x} e^{-t^2/2} dt\n\\end{equation}\\]\nDas Integral lässt sich nur näherungsweise berechnen. In R ist diese Berechnung mit der Funktion pnorm bereits implementiert.\n\npnorm(2 / sqrt(1.81))\n\n[1] 0.9314382\n\n\nSie können das Ergebnis auch mit teachIRT::p_tirt() überprüfen. Bedenken Sie dabei aber, dass die Funktion Residualvarianzen erwartet. Sie müssen also \\(\\psi_j^2\\) und \\(\\psi_k^2\\) übergeben.\n\nteachIRT::p_tirt(\n        theta = c(0.5, 0), \n        mu = c(0.5, -1), \n        lambda = c(1, -0.9), \n        psi2 = c(1^2, 0.9^2)\n        )\n\n[1] 0.9314382\n\n\n\n\n\n\n\n\nIn der letzten Aufgabe sind Sie der CDF der Standardnormalverteilung, \\(\\Phi\\), begegnet. Die Funktion \\(\\Phi\\) erfüllt in IRT-Modellen i.d.R. den gleichen Zweck wie die logistische Funktion (siehe grundlegende Rechenkompetenzen). Das heißt \\(\\Phi\\) bildet eine reelle Zahl auf eine Wahrscheinlichkeit ab. Diesen Zusammenhang kann man formal auch als \\(\\Phi: \\mathbb{R} \\rightarrow [0, 1]\\) aufschreiben.\nIm folgenden Plot sehen Sie die Graphen beider Funktionen im Vergleich.\n\n\n\n\n\n\n\n\n\nModelle, die die logistische Funktion als sog. Link-Funktion verwenden, kann man auch als Logit-Modelle bezeichnen. Modelle, die die CDF der Standardnormalverteilung als Link-Funktion verwenden, kann man als Probit-Modelle bezeichnen.\n\n\n\n\nSie können die ICS des Thurstonian IRT Modells mit dem teachIRT Paket plotten. Stellen Sie zunächst theoretische Überlegungen darüber an, wie die ICSs des Thurstonian IRT Modells vermutlich aussehen. Überprüfen Sie dann Ihre Vermutung mit dem Befehl\n\nteachIRT::icc_tirt(\n        mu = c(0.5, -1),\n        lambda = c(1, -0.9),\n        psi = c(1, 0.9),\n        rotation = 30\n        )\n\nEntspricht das Ergebnis Ihren Erwartungen?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nteachIRT::icc_tirt(\n        mu = c(0.5, -1),\n        lambda = c(1, -0.9),\n        psi2 = c(1^2, 0.9^2),\n        rotation = 30\n        )\n\n\n\n\n\n\n\n\nDa die Antwort auf einen Paarvergleich laut Thurstonian IRT Modell von zwei latenten Traits abhängig ist, erhalten wir beim Thurstonian IRT eine Item Characteristic Surface (ICS).\n\n\n\n\nLesen Sie von der geplotteten ICS ab, wie wahrscheinlich es ist, Item \\(j\\) gegenüber Item \\(k\\) zu bevorzugen, wenn eine Person die Traitwerte \\(\\theta_a = 4\\) und \\(\\theta_b = -4\\) aufweist.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nMan kann ablesen, dass die Wahrscheinlichkeit fast \\(1\\) ist. Das ist natürlich nicht sehr genau. Den exakten Wert können wir mit teachIRT berechnen:\n\nteachIRT::p_tirt(\n    theta = c(4, -4),\n    mu = c(0.5, -1),\n    lambda = c(1, -0.9),\n    psi2 = c(1^2, 0.9^2)\n)\n\n[1] 0.9210631"
  },
  {
    "objectID": "sections/thurstonian_irt/thurstonian_irt.html#forced-choice-daten",
    "href": "sections/thurstonian_irt/thurstonian_irt.html#forced-choice-daten",
    "title": "Thurstonian Item Response Modell",
    "section": "",
    "text": "Im Folgenden sehen Sie die Datenmatrix eines forced-choice Tests mit zwei multidimensionalen Triplets.\n\\[\\begin{equation}\n    \\mathbf{U} =\n    \\begin{bmatrix}\n        1 & 1 & 0 & 0 & 1 & 1 \\\\\n        1 & 0 & 0 & 0 & 0 & 0 \\\\\n        0 & 0 & 1 & 1 & 0 & 0\\\\\n    \\end{bmatrix}\n\\end{equation}\\]\n\nWas bedeuten jeweils die Zeilen und Spalten der Datenmatrix?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nJede Zeile enthält die Antworten einer Person.\nJede Spalte entspricht einem binären Paarvergleich.\n\n\n\n\nIn welche Reihenfolge hat Person \\(3\\) die Items von Triplet \\(2\\) sortiert?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Spalten entsprechen von links nach rechts den folgenden Paarvergleichen:\nTriplet 1\n\nItem 1 aus Triplet 1 vs. Item 2 aus Triplet 1\nItem 1 aus Triplet 1 vs. Item 3 aus Triplet 1\nItem 2 aus Triplet 1 vs. Item 3 aus Triplet 1\n\nTriplet 2\n\nItem 1 aus Triplet 2 vs. Item 2 aus Triplet 2\nItem 1 aus Triplet 2 vs. Item 3 aus Triplet 2\nItem 2 aus Triplet 2 vs. Item 3 aus Triplet 2\n\nUm herauszufinden, in welche Reihenfolge Person \\(3\\) die Items von Triplet \\(2\\) sortiert hat, muss man also die Matrixeinträge in Zeile \\(3\\) und Spalten \\(4\\)-\\(6\\) betrachten.\nEs sind \\(u_{34} = 1\\), \\(u_{35} = 0\\), und \\(u_{36} = 0\\) die beobachteten Wert von Person \\(3\\) auf Triplet \\(2\\). Die Person muss die Items des Blocks also in die Reihenfolge \\(312\\) gebracht haben.\n\n\n\n\nEine vierte Person hat die beiden Triplets jeweils in die Reihenfolgen \\(132\\) und \\(312\\) sortiert. Ergänzen Sie die vierte Zeile der Datenmatrix.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nTriplet 1:\nDie Rangfolge ist \\(132\\).\nEs wurde Item 1 über Item 2 bevorzugt (1).\nEs wurde Item 1 über Item 3 bevorzugt (1).\nEs wurde nicht Item 3 über Item 2 bevorzugt (0).\nTriplet 2:\nDie Rangfolge ist \\(312\\).\nEs wurde Item 1 über Item 2 bevorzugt (1).\nEs wurde nicht Item 1 über Item 3 bevorzugt (0).\nEs wurde nicht Item 2 über Item 3 bevorzugt (0).\nDie ergänzte Matrix ist also\n\\[\\begin{equation}\n    \\mathbf{U} =\n    \\begin{bmatrix}\n        1 & 1 & 0 & 0 & 1 & 1 \\\\\n        1 & 0 & 0 & 0 & 0 & 0 \\\\\n        0 & 0 & 1 & 1 & 0 & 0 \\\\\n        1 & 1 & 0 & 1 & 0 & 0\n    \\end{bmatrix}\n\\end{equation}\\]\n\n\n\n\nWarum ist die Auswertung von forced-choice Daten mit Hilfe der Klassischen Testtheorie suboptimal?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie resultierenden Summenscores sind ipsativ."
  },
  {
    "objectID": "sections/thurstonian_irt/thurstonian_irt.html#thurstonian-irt",
    "href": "sections/thurstonian_irt/thurstonian_irt.html#thurstonian-irt",
    "title": "Thurstonian Item Response Modell",
    "section": "",
    "text": "Eine der Klassichen Testtheorie überlegene Auswertungsmethode für MFC Testantworten ist die Auswertung mit Hilfe spezialisierter Item Response Modelle. In der Vorlesung haben Sie das Thurstonian IRT Modell kennengelernt.\n\nAus dem Thurstonian IRT Modell lassen sich blockweise abhängige Item Characteristic Surface Functions (ICSs) herleiten. Suchen Sie die Formel für die ICS des Thurstonian IRT Modells in der Formelsammlung.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nBedingte Wahrscheinlichkeit, Item \\(i\\) gegenüber Item \\(k\\) zu bevorzugen:\n\\[\\begin{equation}\n\nP_l(y_l = 1 | \\theta_a, \\theta_b) = \\Phi \\Big( \\frac{\\mu_i - \\mu_k + \\lambda_i \\theta_a - \\lambda_k \\theta_b}{\\sqrt{\\psi^2_i + \\psi^2_k}} \\Big)\n\n\\end{equation}\\]\n\n\n\n\nDie Notation der Vorlesung weicht bei diesem Modell von den vorherigen IRT-Modellen ab. Es lohnt sich daher, die Bestandteile der Formel einzeln zu betrachten.\n1. Indices\nWas bedeuten hier die Indices \\(l\\), \\(a\\), \\(b\\), \\(i\\), und \\(k\\)?\n2. Daten\nWie steht \\(y_l\\) mit der bereits etablierten Datenmatrix \\(\\mathbf{U}\\) im Zusammenhang?\n3. Parameter\nWas bedeuten \\(\\theta_a\\), \\(\\theta_b\\), \\(\\mu_i\\), \\(\\mu_k\\), \\(\\lambda_i\\), \\(\\lambda_k\\), \\(\\psi_i\\), und \\(\\psi_k\\)?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(l\\): Paarvergleich\n\\(a\\): Erster Trait\n\\(b\\): Zweiter Trait\n\\(i\\): Erstes Item\n\\(k\\): Zweites Item\nDas \\(l\\) kodiert die Spalte der Datenmatrix. Es gibt keinen Personenparameter. Es geht also um eine beliebige Person.\n\\(\\theta_a\\): Traitwert auf dem ersten Trait (gemessen durch Item \\(i\\))\n\\(\\theta_b\\): Traitwert auf dem zweiten Trait (gemessen durch Item \\(k\\))\n\\(\\mu_i\\): Mittelwertsparameter von Item \\(i\\)\n\\(\\mu_k\\): Mittelwertsparameter von Item \\(k\\)\n\\(\\lambda_i\\): Faktorladung von Item \\(i\\) auf Trait \\(a\\)\n\\(\\lambda_k\\): Faktorladung von Item \\(k\\) auf Trait \\(b\\)\n\\(\\psi_i\\): Residual-Standardabweichung von Item \\(i\\)\n\\(\\psi_k\\): Residual-Standardabweichung von Item \\(k\\)\n\n\n\n\nWas bedeutet die Wahrscheinlichkeit \\(P(y_2 = 1 | \\theta_a, \\theta_b)\\) inhaltlich?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Wahrscheinlichkeit, dass eine Person mit den Traitwerten \\(\\theta_a\\) und \\(\\theta_b\\) auf dem zweiten Paarvergleich das erste Item von beiden bevorzugt.\n\n\n\n\nEine Person mit \\(\\theta_a = 0.5\\) und \\(\\theta_b = 0\\) bearbeitet ein MFC Paar. Die Itemparameter des MFC Paars sind \\(\\mu_j = 0.5\\), \\(\\mu_k = -1\\), \\(\\lambda_j = 1\\), \\(\\lambda_k = -0.9\\), \\(\\psi_j = 1\\), und \\(\\psi_k = 0.9\\). Berechnen Sie die Wahrscheinlichkeit, dass die Person Item \\(j\\) gegenüber Item \\(k\\) bevorzugt.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben:\n\\(\\theta_a = 0.5\\), \\(\\theta_b = 0\\)\n\\(\\mu_j = 0.5\\), \\(\\mu_k = -1\\)\n\\(\\lambda_j = 1\\), \\(\\lambda_k = -0.9\\)\n\\(\\psi_j = 1\\), \\(\\psi_k = 0.9\\)\nGesucht:\nDie Wahrscheinlichkeit, dass die Person Item \\(j\\) gegenüber Item \\(k\\) bevorzugt.\n\\[\\begin{equation}\n    P(y_l = 1 | \\theta_a, \\theta_b)\n\\end{equation}\\]\n\\[\\begin{equation}\n    = \\Phi(\n        \\frac{\n                \\mu_j - \\mu_k + \\lambda_j \\theta_a  - \\lambda_k \\theta_b\n            }{\n                \\sqrt{\\psi_j^2 + \\psi_k^2}\n            }\n    )\n\\end{equation}\\] \\[\\begin{equation}\n    = \\Phi(\n        \\frac{\n                0.5 + 1 + 0.5\n            }{\n                \\sqrt{1^2 + 0.9^2}\n            }\n    )\n\\end{equation}\\] \\[\\begin{equation}\n    = \\Phi(\\frac{2}{\\sqrt{1.81}})\n\\end{equation}\\] \\[\\begin{equation}\n    \\approx .93\n\\end{equation}\\]\n\\(\\Phi\\) steht hier für die kumulative Dichteverteilung (CDF) der Standardnormalverteilung. Die Vorschrift von \\(\\Phi\\) ist\n\\[\\begin{equation}\n    \\Phi(x) = \\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{x} e^{-t^2/2} dt\n\\end{equation}\\]\nDas Integral lässt sich nur näherungsweise berechnen. In R ist diese Berechnung mit der Funktion pnorm bereits implementiert.\n\npnorm(2 / sqrt(1.81))\n\n[1] 0.9314382\n\n\nSie können das Ergebnis auch mit teachIRT::p_tirt() überprüfen. Bedenken Sie dabei aber, dass die Funktion Residualvarianzen erwartet. Sie müssen also \\(\\psi_j^2\\) und \\(\\psi_k^2\\) übergeben.\n\nteachIRT::p_tirt(\n        theta = c(0.5, 0), \n        mu = c(0.5, -1), \n        lambda = c(1, -0.9), \n        psi2 = c(1^2, 0.9^2)\n        )\n\n[1] 0.9314382"
  },
  {
    "objectID": "sections/thurstonian_irt/thurstonian_irt.html#die-link-funktion-phi",
    "href": "sections/thurstonian_irt/thurstonian_irt.html#die-link-funktion-phi",
    "title": "Thurstonian Item Response Modell",
    "section": "",
    "text": "In der letzten Aufgabe sind Sie der CDF der Standardnormalverteilung, \\(\\Phi\\), begegnet. Die Funktion \\(\\Phi\\) erfüllt in IRT-Modellen i.d.R. den gleichen Zweck wie die logistische Funktion (siehe grundlegende Rechenkompetenzen). Das heißt \\(\\Phi\\) bildet eine reelle Zahl auf eine Wahrscheinlichkeit ab. Diesen Zusammenhang kann man formal auch als \\(\\Phi: \\mathbb{R} \\rightarrow [0, 1]\\) aufschreiben.\nIm folgenden Plot sehen Sie die Graphen beider Funktionen im Vergleich.\n\n\n\n\n\n\n\n\n\nModelle, die die logistische Funktion als sog. Link-Funktion verwenden, kann man auch als Logit-Modelle bezeichnen. Modelle, die die CDF der Standardnormalverteilung als Link-Funktion verwenden, kann man als Probit-Modelle bezeichnen."
  },
  {
    "objectID": "sections/thurstonian_irt/thurstonian_irt.html#iccs-im-thurstonian-irt-modell",
    "href": "sections/thurstonian_irt/thurstonian_irt.html#iccs-im-thurstonian-irt-modell",
    "title": "Thurstonian Item Response Modell",
    "section": "",
    "text": "Sie können die ICS des Thurstonian IRT Modells mit dem teachIRT Paket plotten. Stellen Sie zunächst theoretische Überlegungen darüber an, wie die ICSs des Thurstonian IRT Modells vermutlich aussehen. Überprüfen Sie dann Ihre Vermutung mit dem Befehl\n\nteachIRT::icc_tirt(\n        mu = c(0.5, -1),\n        lambda = c(1, -0.9),\n        psi = c(1, 0.9),\n        rotation = 30\n        )\n\nEntspricht das Ergebnis Ihren Erwartungen?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nteachIRT::icc_tirt(\n        mu = c(0.5, -1),\n        lambda = c(1, -0.9),\n        psi2 = c(1^2, 0.9^2),\n        rotation = 30\n        )\n\n\n\n\n\n\n\n\nDa die Antwort auf einen Paarvergleich laut Thurstonian IRT Modell von zwei latenten Traits abhängig ist, erhalten wir beim Thurstonian IRT eine Item Characteristic Surface (ICS).\n\n\n\n\nLesen Sie von der geplotteten ICS ab, wie wahrscheinlich es ist, Item \\(j\\) gegenüber Item \\(k\\) zu bevorzugen, wenn eine Person die Traitwerte \\(\\theta_a = 4\\) und \\(\\theta_b = -4\\) aufweist.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nMan kann ablesen, dass die Wahrscheinlichkeit fast \\(1\\) ist. Das ist natürlich nicht sehr genau. Den exakten Wert können wir mit teachIRT berechnen:\n\nteachIRT::p_tirt(\n    theta = c(4, -4),\n    mu = c(0.5, -1),\n    lambda = c(1, -0.9),\n    psi2 = c(1^2, 0.9^2)\n)\n\n[1] 0.9210631"
  },
  {
    "objectID": "sections/polytom/polytom.html",
    "href": "sections/polytom/polytom.html",
    "title": "IRT-Modelle für Polytome Daten",
    "section": "",
    "text": "Bisher haben wir IRT-Modelle für dichotome Daten behandelt. Das heißt die Datenmatrix enthielt nur Nullen und Einsen. Im Folgenden beschäftigen wir uns mit Modellen, die polytome Antwortformate modellieren können. Vorab möchten wir aber noch einem häufigen Missverständnis vorbeugen. Da IRT-Modelle für dichotome Daten oft so eingeführt werden, dass eine \\(0\\) in der Datenmatrix eine nicht gelöste Aufgabe repräsentiert und eine \\(1\\) eine gelöste Aufgabe, und da IRT-Modelle für polytome Daten oft so eingeführt werden, dass sie das Modellieren einer Likert-Skala ermöglichen, kann schnell das Missverständnis entstehen, dichotome IRT-Modelle seien nur für Leistungstests und polytome IRT-Modelle seien nur für Persönlichkeitstests geeignet. Dem ist nicht so. Sie können mit den behandelten IRT-Modellen für dichotome Daten, aber auch mit den im Folgenden behandelten IRT-Modellen für polytome Daten sowohl Persönlichkeitstests, wie auch Leistungstests modellieren. Wenn der Personenparameter \\(\\theta\\) auch im Personlichkeitskontext als “Fähigkeitsparameter” bezeichnet wird, ist das nur der historischen Entwicklung, aber nicht einer Limitation der Modelle geschuldet.\n\n\n\n\\(n = 4\\) Personen bearbeiten \\(m = 3\\) Items im 4-Punkt Ratingskalenformat. Notieren Sie eine mögliche Datenmatrix, \\(\\mathbf{U}\\), für diesen Fall.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\[\\begin{equation}\n    \\mathbf{U} =\n    \\begin{bmatrix}\n    0 & 1 & 2 \\\\\n    3 & 0 & 1 \\\\\n    2 & 3 & 0 \\\\\n    1 & 2 & 3\n    \\end{bmatrix}\n\\end{equation}\\]\n\n\n\nSie haben in der Vorlesung das PCM kennengelernt. Im PCM wird angenommen, dass die Wahrscheinlichkeiten für aufeinanderfolgende Schritte der Ratingskala Rasch-Modellen folgen:\n\\[\\begin{equation}\n    P(U_{ij} = c | u_{ij} \\in \\{c-1, c\\}, \\theta_i, \\delta_{jc}) =\n    \\frac{\n        exp( \\theta_i - \\delta_{jc} )\n    }{\n        1 + exp( \\theta_i - \\delta_{jc} )\n    }\n\\end{equation}\\]\n\nWas bedeuten die folgenden Wahrscheinlichkeiten inhaltlich?\n\n\\(P(U_{ij} = 3 | u_{ij} \\in \\{3-1, 3\\}, \\theta_i, \\delta_{j3})\\)\n\\(P(U_{ij} = c | u_{ij} \\in \\{c-1, c\\}, \\theta_i, \\delta_{jc})\\), mit \\(c = 1\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nDie Wahrscheinlichkeit Kategorie \\(3\\) statt Kategorie \\(2\\) zu wählen.\nDie Wahrscheinlichkeit, Kategorie \\(c = 1\\) statt der Kategorie \\(c-1 = 0\\) zu wählen.\n\n\n\n\nGegeben ist ein Item mit \\(\\boldsymbol{\\delta} = [-0.3, 1.2, 0.8]\\). Die folgende Abbildung zeigt die schrittweisen Wahrscheinlichkeiten, die nächstmögliche Antwortkategorie zu bevorzugen.\n\n\n\n\n\n\n\n\n\n\nBerechnen Sie die Wahrscheinlichkeit für den Sprung zwischen den Kategorien (1) \\(0\\) und \\(1\\), (2) \\(1\\) und \\(2\\), (3) \\(2\\) und \\(3\\) bei \\(\\theta = 0\\). Überprüfen Sie Ihr Ergebnis zunächst anhand der Abbildung der schrittweisen Antwortwahrscheinlichkeiten.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nKategorie 1 über Kategorie 0 bevorzugen:\n\\[\\begin{equation}\nP(U_{ij} = 1 | u_{ij} \\in \\{0, 1\\}, \\theta_i, \\delta_{j1}) =\n    \\frac{\n        exp( 0.3 )\n    }{\n        1 + exp( 0.3 )\n    } \\approx .57\n\\end{equation}\\]\n\nteachIRT::p_rasch(theta = 0, beta = -0.3)\n\n[1] 0.5744425\n\n\nKategorie 2 über Kategorie 1 bevorzugen:\n\\[\\begin{equation}\nP(U_{ij} = 2 | u_{ij} \\in \\{1, 2\\}, \\theta_i, \\delta_{j2}) =\n    \\frac{\n        exp( -1.2 )\n    }{\n        1 + exp( -1.2 )\n    } \\approx .23\n\\end{equation}\\]\n\nteachIRT::p_rasch(theta = 0, beta = 1.2)\n\n[1] 0.2314752\n\n\nKategorie 3 über Kategorie 2 bevorzugen:\n\\[\\begin{equation}\nP(U_{ij} = 2 | u_{ij} \\in \\{2, 3\\}, \\theta_i, \\delta_{j3}) =\n    \\frac{\n        exp( -0.8 )\n    }{\n        1 + exp( -0.8 )\n    } \\approx .31\n\\end{equation}\\]\n\nteachIRT::p_rasch(theta = 0, beta = 0.8)\n\n[1] 0.3100255\n\n\n\n\n\nAus der Gleichung bedingter Wahrscheinlichkeiten im PCM lassen sich unbedingte Kategorienwahrscheinlichkeiten herleiten.\n\\[\\begin{equation}\n    P(U_{ij} = c | \\theta_i, \\boldsymbol{\\delta}_j) =\n    \\frac{\n        exp( \\sum_{k = 0}^{c} (\\theta_i - \\delta_{jk}) )\n    }{\n        \\sum_{l = 0}^{m^{\\star}_j}[exp(\\sum_{k = 0}^{l} (\\theta_i - \\delta_{jk}))]\n    }\n\\end{equation}\\]\nmit \\(\\sum_{k = 0}^{0} (\\theta_i - \\delta_{jk}) \\equiv 0\\).\n\nSuchen die Formel für unbedingte Kategorienwahrscheinlichkeiten im PCM in der Formelsammlung.\n\nAufgrund der Doppelsumme im Nenner kann die Formel zunächst etwas erschlagend wirken. Im Zusatzmaterial finden Sie daher ein ausführliches Rechenbeispiel.\n\nBerechnen Sie \\(P(U_{ij} = 2 | \\theta_i, \\boldsymbol{\\delta})\\) für die Parameterwerte aus Aufgabe (c) bei \\(\\theta = 1\\).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben sind der Vektor der Schwellenparameter \\(\\boldsymbol{\\delta} = [-0.3, 1.2, 0.8]\\) und der Fähigkeitsparameter \\(\\theta = 1\\).\nDie Skala ist eine \\(4\\)-Punkt Skala mit möglichen Werten \\(U_{ij} \\in \\{0, 1, 2, 3\\}\\).\nIn den Beispielen hat eine Person in Kategorie \\(2\\) geantwortet.\n\\[\\begin{equation}\n    \\begin{split}\n        P(U_{ij} = 2 | \\theta, \\boldsymbol{\\delta})\n        \\\\\\\\\n        = \\frac{\n            exp(\\sum_{k = 0}^{c} (\\theta - \\delta_j))\n        }{\n        \\sum_{l = 0}^{m_j^*} [exp(\\sum_{k = 0}^{l} (\\theta - \\delta_j))]\n        }\\\\\\\\\n        = \\frac{\n            exp(0 + (1 + 0.3) + (1 - 1.2))\n        }{\n        \\begin{split}\n        exp(0)\\\\\n        + exp(0 + (1 + 0.3))\\\\\n        + exp(0 + (1 + 0.3) + (1 - 1.2))\\\\\n        + exp(0 + (1 + 0.3) + (1 - 1.2) + (1 - 0.8))\n        \\end{split}\n        }\\\\\\\\\n        = \\frac{exp(1.1)}{exp(0) + exp(1.3) + exp(1.1) + exp(1.3)}\\\\\n        \\\\\\\\\n        \\approx 0.265\n    \\end{split}\n\\end{equation}\\]\n\np &lt;- teachIRT::p_pcm(\n    theta = 1,\n    delta = c(-0.3, 1.2, 0.8)\n    )\nprint(p[3])\n\n[1] 0.2648532\n\n\n\n\n\nFalls Sie bei der vorherigen Aufgabe in die Lösung schauen mussten, haben wir hier noch einige Parameterwerte mit Lösungen gesammelt. Diese können Sie zum Üben bearbeiten. Falls Sie sich mit der Formel für Kategorienwahrscheinlichkeiten im PCM bereits sicher fühlen, können Sie diese Aufgabe aber auch überspringen. Denken Sie aber daran, dass die Formel ohne etwas Routine zum echten Zeitfresser werden kann. Es lohnt sich daher, mehr als eine Aufgabe damit zu rechnen.\n\nBerechnen Sie mit Hilfe des PCM:\n\\(P(U_{ij} = 1 | \\theta_i = -1, \\boldsymbol{\\delta} = [-0.3, 1.2, 0.8])\\)\n\\(P(U_{ij} = 4 | \\theta_i = 3, \\boldsymbol{\\delta} = [1, 0.8, 1.5, 2.1])\\)\n\\(P(U_{ij} = 2 \\mid \\theta_i = 0, \\boldsymbol{\\delta} = [-0.5, 0.7, 1.3])\\)\n\\(P(U_{ij} = 3 \\mid \\theta_i = 1.5, \\boldsymbol{\\delta} = [-1, 0.5, 1.2, 2])\\)\n\\(P(U_{ij} = 0 \\mid \\theta_i = -2, \\boldsymbol{\\delta} = [0.2, 1, 1.7])\\)\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(P(U_{ij} = 1 | \\theta_i = -1, \\boldsymbol{\\delta} = [-0.3, 1.2, 0.8]) \\approx .32\\)\n\nteachIRT::p_pcm(theta = -1, delta = c(-0.3, 1.2, 0.8))[2]\n\n[1] 0.3181804\n\n\n\\(P(U_{ij} = 4 | \\theta_i = 3, \\boldsymbol{\\delta} = [1, 0.8, 1.5, 2.1]) \\approx .66\\)\n\nteachIRT::p_pcm(theta = 3, delta = c(1, 0.8, 1.5, 2.1))[5]\n\n[1] 0.6628224\n\n\n\\(P(U_{ij} = 2 \\mid \\theta_i = 0, \\boldsymbol{\\delta} = [-0.5, 0.7, 1.3]) \\approx .22\\)\n\nteachIRT::p_pcm(theta = 0, delta = c(-0.5, 0.7, 1.3))[3]\n\n[1] 0.2218433\n\n\n\\(P(U_{ij} = 3 \\mid \\theta_i = 1.5, \\boldsymbol{\\delta} = [-1, 0.5, 1.2, 2]) \\approx .38\\)\n\nteachIRT::p_pcm(theta = 1.5, delta = c(-1, 0.5, 1.2, 2))[4]\n\n[1] 0.3784651\n\n\n\\(P(U_{ij} = 0 \\mid \\theta_i = -2, \\boldsymbol{\\delta} = [0.2, 1, 1.7]) \\approx .90\\)\n\nteachIRT::p_pcm(theta = -2, delta = c(0.2, 1, 1.7))[1]\n\n[1] 0.8956913\n\n\n\n\n\nIn der letzten Aufgabe haben Sie durch das PCM implizierte Wahrscheinlichkeiten berechnet, dass eine Person mit einem exakten Fähigkeitsparameter in einer exakten Kategorie antwortet. Die folgende Abbildung plottet die Kategorienwahrscheinlichkeiten für alle Kategorien und für ein festgelegtes Intervall von Fähigkeiten.\n\nteachIRT::icc_pcm(delta = c(-0.3, 1.2, 0.8))\n\n\n\n\n\n\n\n\n\nVersuchen Sie die zuvor berechnete Wahrscheinlichkeit \\(P(U_{ij} = 2 | \\theta, \\boldsymbol{\\delta})\\) in der Abbildung wiederzufinden.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nBlaue Kurve bei \\(1\\) auf der x-Achse ablesen\n\n\n\n\nDie Schwellenparameter des Items in Aufgabe (c) sind nicht geordnet. Welche Besonderheit ergibt sich daraus für die abgebildeten CCCs?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nKategorie 2 ist an keiner Stelle der Fähigkeitsachse die modale Kategorie.\n\n\n\n\nLesen Sie die Wahrscheinlichkeit ab, dass eine Person mit \\(\\theta = -1.5\\) die niedrigste Antwortkategorie wählt.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nMan kann in etwa .75 ablesen.\nDen genauen Wert können Sie händisch oder mit teachIRT ausrechnen:\n\nteachIRT::p_pcm(theta = -1.5, delta = c(-0.3, 1.2, 0.8))[1]\n\n[1] 0.755592\n\n\n\n\n\n\nSie können die Abbildung mit dem Befehl teachIRT::icc_pcm(delta = c(-0.3, 1.2, 0.8)) nachstellen. Probieren Sie aus, was passiert, wenn Sie die Werte verändern.\n\nDer mirt Befehl, um ein PCM zu schätzen ist mirt::mirt(data , 1, itemtype = \"Rasch\"). Das ist der gleiche Befehl, den man verwendet, um ein Rasch-Modell mit mirt zu schätzen.\n\n\nWarum ist die Benennung “Rasch” auch beim PCM sinnvoll?\nWie erkennt mirt, dass es sich um ein PCM handeln muss?\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nDas Rasch-Modell ist im PCM genestet. Wenn man das PCM mit zwei Kategorien spezifiziert wird es zum klassischen Rasch-Modell für dichotome Daten. Die zentralen Eigenschaften des Rasch-Modells bleiben im PCM erhalten.\nDie Anzahl an Kategorien erkennt mirt an der Datenmatrix. Da das Rasch-Modell ein Spezialfall des PCM ist, muss mirt allerdings nicht das eine oder andere Modell wählen.\n\n\n\n\n\nPlotten Sie ICCs für ein GPCM mit Hilfe des Befehls teachIRT::icc_gpcm(alpha = 0, delta = c(-2.5, 0, 2.5)).\nErhöhen Sie sukzessive den \\(\\alpha\\)-Parameter. Wie verändern sich die dargestellten Funktionen und was bedeutet die Veränderung des Parameters inhaltlich?\n\n\n\n\nEin GRM wurde genutzt, um ein Ratingskalenitem zu skalieren. Es ergeben sich die folgenden OCCs und CCCs:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\alpha = 1.2\\). Lesen Sie die übrigen Itemparameter ab.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(\\alpha = 1.2\\)\n\\(\\mathbf{\\delta} = [-1.5, -0.5, 0, 0.5]\\)\n\n\n\n\n\\(n = 200\\) Testand:innen beantworten das Item. Die Testand:innen haben Fähigkeiten, die der Verteilung \\(N(1, 0.5)\\) folgen. Welche Kategorie werden die Testand:innen erwartungsgemäß am häufigsten wählen?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nKategorie 4, da sie im Bereich der Verteilung der Personenparameter die höchste Kategorienwahrscheinlichkeit hat.\nMan kann das auch in einer kleinen Simulation überprüfen:\n\n# Einen seed wählen, damit Sampling replizierbar ist\nset.seed(434)\n\n# Fähigkeiten simulieren\nn &lt;- 200\ntheta &lt;- rnorm(n = n, mean = 1, sd = 0.5)\n\n# Itemparameter festlegen (siehe Lösung der vorherigen Aufgabe)\nalpha &lt;- 1.2\ndelta &lt;- c(-1.5, -0.5, 0, 0.5)\n\n# Einen leeren Antwortvektor initialisieren\nX &lt;- rep(NA, n)\n\n# Für jede Person eine Antwort anhand der Antwortwahrscheinlichkeiten simulieren\nfor (i in 1:n) {\n\n    # Kategorienwahrscheinlichkeiten der Person i berechnen\n    prob &lt;- teachIRT::p_grm(\n        theta = theta[i],\n        alpha = alpha,\n        delta = delta\n        )\n\n    # Eine Kategorie ziehen\n    X[i] &lt;- sample(0:length(delta), 1, prob = prob)\n\n}\n\n# Die beobachteten Antwortwahrscheinlichkeiten anzeigen\ntable(X) / n\n\nX\n    0     1     2     3     4 \n0.055 0.065 0.085 0.130 0.665 \n\n\nWie erwartet wurde Kategorie \\(4\\) am häufigsten gewählt.\n\n\n\nZum Weiterdenken:\nSie wissen, wie man die Wahrscheinlichkeit einer Kategorie an einem Punkt der \\(\\theta\\)-Achse berechnet. In der letzten Aufgabe sollten Sie aber herausfinden, welche Kategorie am häufigsten gewählt wird, wenn Sie Fähigkeiten interessieren, die aus einer Verteilung stammen. Im vorgegebenen Fall konnte man das graphisch anhand der CCCs abschätzen. Wie könnten Sie vorgehen, wenn die visuelle Inspektion keine eindeutige Antwort liefert oder Sie exakte Wahrscheinlichkeiten gegeben einer Verteilung von Personenparametern berechnen möchten? Welche Kategorie würde zum Beispiel erwartungsgemäß am häufigsten gewählt, wenn die \\(\\theta\\)-Werte aus der Verteilung \\(N(0.25, 0.75)\\) stammen?\n\nEine Person hat eine latente Fähigkeit von \\(\\theta = 1\\). Lesen Sie so genau Sie können die folgenden Werte ab:\n\nDie Wahrscheinlichkeit, dass die Person in der niedrigsten Kategorie antwortet\nDie Wahrscheinlichkeit, dass die Person mindestens in der niedrigsten Kategorie antwortet\n\\(P(U = 3 | \\theta = 1, \\boldsymbol{\\delta})\\)\n\\(P(U \\geq 1 | \\theta = 1, \\boldsymbol{\\delta})\\)\n\nDie OCCs und CCCs sind gegeben:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWir berechnen die Werte zur Kontrolle exakt.\n\nDie Wahrscheinlichkeit, dass die Person in der niedrigsten Kategorie antwortet\n\n\ntheta &lt;- 1\nalpha &lt;- 0.95\ndelta &lt;- c(-0.5, 0.5, 1, 1.75)\nteachIRT::p_grm(theta, alpha, delta)[1]\n\n[1] 0.1938789\n\n\n\nDie Wahrscheinlichkeit, dass die Person mindestens in der niedrigsten Kategorie antwortet\n\nDas müssten wir eigentlich nicht berechnen. Gegeben, dass die Person überhaupt eine Antwort gibt, wird sie immer mindestens in der niedrigsten Kategorie antworten.\n\nteachIRT::p_step_grm(theta, alpha, delta)[1]\n\n[1] 1\n\n\n\n\\(P(U = 3 | \\theta = 1, \\boldsymbol{\\delta})\\)\n\n\nteachIRT::p_grm(theta, alpha, delta)[4]\n\n[1] 0.1709533\n\n\n\n\\(P(U \\geq 1 | \\theta = 1, \\boldsymbol{\\delta})\\)\n\n\nteachIRT::p_step_grm(theta, alpha, delta)[2]\n\n[1] 0.8061211\n\n\n\n\n\n\nSuchen Sie die Formel zur Berechnung von Kategorienwahrscheinlichkeiten im GRM in der Formelsammlung. Berechnen Sie mit Hilfe der Formel \\(P(U = 4 | \\theta = 0, \\alpha = 1.5, \\boldsymbol{\\delta} = [-2, -0.5, 1, 1.2])\\).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(P(U = 4 | \\theta = 0, \\alpha = 1.5, \\boldsymbol{\\delta} = [-2, -0.5, 1, 1.2])\\)\n\\(=P^*(U \\ge 4) - 0\\)\n\\(=\\frac{1}{1 + e^{-\\alpha(\\theta - \\delta_4)}}\\) (verkürzte Form mit \\(\\frac{e^{x}}{1 + e^{x}} = \\frac{1}{1 + e^{-x}}\\) für alle \\(x \\in \\mathbb{R}\\))\n\\(=\\frac{1}{1 + e^{-1.5(0 - 1.2)}}\\)\n\\(\\approx .14\\)\nBerechnung in teachIRT:\n\ntheta = 0\nalpha = 1.5\ndelta = c(-2, -0.5, 1, 1.2)\nteachIRT::p_grm(theta, alpha, delta)[5]\n\n[1] 0.1418511"
  },
  {
    "objectID": "sections/polytom/polytom.html#generalized-partial-credit-model-gpcm",
    "href": "sections/polytom/polytom.html#generalized-partial-credit-model-gpcm",
    "title": "IRT-Modelle für Polytome Daten",
    "section": "",
    "text": "\\(n = 4\\) Personen bearbeiten \\(m = 3\\) Items im 4-Punkt Ratingskalenformat. Notieren Sie eine mögliche Datenmatrix, \\(\\mathbf{U}\\), für diesen Fall.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\[\\begin{equation}\n    \\mathbf{U} =\n    \\begin{bmatrix}\n    0 & 1 & 2 \\\\\n    3 & 0 & 1 \\\\\n    2 & 3 & 0 \\\\\n    1 & 2 & 3\n    \\end{bmatrix}\n\\end{equation}\\]\n\n\n\nSie haben in der Vorlesung das PCM kennengelernt. Im PCM wird angenommen, dass die Wahrscheinlichkeiten für aufeinanderfolgende Schritte der Ratingskala Rasch-Modellen folgen:\n\\[\\begin{equation}\n    P(U_{ij} = c | u_{ij} \\in \\{c-1, c\\}, \\theta_i, \\delta_{jc}) =\n    \\frac{\n        exp( \\theta_i - \\delta_{jc} )\n    }{\n        1 + exp( \\theta_i - \\delta_{jc} )\n    }\n\\end{equation}\\]\n\nWas bedeuten die folgenden Wahrscheinlichkeiten inhaltlich?\n\n\\(P(U_{ij} = 3 | u_{ij} \\in \\{3-1, 3\\}, \\theta_i, \\delta_{j3})\\)\n\\(P(U_{ij} = c | u_{ij} \\in \\{c-1, c\\}, \\theta_i, \\delta_{jc})\\), mit \\(c = 1\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nDie Wahrscheinlichkeit Kategorie \\(3\\) statt Kategorie \\(2\\) zu wählen.\nDie Wahrscheinlichkeit, Kategorie \\(c = 1\\) statt der Kategorie \\(c-1 = 0\\) zu wählen.\n\n\n\n\nGegeben ist ein Item mit \\(\\boldsymbol{\\delta} = [-0.3, 1.2, 0.8]\\). Die folgende Abbildung zeigt die schrittweisen Wahrscheinlichkeiten, die nächstmögliche Antwortkategorie zu bevorzugen.\n\n\n\n\n\n\n\n\n\n\nBerechnen Sie die Wahrscheinlichkeit für den Sprung zwischen den Kategorien (1) \\(0\\) und \\(1\\), (2) \\(1\\) und \\(2\\), (3) \\(2\\) und \\(3\\) bei \\(\\theta = 0\\). Überprüfen Sie Ihr Ergebnis zunächst anhand der Abbildung der schrittweisen Antwortwahrscheinlichkeiten.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nKategorie 1 über Kategorie 0 bevorzugen:\n\\[\\begin{equation}\nP(U_{ij} = 1 | u_{ij} \\in \\{0, 1\\}, \\theta_i, \\delta_{j1}) =\n    \\frac{\n        exp( 0.3 )\n    }{\n        1 + exp( 0.3 )\n    } \\approx .57\n\\end{equation}\\]\n\nteachIRT::p_rasch(theta = 0, beta = -0.3)\n\n[1] 0.5744425\n\n\nKategorie 2 über Kategorie 1 bevorzugen:\n\\[\\begin{equation}\nP(U_{ij} = 2 | u_{ij} \\in \\{1, 2\\}, \\theta_i, \\delta_{j2}) =\n    \\frac{\n        exp( -1.2 )\n    }{\n        1 + exp( -1.2 )\n    } \\approx .23\n\\end{equation}\\]\n\nteachIRT::p_rasch(theta = 0, beta = 1.2)\n\n[1] 0.2314752\n\n\nKategorie 3 über Kategorie 2 bevorzugen:\n\\[\\begin{equation}\nP(U_{ij} = 2 | u_{ij} \\in \\{2, 3\\}, \\theta_i, \\delta_{j3}) =\n    \\frac{\n        exp( -0.8 )\n    }{\n        1 + exp( -0.8 )\n    } \\approx .31\n\\end{equation}\\]\n\nteachIRT::p_rasch(theta = 0, beta = 0.8)\n\n[1] 0.3100255\n\n\n\n\n\nAus der Gleichung bedingter Wahrscheinlichkeiten im PCM lassen sich unbedingte Kategorienwahrscheinlichkeiten herleiten.\n\\[\\begin{equation}\n    P(U_{ij} = c | \\theta_i, \\boldsymbol{\\delta}_j) =\n    \\frac{\n        exp( \\sum_{k = 0}^{c} (\\theta_i - \\delta_{jk}) )\n    }{\n        \\sum_{l = 0}^{m^{\\star}_j}[exp(\\sum_{k = 0}^{l} (\\theta_i - \\delta_{jk}))]\n    }\n\\end{equation}\\]\nmit \\(\\sum_{k = 0}^{0} (\\theta_i - \\delta_{jk}) \\equiv 0\\).\n\nSuchen die Formel für unbedingte Kategorienwahrscheinlichkeiten im PCM in der Formelsammlung.\n\nAufgrund der Doppelsumme im Nenner kann die Formel zunächst etwas erschlagend wirken. Im Zusatzmaterial finden Sie daher ein ausführliches Rechenbeispiel.\n\nBerechnen Sie \\(P(U_{ij} = 2 | \\theta_i, \\boldsymbol{\\delta})\\) für die Parameterwerte aus Aufgabe (c) bei \\(\\theta = 1\\).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben sind der Vektor der Schwellenparameter \\(\\boldsymbol{\\delta} = [-0.3, 1.2, 0.8]\\) und der Fähigkeitsparameter \\(\\theta = 1\\).\nDie Skala ist eine \\(4\\)-Punkt Skala mit möglichen Werten \\(U_{ij} \\in \\{0, 1, 2, 3\\}\\).\nIn den Beispielen hat eine Person in Kategorie \\(2\\) geantwortet.\n\\[\\begin{equation}\n    \\begin{split}\n        P(U_{ij} = 2 | \\theta, \\boldsymbol{\\delta})\n        \\\\\\\\\n        = \\frac{\n            exp(\\sum_{k = 0}^{c} (\\theta - \\delta_j))\n        }{\n        \\sum_{l = 0}^{m_j^*} [exp(\\sum_{k = 0}^{l} (\\theta - \\delta_j))]\n        }\\\\\\\\\n        = \\frac{\n            exp(0 + (1 + 0.3) + (1 - 1.2))\n        }{\n        \\begin{split}\n        exp(0)\\\\\n        + exp(0 + (1 + 0.3))\\\\\n        + exp(0 + (1 + 0.3) + (1 - 1.2))\\\\\n        + exp(0 + (1 + 0.3) + (1 - 1.2) + (1 - 0.8))\n        \\end{split}\n        }\\\\\\\\\n        = \\frac{exp(1.1)}{exp(0) + exp(1.3) + exp(1.1) + exp(1.3)}\\\\\n        \\\\\\\\\n        \\approx 0.265\n    \\end{split}\n\\end{equation}\\]\n\np &lt;- teachIRT::p_pcm(\n    theta = 1,\n    delta = c(-0.3, 1.2, 0.8)\n    )\nprint(p[3])\n\n[1] 0.2648532\n\n\n\n\n\nFalls Sie bei der vorherigen Aufgabe in die Lösung schauen mussten, haben wir hier noch einige Parameterwerte mit Lösungen gesammelt. Diese können Sie zum Üben bearbeiten. Falls Sie sich mit der Formel für Kategorienwahrscheinlichkeiten im PCM bereits sicher fühlen, können Sie diese Aufgabe aber auch überspringen. Denken Sie aber daran, dass die Formel ohne etwas Routine zum echten Zeitfresser werden kann. Es lohnt sich daher, mehr als eine Aufgabe damit zu rechnen.\n\nBerechnen Sie mit Hilfe des PCM:\n\\(P(U_{ij} = 1 | \\theta_i = -1, \\boldsymbol{\\delta} = [-0.3, 1.2, 0.8])\\)\n\\(P(U_{ij} = 4 | \\theta_i = 3, \\boldsymbol{\\delta} = [1, 0.8, 1.5, 2.1])\\)\n\\(P(U_{ij} = 2 \\mid \\theta_i = 0, \\boldsymbol{\\delta} = [-0.5, 0.7, 1.3])\\)\n\\(P(U_{ij} = 3 \\mid \\theta_i = 1.5, \\boldsymbol{\\delta} = [-1, 0.5, 1.2, 2])\\)\n\\(P(U_{ij} = 0 \\mid \\theta_i = -2, \\boldsymbol{\\delta} = [0.2, 1, 1.7])\\)\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(P(U_{ij} = 1 | \\theta_i = -1, \\boldsymbol{\\delta} = [-0.3, 1.2, 0.8]) \\approx .32\\)\n\nteachIRT::p_pcm(theta = -1, delta = c(-0.3, 1.2, 0.8))[2]\n\n[1] 0.3181804\n\n\n\\(P(U_{ij} = 4 | \\theta_i = 3, \\boldsymbol{\\delta} = [1, 0.8, 1.5, 2.1]) \\approx .66\\)\n\nteachIRT::p_pcm(theta = 3, delta = c(1, 0.8, 1.5, 2.1))[5]\n\n[1] 0.6628224\n\n\n\\(P(U_{ij} = 2 \\mid \\theta_i = 0, \\boldsymbol{\\delta} = [-0.5, 0.7, 1.3]) \\approx .22\\)\n\nteachIRT::p_pcm(theta = 0, delta = c(-0.5, 0.7, 1.3))[3]\n\n[1] 0.2218433\n\n\n\\(P(U_{ij} = 3 \\mid \\theta_i = 1.5, \\boldsymbol{\\delta} = [-1, 0.5, 1.2, 2]) \\approx .38\\)\n\nteachIRT::p_pcm(theta = 1.5, delta = c(-1, 0.5, 1.2, 2))[4]\n\n[1] 0.3784651\n\n\n\\(P(U_{ij} = 0 \\mid \\theta_i = -2, \\boldsymbol{\\delta} = [0.2, 1, 1.7]) \\approx .90\\)\n\nteachIRT::p_pcm(theta = -2, delta = c(0.2, 1, 1.7))[1]\n\n[1] 0.8956913\n\n\n\n\n\nIn der letzten Aufgabe haben Sie durch das PCM implizierte Wahrscheinlichkeiten berechnet, dass eine Person mit einem exakten Fähigkeitsparameter in einer exakten Kategorie antwortet. Die folgende Abbildung plottet die Kategorienwahrscheinlichkeiten für alle Kategorien und für ein festgelegtes Intervall von Fähigkeiten.\n\nteachIRT::icc_pcm(delta = c(-0.3, 1.2, 0.8))\n\n\n\n\n\n\n\n\n\nVersuchen Sie die zuvor berechnete Wahrscheinlichkeit \\(P(U_{ij} = 2 | \\theta, \\boldsymbol{\\delta})\\) in der Abbildung wiederzufinden.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nBlaue Kurve bei \\(1\\) auf der x-Achse ablesen\n\n\n\n\nDie Schwellenparameter des Items in Aufgabe (c) sind nicht geordnet. Welche Besonderheit ergibt sich daraus für die abgebildeten CCCs?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nKategorie 2 ist an keiner Stelle der Fähigkeitsachse die modale Kategorie.\n\n\n\n\nLesen Sie die Wahrscheinlichkeit ab, dass eine Person mit \\(\\theta = -1.5\\) die niedrigste Antwortkategorie wählt.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nMan kann in etwa .75 ablesen.\nDen genauen Wert können Sie händisch oder mit teachIRT ausrechnen:\n\nteachIRT::p_pcm(theta = -1.5, delta = c(-0.3, 1.2, 0.8))[1]\n\n[1] 0.755592\n\n\n\n\n\n\nSie können die Abbildung mit dem Befehl teachIRT::icc_pcm(delta = c(-0.3, 1.2, 0.8)) nachstellen. Probieren Sie aus, was passiert, wenn Sie die Werte verändern.\n\nDer mirt Befehl, um ein PCM zu schätzen ist mirt::mirt(data , 1, itemtype = \"Rasch\"). Das ist der gleiche Befehl, den man verwendet, um ein Rasch-Modell mit mirt zu schätzen.\n\n\nWarum ist die Benennung “Rasch” auch beim PCM sinnvoll?\nWie erkennt mirt, dass es sich um ein PCM handeln muss?\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nDas Rasch-Modell ist im PCM genestet. Wenn man das PCM mit zwei Kategorien spezifiziert wird es zum klassischen Rasch-Modell für dichotome Daten. Die zentralen Eigenschaften des Rasch-Modells bleiben im PCM erhalten.\nDie Anzahl an Kategorien erkennt mirt an der Datenmatrix. Da das Rasch-Modell ein Spezialfall des PCM ist, muss mirt allerdings nicht das eine oder andere Modell wählen.\n\n\n\n\n\nPlotten Sie ICCs für ein GPCM mit Hilfe des Befehls teachIRT::icc_gpcm(alpha = 0, delta = c(-2.5, 0, 2.5)).\nErhöhen Sie sukzessive den \\(\\alpha\\)-Parameter. Wie verändern sich die dargestellten Funktionen und was bedeutet die Veränderung des Parameters inhaltlich?"
  },
  {
    "objectID": "sections/polytom/polytom.html#graded-response-model",
    "href": "sections/polytom/polytom.html#graded-response-model",
    "title": "IRT-Modelle für Polytome Daten",
    "section": "",
    "text": "Ein GRM wurde genutzt, um ein Ratingskalenitem zu skalieren. Es ergeben sich die folgenden OCCs und CCCs:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\alpha = 1.2\\). Lesen Sie die übrigen Itemparameter ab.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(\\alpha = 1.2\\)\n\\(\\mathbf{\\delta} = [-1.5, -0.5, 0, 0.5]\\)\n\n\n\n\n\\(n = 200\\) Testand:innen beantworten das Item. Die Testand:innen haben Fähigkeiten, die der Verteilung \\(N(1, 0.5)\\) folgen. Welche Kategorie werden die Testand:innen erwartungsgemäß am häufigsten wählen?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nKategorie 4, da sie im Bereich der Verteilung der Personenparameter die höchste Kategorienwahrscheinlichkeit hat.\nMan kann das auch in einer kleinen Simulation überprüfen:\n\n# Einen seed wählen, damit Sampling replizierbar ist\nset.seed(434)\n\n# Fähigkeiten simulieren\nn &lt;- 200\ntheta &lt;- rnorm(n = n, mean = 1, sd = 0.5)\n\n# Itemparameter festlegen (siehe Lösung der vorherigen Aufgabe)\nalpha &lt;- 1.2\ndelta &lt;- c(-1.5, -0.5, 0, 0.5)\n\n# Einen leeren Antwortvektor initialisieren\nX &lt;- rep(NA, n)\n\n# Für jede Person eine Antwort anhand der Antwortwahrscheinlichkeiten simulieren\nfor (i in 1:n) {\n\n    # Kategorienwahrscheinlichkeiten der Person i berechnen\n    prob &lt;- teachIRT::p_grm(\n        theta = theta[i],\n        alpha = alpha,\n        delta = delta\n        )\n\n    # Eine Kategorie ziehen\n    X[i] &lt;- sample(0:length(delta), 1, prob = prob)\n\n}\n\n# Die beobachteten Antwortwahrscheinlichkeiten anzeigen\ntable(X) / n\n\nX\n    0     1     2     3     4 \n0.055 0.065 0.085 0.130 0.665 \n\n\nWie erwartet wurde Kategorie \\(4\\) am häufigsten gewählt.\n\n\n\nZum Weiterdenken:\nSie wissen, wie man die Wahrscheinlichkeit einer Kategorie an einem Punkt der \\(\\theta\\)-Achse berechnet. In der letzten Aufgabe sollten Sie aber herausfinden, welche Kategorie am häufigsten gewählt wird, wenn Sie Fähigkeiten interessieren, die aus einer Verteilung stammen. Im vorgegebenen Fall konnte man das graphisch anhand der CCCs abschätzen. Wie könnten Sie vorgehen, wenn die visuelle Inspektion keine eindeutige Antwort liefert oder Sie exakte Wahrscheinlichkeiten gegeben einer Verteilung von Personenparametern berechnen möchten? Welche Kategorie würde zum Beispiel erwartungsgemäß am häufigsten gewählt, wenn die \\(\\theta\\)-Werte aus der Verteilung \\(N(0.25, 0.75)\\) stammen?\n\nEine Person hat eine latente Fähigkeit von \\(\\theta = 1\\). Lesen Sie so genau Sie können die folgenden Werte ab:\n\nDie Wahrscheinlichkeit, dass die Person in der niedrigsten Kategorie antwortet\nDie Wahrscheinlichkeit, dass die Person mindestens in der niedrigsten Kategorie antwortet\n\\(P(U = 3 | \\theta = 1, \\boldsymbol{\\delta})\\)\n\\(P(U \\geq 1 | \\theta = 1, \\boldsymbol{\\delta})\\)\n\nDie OCCs und CCCs sind gegeben:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWir berechnen die Werte zur Kontrolle exakt.\n\nDie Wahrscheinlichkeit, dass die Person in der niedrigsten Kategorie antwortet\n\n\ntheta &lt;- 1\nalpha &lt;- 0.95\ndelta &lt;- c(-0.5, 0.5, 1, 1.75)\nteachIRT::p_grm(theta, alpha, delta)[1]\n\n[1] 0.1938789\n\n\n\nDie Wahrscheinlichkeit, dass die Person mindestens in der niedrigsten Kategorie antwortet\n\nDas müssten wir eigentlich nicht berechnen. Gegeben, dass die Person überhaupt eine Antwort gibt, wird sie immer mindestens in der niedrigsten Kategorie antworten.\n\nteachIRT::p_step_grm(theta, alpha, delta)[1]\n\n[1] 1\n\n\n\n\\(P(U = 3 | \\theta = 1, \\boldsymbol{\\delta})\\)\n\n\nteachIRT::p_grm(theta, alpha, delta)[4]\n\n[1] 0.1709533\n\n\n\n\\(P(U \\geq 1 | \\theta = 1, \\boldsymbol{\\delta})\\)\n\n\nteachIRT::p_step_grm(theta, alpha, delta)[2]\n\n[1] 0.8061211\n\n\n\n\n\n\nSuchen Sie die Formel zur Berechnung von Kategorienwahrscheinlichkeiten im GRM in der Formelsammlung. Berechnen Sie mit Hilfe der Formel \\(P(U = 4 | \\theta = 0, \\alpha = 1.5, \\boldsymbol{\\delta} = [-2, -0.5, 1, 1.2])\\).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(P(U = 4 | \\theta = 0, \\alpha = 1.5, \\boldsymbol{\\delta} = [-2, -0.5, 1, 1.2])\\)\n\\(=P^*(U \\ge 4) - 0\\)\n\\(=\\frac{1}{1 + e^{-\\alpha(\\theta - \\delta_4)}}\\) (verkürzte Form mit \\(\\frac{e^{x}}{1 + e^{x}} = \\frac{1}{1 + e^{-x}}\\) für alle \\(x \\in \\mathbb{R}\\))\n\\(=\\frac{1}{1 + e^{-1.5(0 - 1.2)}}\\)\n\\(\\approx .14\\)\nBerechnung in teachIRT:\n\ntheta = 0\nalpha = 1.5\ndelta = c(-2, -0.5, 1, 1.2)\nteachIRT::p_grm(theta, alpha, delta)[5]\n\n[1] 0.1418511"
  },
  {
    "objectID": "sections/rechenkompetenzen_diagnostik/rechenkompetenzen_diagnostik.html",
    "href": "sections/rechenkompetenzen_diagnostik/rechenkompetenzen_diagnostik.html",
    "title": "Rechenkompetenzen der Diagnostik",
    "section": "",
    "text": "Belastbare psychologische Diagnostik ist an vielen Stellen auf diagnostische Rechenkompetenzen angewiesen. Im Folgenden werden einige dieser Kompetenzen geübt.\n\n\n\n\nTestwerte lassen sich durch den Vergleich mit einer Normstichprobe interpretieren. Im einfachsten Fall liegen dafür Normtabellen vor. Im Folgenden finden Sie den Auszug einer Normtabelle für den BDI-II:\n\nRoelofs, J., Van Breukelen, G., De Graaf, L. E., Beck, A. T., Arntz, A., & Huibers, M. J. H. (2013). Norms for the Beck Depression Inventory (BDI-II) in a large dutch community sample. , 35(1), 93–98. https://doi.org/10.1007/s10862-012-9309-2\n\n\n\nIn einer Studie wird der Zusammenhang zwischen Schlafgewohnheiten und depressiven Symptomen untersucht. In einer Subanalyse soll auf die Bevölkerung der \\(40\\%\\) betroffensten Frauen mit hohen Bildungsabschlüssen rückgeschlossen werden. Ob eine Person mit in die Analyse mit aufgenommen wird, soll anhand ihres BDI-II Scores entschieden werden. Ab welchem BDI-II Score sollte eine Frau mit hohem Bildungsabschluss in die Analyse aufgenommen werden?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nPersonen mit einem BDI-II Score \\(&gt;7\\) sollten in die Analyse mit aufgenommen werden.\n\n\n\n\n\n\nEs gibt verschiedene Normwerteverteilungen (z, IQ, T, SW, etc.), die anhand von Mittelwert und Standardabweichungen definiert sind. Wenn Mittelwert und Standardabweichung der Testwerte in einer Normstichprobe bekannt sind, können die Testwerte entsprechend normiert werden.\n\n\n\n\n\n\n\nNormbezeichnung\nTransformation\n\n\n\n\nz-Skala\n\\(z_i = \\frac{x_i - \\overline{x}}{SD(x)}\\)\n\n\nIQ-Abweichungsskala\n\\(IQ_i = 100 + 15 z_i\\)\n\n\nT-Werte\n\\(T_i = 50 + 10 z_i\\)\n\n\nStandardwerte\n\\(SW_i = 100 + 10 z_i\\)\n\n\nPISA-Skala\n\\(P_i = 500 + 100 z_i\\)\n\n\nStanine-Normwert\n\\(S_i \\approx 5 + 2 z_i\\)\n\n\nProzentrang\n\\(PR_i = 100 \\frac{freq_{\\text{cum}}(X_i)}{N}\\)\n\n\n\n\nEine Person erzielt einen Testwert von \\(36\\). In der Normstichprobe weisen die Testwerte einen Mittelwert von \\(\\overline{x} = 31\\) und eine Standardabweichung von \\(SD(x) = 5\\) auf.\n\nWelchen z-Wert hat die Person im Vergleich zur Normstichprobe?\nDer z-Wert lässt sich anhand der Formeln in andere Normwerte transformieren. Welcher T-Wert ergibt sich daraus?\n\n\n\n\n\n\n\n\nLösung (a)\n\n\n\n\n\nGegeben:\n\\(x = 36\\)\n\\(\\overline{x} = 31\\)\n\\(SD(x) = 5\\)\nGesucht:\n\\(z = \\frac{x - \\overline{x}}{SD(x)} = \\frac{36 - 31}{5} = 1\\)\n\n\n\n\n\n\n\n\n\nLösung (b)\n\n\n\n\n\nGegeben:\n\\(z = 1\\)\nGesucht:\n\\(T = 50 + 10z = 50 + 10 = 60\\)\n\n\n\n\n\n\n\nNutzen Sie den Code um die Daten der darunter folgenden Abbildung zu samplen.\n\nset.seed(101)\n        \n# Daten samplen\nN &lt;- 100\nx &lt;- rnorm(N, 2, 5)\nx &lt;- round(x)\n\nHistogramm:\n\n\n\n\n\n\n\n\n\n\nBerechnen Sie die Prozentränge in R und überprüfen Sie Ihr Ergebnis anhand der Abbildung.\n\nProzentränge:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nSie benötigen die Funktionen {r} table und {r} cumsum.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nset.seed(101)\n        \n# Daten samplen\nN &lt;- 100\nx &lt;- rnorm(N, 2, 5)\nx &lt;- round(x)\n\n# Prozentränge berechnen\ncumsum(table(x) / N)*100\n\n-10  -8  -7  -6  -5  -4  -3  -2  -1   0   1   2   3   4   5   6   7   8   9  10 \n  1   3   5   6  12  15  17  25  30  35  45  52  60  72  77  83  86  92  96  99 \n 11 \n100 \n\n\n\n\n\n\n\n\nDie Lesefähigkeit von Emilia wurde mit Hilfe eines validierten Leistungstests für Kinder erhoben. Um Emilias Leistung mit der Leistung von 9-Klässlerinnen in Rheinland-Pfälzer Gymnasien vergleichbar zu machen, wurde ihre Punktzahl von der leitenden Diagnostikerin zu einem \\(T\\)-Wert von \\(T = 56\\) transformiert.\n\n\nBerechnen Sie Emilias Leistung als IQ-Wert.\nBerechnen Sie den Prozentrang von Emilia innerhalb ihrer Schulklasse. In der Abbildung finden Sie dazu Häufigkeiten der T-Normwerte der Schüler:innen in Emilias Klasse.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLösung (a)\n\n\n\n\n\nGegeben:\n\\(T = 56\\)\nGesucht:\n\\(IQ = 100 + 15z\\)\n\\(z = \\frac{T - 50}{10}\\)\nAlso \\(IQ = 100 + 15 \\cdot \\Big(\\frac{T - 50}{10}\\Big) = 109\\)\n\n\n\n\n\n\n\n\n\nLösung (b)\n\n\n\n\n\nGesucht:\n\\(PR = 100 \\cdot \\frac{freq_{cum}(x)}{N}\\)\n\\(x = 56\\)\nAbgelesen:\n\\(freq_{cum}(56) = 5\\)\n\\(N = 15\\)\nAlso \\(PR = 100 \\frac{5}{15} \\approx 33.33\\)\n\n\n\n\n\n\nDie nächste Aufgabe ist etwas länger als die anderen. Sie werden in diesem Abschnitt Daten in R simulieren und selbst eine Normtabelle für einen Test erstellen.\nStellen Sie sich vor, Sie hätten in einem Forschungsprojekt einen Test mit drei Items entwickelt - zum Beispiel ein Screening Instrument zur Detektion von Spinnenangst. \\(N = 1000\\) Personen aus der Gesamtbevölkerung bewerteten die drei Items auf einer fünfstufigen Ratingskala (stimme nicht zu, stimme eher nicht zu, weder noch, stimme eher zu, stimme zu). Alle Items sind positiv gepolt.\nIhre Aufgabe wird es sein, anhand dieser Daten eine Normtabelle zu generieren, die nach Geschlecht (Mann, Frau, Divers) und fünf Altersbändern ([18, 25), [25, 35), [35, 45), [45, 55), [55, 65)) differenziert. Anwender:innen sollten anhand der Tabelle Summenscores in Standardwerte umwandeln können. Die folgenden Aufgaben leiten Sie schrittweise zu diesem Ergebnis.\nDer erste Schritt ist es, die Antworten der \\(N = 1000\\) Versuchspersonen in Ihrer R-Session zu generieren. Da es sich um ein fiktives Beispiel handelt, können wir selbst Übungsdaten simulieren. Genau das ist Ihre erste Aufgabe.\n\nKopieren Sie den folgenden Code-Abschnitt in Ihre IDE (z.B. RStudio) und führen sie den Code vollständig aus.\n\n# Seed setzen\nset.seed(5546)\n\n# Anzahl der Personen\nN &lt;- 1000\n\n# Anzahl der Items\nI &lt;- 3\n\n# Geschlecht der Personen festlegen\ngeschlecht &lt;- sample(\n  x = c(\"mann\", \"frau\", \"divers\"),\n  size = N, \n  replace = TRUE,\n  prob = c(0.46, 0.46, 0.08)\n  )\n\n# Altersgruppe der Personen festlegen\nalter &lt;- sample(\n  x = c(\"[18, 25)\", \"[25, 35)\", \"[35, 45)\", \"[45, 55)\", \"[55, 65)\"),\n  size = N,\n  replace = TRUE,\n  prob = c(0.15, 0.25, 0.25, 0.20, 0.15)\n)\n\n# Fragebogenantworten simulieren\nU &lt;- teachIRT::sim_pcm(n = N, m = I, m_star = 4) + 1\n\n# Fragebogenantworten und Datensatz mergen\ndat &lt;- dplyr::bind_cols(\n  person = 1:N,\n  geschlecht = geschlecht,\n  alter = alter,\n  U\n  )\n\n# Oberste zehn Zeilen des Datensatzes anzeigen\ndat &lt;- dplyr::as_tibble(dat)\nprint(dat)\n\n# A tibble: 1,000 × 6\n   person geschlecht alter    item_1 item_2 item_3\n    &lt;int&gt; &lt;chr&gt;      &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1      1 mann       [35, 45)      4      3      4\n 2      2 mann       [45, 55)      4      5      5\n 3      3 frau       [25, 35)      4      4      3\n 4      4 frau       [45, 55)      2      1      1\n 5      5 mann       [35, 45)      4      5      2\n 6      6 mann       [25, 35)      3      2      2\n 7      7 frau       [35, 45)      3      3      1\n 8      8 mann       [55, 65)      3      5      4\n 9      9 frau       [55, 65)      4      3      4\n10     10 mann       [18, 25)      4      4      3\n# ℹ 990 more rows\n\n\n\nNun sollten Sie in Ihrer R-Session auf den Datensatz dat zugreifen können. Da Sie zu Beginn mit dem Befehl set.seed() einen bestimmten Startwert für die Zufallsziehungen im Code-Abschnitt festlegen, sollten Sie, wenn Sie den Code-Abschnitt wiederholt vollständig ausführen auch immer wieder die gleichen Daten generieren.\nZuerst verschaffen wir uns einen Überblick über den Datensatz. Versuchen Sie Folgendes herauszufinden:\n\n\nWelche Variablen hat der Datensatz?\nWelche möglichen Werte haben die Variablen jeweils?\nWie viele Zeilen hat der Datensatz?\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWelche Variablen hat der Datensatz?\nUm das herauszufinden, kann man den Befehl colnames(dat) verwenden.\n\ncolnames(dat)\n\n[1] \"person\"     \"geschlecht\" \"alter\"      \"item_1\"     \"item_2\"    \n[6] \"item_3\"    \n\n\nWelche möglichen Werte haben die Variablen jeweils?\ndat$person enthält natürliche Zahlen von \\(1\\) bis \\(1000\\) und kodiert, zu welcher Person eine Zeile jeweils gehört. Hier die ersten 10 Personen:\n\ndat$person[1:10]\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nDie möglichen Werte (und Häufigkeiten) der Geschlechtsvariable, dat$geschlecht, und der Altersvariable, dat$alter, können Sie sich so anzeigen:\n\ntable(dat$geschlecht)\n\n\ndivers   frau   mann \n    60    452    488 \n\ntable(dat$alter)\n\n\n[18, 25) [25, 35) [35, 45) [45, 55) [55, 65) \n     153      235      251      191      170 \n\n\nDie Variablen dat$item_1 bis dat$item_5 enthalten die Antworten auf die fünf Fragebogenitems:\n\ntable(dat$item_1)\n\n\n  1   2   3   4   5 \n 58 225 391 256  70 \n\ntable(dat$item_2)\n\n\n  1   2   3   4   5 \n 59 215 389 264  73 \n\ntable(dat$item_3)\n\n\n  1   2   3   4   5 \n 74 237 340 258  91 \n\n\nWie viele Zeilen hat der Datensatz?\nDafür können wir den Befehl nrow() verwenden.\n\nnrow(dat)\n\n[1] 1000\n\n\n\n\n\n\nWenn Sie der Struktur dieser Aufgabe folgen, werden Sie recht kleinschrittig zur fertigen Normtabelle geleitet. Überlegen Sie dennoch vorher selbst, welche Schritte Sie unternehmen müssten, um aus den simulierten Daten eine Tabelle zu erzeugen, die es Ihnen ermöglicht, jeden Rohwert in einen Standardwert zu transformieren.\n\nIm nächsten Schritt Berechnen Sie aus den Antworten auf die drei Items für jede Person einen Summenscore. Später in der Vorlesung und Übung werden Sie Alternativen zum Summenscore kennenlernen. Für diese Aufgabe wird es aber ausreichen, Test-Scores durch einfache Summen zu erzeugen.\n\nErzeugen Sie eine neue Variable dat$score im Datensatz, indem Sie die Antworten auf die drei Items summieren.\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\n\ndat$score &lt;- ...\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat$score &lt;- dat$item_1 + dat$item_2 + dat$item_3\n\n\n\n\nWenn wir nun den Datensatz anzeigen, ist die neue Variable score zu sehen:\n\nprint(dat)\n\n# A tibble: 1,000 × 7\n   person geschlecht alter    item_1 item_2 item_3 score\n    &lt;int&gt; &lt;chr&gt;      &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1      1 mann       [35, 45)      4      3      4    11\n 2      2 mann       [45, 55)      4      5      5    14\n 3      3 frau       [25, 35)      4      4      3    11\n 4      4 frau       [45, 55)      2      1      1     4\n 5      5 mann       [35, 45)      4      5      2    11\n 6      6 mann       [25, 35)      3      2      2     7\n 7      7 frau       [35, 45)      3      3      1     7\n 8      8 mann       [55, 65)      3      5      4    12\n 9      9 frau       [55, 65)      4      3      4    11\n10     10 mann       [18, 25)      4      4      3    11\n# ℹ 990 more rows\n\n\nIn den vorherigen Rechenaufgaben haben Sie verwendet, dass man einen Score in einen beliebigen Normwert transformieren kann, wenn man den Mittelwert und die Standardabweichung der Scores in Normstichprobe kennt. In der nächsten Aufgabe werden Sie daher Mittelwert und Standardabweichung für jede Kombination von Geschlecht und Altersbändern berechnen.\n\nBerechnen Sie für jede Kombination von Geschlecht und Altersband einen mittleren Score und eine Standardabweichung der Scores. Das Ergebnis sollte ein data.frame (oder tibble) mit den Spalten geschlecht, alter, score_mean (Mittelwert in der Zelle), score_sd (Standardabweichung in der Zelle) sein. Nennen Sie den data.frame dstats.\n\nFür diesen Schritt können Sie auch die Lösung kopieren, falls Sie selten mit R arbeiten.\n\n\n\n\n\n\nTipp\n\n\n\n\n\n\n# Mittelwert\nm &lt;- aggregate(score ~ geschlecht + ???, dat, mean)\n\n# Standardabweichung\ns &lt;- aggregate(???, dat, ???)\n\n# Neu berechnete Spalten umbenennen\nnames(m)[3] &lt;- \"score_mean\"\nnames(s)[3] &lt;- \"score_sd\"\n\n# Zu dstats mergen\ndstats &lt;- merge(???, s, by = c(???, \"alter\"))\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# Mittelwert\nm &lt;- aggregate(score ~ geschlecht + alter, dat, mean)\n\n# Standardabweichung\ns &lt;- aggregate(score ~ geschlecht + alter, dat, sd)\n\n# Neu berechnete Spalten umbenennen\nnames(m)[3] &lt;- \"score_mean\"\nnames(s)[3] &lt;- \"score_sd\"\n\n# Zu dstats mergen\ndstats &lt;- merge(m, s, by = c(\"geschlecht\", \"alter\"))\n\n# Optional für schöneres Printing in tibble umwandeln:\ndstats &lt;- dplyr::as_tibble(dstats)\n\n\n\n\n\n\n\n\n\n\nExkurs\n\n\n\n\n\nWenn Sie planen noch lange mit R zu arbeiten, lohnt sich an dieser Stelle ein Blick in das https://tidyverse.org/. Mit dem Paket dplyr gelangen Sie folgendermaßen an das gleiche Ziel:\n\nlibrary(dplyr)\n\ndstats &lt;- dat |&gt; \n\n  # Daten gruppieren\n  group_by(geschlecht, alter) |&gt; \n\n  # Mittelwert und Standardabweichung berechnen\n  summarise(\n    score_mean = mean(score),\n    score_sd = sd(score),\n    .groups = \"drop\"\n    )\n\nDie Denkweise beliebig zu gruppieren und dann Zeilen in Gruppen zusammenzufassen finde ich persönlich etwas angenehmer.\n\n\n\nDer resultierende data.frame sollte so aussehen:\n\nprint(dstats)\n\n# A tibble: 15 × 4\n   geschlecht alter    score_mean score_sd\n   &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n 1 divers     [18, 25)       8.55     1.63\n 2 divers     [25, 35)       8        2.36\n 3 divers     [35, 45)       8.35     3.10\n 4 divers     [45, 55)       8.82     2.32\n 5 divers     [55, 65)      10.1      2.39\n 6 frau       [18, 25)       9        2.58\n 7 frau       [25, 35)       9.44     2.35\n 8 frau       [35, 45)       9.51     2.43\n 9 frau       [45, 55)       9.08     2.32\n10 frau       [55, 65)       9.13     2.04\n11 mann       [18, 25)       9.49     2.39\n12 mann       [25, 35)       8.97     2.31\n13 mann       [35, 45)       9.06     2.32\n14 mann       [45, 55)       9.39     2.32\n15 mann       [55, 65)       9.06     2.43\n\n\nFür jede Kombination der Geschlechts- und Altersvariable können Sie nun den Score-Mittelwert und die Standardabweichung ablesen. Diese Information ist ausreichend, um Summenscores (/Rohwerte) in z-Werte und anschließend in Standardwerte umzuwandeln. Berechnen Sie vor der Erstellung der gesamten Tabelle ein einzelnes Wertebeispiel.\n\nBerechnen Sie den Standardwert einer 32-jährigen Frau mit einem Summenscore von \\(4\\).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben:\n\\(x_i = 4\\) Summenscore\n\\(\\overline{x} = 9.44\\) Score-Mittelwert in der Normstichprobe\n\\(SD(x) = 2.35\\) Score-Standardabweichung in der Normstichprobe\nGesucht:\n\\(SW_i = 100 + 10 \\cdot z_i\\) Standardwert\nBerechnung:\n\\(z_i = \\frac{x_i - \\overline{x}}{SD(x)} = \\frac{4 - 9.44}{2.35}\\)\n\\(SW_i = 100 + 10 \\cdot \\frac{4 - 9.44}{2.35}\\)\nMit dem Taschenrechner:\n\nz_i &lt;- (4 - 9.44) / 2.35\nSW_i &lt;- 100 + 10 * z_i\nprint(SW_i)\n\n[1] 76.85106\n\n\nGerundet ergibt sich \\(SW_i \\approx 76.85\\), ein weit unterdurchschnittlicher Wert.\n\n\n\nNun können wir uns an die gesamte Tabelle machen. Überlegen Sie dafür zuerst, welcher Wert der minimal erreichbare Summenscore und welcher der maximal erreichbare Summenscore wäre.\n\nWas sind jeweils der minimal und maximal erreichbare Summenscore im Beispiel?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDen kleinstmöglichen Wert erhalten Sie, wenn Sie in allen drei Items Kategorie \\(1\\) wählen, also \\(1 + 1+ 1 = 3\\).\nDen höchstmöglichen Wert erhalten Sie, wenn Sie in allen drei Items Kategorie \\(5\\) wählen, also \\(5 + 5 + 5 = 15\\).\nDie Spanne/Range der simulierten Summenscores spiegelt diese Überlegung wider:\n\nrange(dat$score)\n\n[1]  3 15\n\n\n\n\n\nWir benötigen also für jede Kombination von Geschlecht und Alter sowie jeden Summenscore zwischen 3 und 15 einen Standardwert. Um die Aufgabe etwas zu reduzieren, können Sie sich auf die möglichen Scores \\(8, 10, 12\\) beschränken.\n\nBerechnen Sie für jede Kombination von Geschlecht und Altersband den Standardwert der Summenscores \\(8\\), \\(10\\) und \\(12\\).\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nBei dieser Aufgabe müssen Sie für jeden möglichen Summenscore (\\(8\\), \\(10\\), \\(12\\)) eine Spalte an dstats anfügen, die Standardwerte enthält.\n\n\n\n\n\n\n\n\n\nTipp: z-Werte für Rohwert 8\n\n\n\n\n\nAls Zwischenschritt ist es sinnvoll, zunächst z-Werte für jede Kombination von Geschlecht und Altersband zu berechnen. Das geht für einen Summenscore von \\(8\\) so:\n\ndstats$z_8 &lt;- (8 - dstats$score_mean)/dstats$score_sd\n\n\n\n\n\n\n\n\n\n\nTipp: Standardwerte für Rohwert 8\n\n\n\n\n\nAls nächstes muss man die z-Werte mit der Formel \\(SW_i = 100 + 10 \\cdot z_i\\) in Standardwerte transformieren. So geht das im Fall eines Summenscores von \\(8\\):\n\ndstats$sw_8 &lt;- 100 + 10*dstats$z_8\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# z-Werte berechnen\ndstats$z_8 &lt;- (8 - dstats$score_mean)/dstats$score_sd\ndstats$z_10 &lt;- (10 - dstats$score_mean)/dstats$score_sd\ndstats$z_12 &lt;- (12 - dstats$score_mean)/dstats$score_sd\n\n# Standardwerte berechnen\ndstats$sw_8 &lt;- 100 + 10*dstats$z_8\ndstats$sw_10 &lt;- 100 + 10*dstats$z_10\ndstats$sw_12 &lt;- 100 + 10*dstats$z_12\n\n# z-Wert wieder löschen\ndstats$z_8 &lt;- NULL\ndstats$z_10 &lt;- NULL\ndstats$z_12 &lt;- NULL\n\n\n\n\nDie fertige Normtabelle sollte etwa so aussehen:\n\nprint(dstats)\n\n# A tibble: 15 × 7\n   geschlecht alter    score_mean score_sd  sw_8 sw_10 sw_12\n   &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 divers     [18, 25)       8.55     1.63  96.7 109.   121.\n 2 divers     [25, 35)       8        2.36 100   108.   117.\n 3 divers     [35, 45)       8.35     3.10  98.9 105.   112.\n 4 divers     [45, 55)       8.82     2.32  96.5 105.   114.\n 5 divers     [55, 65)      10.1      2.39  91.2  99.6  108.\n 6 frau       [18, 25)       9        2.58  96.1 104.   112.\n 7 frau       [25, 35)       9.44     2.35  93.9 102.   111.\n 8 frau       [35, 45)       9.51     2.43  93.8 102.   110.\n 9 frau       [45, 55)       9.08     2.32  95.3 104.   113.\n10 frau       [55, 65)       9.13     2.04  94.4 104.   114.\n11 mann       [18, 25)       9.49     2.39  93.7 102.   111.\n12 mann       [25, 35)       8.97     2.31  95.8 104.   113.\n13 mann       [35, 45)       9.06     2.32  95.4 104.   113.\n14 mann       [45, 55)       9.39     2.32  94.0 103.   111.\n15 mann       [55, 65)       9.06     2.43  95.6 104.   112.\n\n\n\nLesen Sie zuletzt den Standardwert eines 45-jährigen Mannes mit einem Summenscore von 12 ab.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(111\\)\n\n\n\n\nZu Beginn diser Aufgabe sollten Sie selbst überlegen, welche Schritte Sie unternehmen müssten, um aus den Daten eine Normtabelle zu erzeugen. Vergleichen Sie nun Ihre Erwartung mit den durchgeführten Schritten.\n\n\n\n\n\nLeider sind Diagnosen nicht immer zutreffend. Es kann durchaus passieren, dass eine Person, die eigentlich geeignet wäre, als ungeeignet klassifiert wird. Genauso kann es passieren, dass eine Person, die eigentlich ungeeignet ist, als geeignet klassifiziert wird.\n\n\n\n\nErstellen Sie eine Tabelle aller möglichen Kombinationen aus wahren Zuständen \\({\\text{geeignet}, \\text{ungeeignet}}\\) und Diagnosen \\({\\text{geeignet}, \\text{ungeeignet}}\\).\nBenennen Sie jede der vier Kombinationen. Verwenden Sie dazu die folgenden Begriffe:\n\n\nFalsch positiv (FP)\nRichtig positiv (RP)\nFalsch negativ (FN)\nRichtig negativ (RN)\nFalse negative (FN)\nFalse positive (FP)\nTrue negative (TN)\nTrue positive (TP)\n\n\nNehmen Sie an, dass eine Person mit einem Testwert \\(&gt;20\\) als geeignet eingestuft wird. Finden Sie einen beispielhaften Testwert für jeden der vier Zustände.\n\n\n\n\n\n\n\n\nTipp: Tabellengerüst\n\n\n\n\n\nSo soll die Tabelle am Ende aussehen:\n\n\n\n\n\n\n\n\n\n\nWahrer Zustand\nTestwert Beispiel\nDiagnose\nPrüfung [De]\nPrüfung [Eng]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJetzt fehlen noch die Werte.\n\n\n\n\n\n\n\n\n\nTipp: Teile von a. vorgeben\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWahrer Zustand\nTestwert Beispiel\nDiagnose\nPrüfung [De]\nPrüfung [Eng]\n\n\n\n\nGeeignet\n\n\n\n\n\n\n\n\nUngeeignet\n\n\n\n\nUngeeignet\n\n\n\n\n\n\n\n\nUngeeignet\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipp: Teile von b. vorgeben\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWahrer Zustand\nTestwert Beispiel\nDiagnose\nPrüfung [De]\nPrüfung [Eng]\n\n\n\n\nGeeignet\n\n\nRP\n\n\n\n\n\nUngeeignet\n\nFN\n\n\nUngeeignet\n\n\n\n\n\n\n\n\nUngeeignet\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nTabelle aller Kreuzungen von wahren Zuständen und Diagnosen (dichotom)\n\n\n\n\n\n\n\n\n\nWahrer Zustand\nTestwert Beispiel\nDiagnose\nPrüfung [De]\nPrüfung [Eng]\n\n\n\n\nGeeignet\n\\(21\\)\nGeeignet\nRP\nTP\n\n\nGeeignet\n\\(20\\)\nUngeeignet\nFN\nFN\n\n\nUngeeignet\n\\(23\\)\nGeeignet\nFP\nFP\n\n\nUngeeignet\n\\(13\\)\nUngeeignet\nRN\nTN\n\n\n\n\n\n\n\n\n\nErgänzen Sie die Formeln für die Sensitivität und Spezifität. Versuchen Sie es zuerst ohne die Vorlesungsfolien und überprüfen Sie dann Ihr Ergebnis.\n\n\\(\\text{Sensitivität} = \\frac{RP}{? + ?}\\)\n\\(\\text{Spezifität} = \\frac{?}{? + RN}\\)\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(\\text{Sensitivität} = \\frac{RP}{RP + FN}\\)\n\\(\\text{Spezifität} = \\frac{RN}{FP + RN}\\)\n\n\n\n\n\n\n\nEine Schule möchte einen neuen Test verwenden, um hochbegabte Schüler:innen frühzeitig zu identifizieren. Ein etablierter Intelligenztest wird als Vergleichsstandard zur Überprüfung der Testvorhersagen herangezogen. Die Testergebnisse für eine Stichprobe von 500 Kindern sind:\n\n\n\nUrteil neuer Test\nUrteil etablierter Test\n\\(n\\)\n\n\n\n\nHochbegabt\nHochbegabt\n\\(10\\)\n\n\nHochbegabt\nNicht hochbegabt\n\\(3\\)\n\n\nNicht hochbegabt\nNicht hochbegabt\n\\(482\\)\n\n\nNicht hochbegabt\nHochbegabt\n\\(5\\)\n\n\n\nBerechnen Sie die Sensitivität und Spezifität des neuen Tests.\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nGegeben:\n\\(RP = ?\\)\n\\(FP = ?\\)\n\\(RN = ?\\)\n\\(FN = ?\\)\nGesucht:\nSensitivität \\(= \\frac{RP}{RP + FN} = ?\\)\nSpezifität \\(= \\frac{RN}{FP + RN} = ?\\)\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben:\n\\(RP = 10\\)\n\\(FP = 3\\)\n\\(RN = 482\\)\n\\(FN = 5\\)\nGesucht:\nSensitivität \\(= \\frac{RP}{RP + FN} = \\frac{10}{10 + 5} \\approx .67\\)\nSpezifität \\(= \\frac{RN}{FP + RN} = \\frac{482}{3 + 482} \\approx .99\\)\n\n\n\n\n\n\nDie Testwerte ungeeigneter Testpersonen sind normalverteilt mit \\(X_u \\sim N(-1.5, 3)\\). Die Testwerte geeigneter Testpersonen sind normalverteilt mit \\(X_g \\sim N(4, 3)\\). Eine Person wird als geeignet klassifiziert, wenn Sie einen Testwert \\(&gt;3\\) aufweist. In der Abbildung sehen Sie die Dichterverteilungen der Testwerte ungeeigneter und geeigneter Personen.\n\n\n\n\n\n\n\n\n\nDie gelb markierte Fläche umfasst \\(93\\%\\) der Fläche unter der linken Verteilung. Die blau markierte Fläche umfasst \\(63\\%\\) der Fläche unter der rechten Verteilung.\n\nBerechnen Sie den Youden-Index.\n\n\n\n\n\n\n\nTipp 1\n\n\n\n\n\nGegeben:\n\\(RN = ?\\)\n\\(RP = ?\\)\n\n\n\n\n\n\n\n\n\nTipp 2\n\n\n\n\n\nGesucht:\nSensitivität \\(=?\\)\nSpezifität \\(=?\\)\nYouden-Index \\(=?\\)\n\n\n\n\n\n\n\n\n\nTipp 3\n\n\n\n\n\nGegeben:\n\\(RN = ?\\)\n\\(RP = ?\\)\nGesucht:\nSensitivität \\(= \\frac{RP}{FN + RP} = ?\\)\nSpezifität \\(= \\frac{RN}{FP + RN} = ?\\)\n\\(\\text{Youden-Index} = \\text{Sensitivität} + \\text{Spezifität} - 1 = ?\\)\n\n\n\n\n\n\n\n\n\nTipp 4: RN und RP vorgeben\n\n\n\n\n\nGegeben:\n\\(RN = .93\\)\n\\(RP = .63\\)\nGesucht:\nSensitivität \\(= \\frac{RP}{FN + RP} = ?\\)\nSpezifität \\(= \\frac{RN}{FP + RN} = ?\\)\n\\(\\text{Youden-Index} = \\text{Sensitivität} + \\text{Spezifität} - 1 = ?\\)\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben:\n\\(RN = .93\\)\n\\(RP = .63\\)\nGesucht:\nSensitivität \\(= \\frac{RP}{FN + RP} = \\frac{.63}{(1-.63) + .63} = .63\\)\nSpezifität \\(= \\frac{RN}{FP + RN} = \\frac{.93}{(1-.93) + .93} = .93\\)\n\\(\\text{Youden-Index} = \\text{Sensitivität} + \\text{Spezifität} - 1 = .63 + .93 - 1 = .56\\)"
  },
  {
    "objectID": "sections/rechenkompetenzen_diagnostik/rechenkompetenzen_diagnostik.html#ablesen-und-berechnen-von-normwerten",
    "href": "sections/rechenkompetenzen_diagnostik/rechenkompetenzen_diagnostik.html#ablesen-und-berechnen-von-normwerten",
    "title": "Rechenkompetenzen der Diagnostik",
    "section": "",
    "text": "Testwerte lassen sich durch den Vergleich mit einer Normstichprobe interpretieren. Im einfachsten Fall liegen dafür Normtabellen vor. Im Folgenden finden Sie den Auszug einer Normtabelle für den BDI-II:\n\nRoelofs, J., Van Breukelen, G., De Graaf, L. E., Beck, A. T., Arntz, A., & Huibers, M. J. H. (2013). Norms for the Beck Depression Inventory (BDI-II) in a large dutch community sample. , 35(1), 93–98. https://doi.org/10.1007/s10862-012-9309-2\n\n\n\nIn einer Studie wird der Zusammenhang zwischen Schlafgewohnheiten und depressiven Symptomen untersucht. In einer Subanalyse soll auf die Bevölkerung der \\(40\\%\\) betroffensten Frauen mit hohen Bildungsabschlüssen rückgeschlossen werden. Ob eine Person mit in die Analyse mit aufgenommen wird, soll anhand ihres BDI-II Scores entschieden werden. Ab welchem BDI-II Score sollte eine Frau mit hohem Bildungsabschluss in die Analyse aufgenommen werden?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nPersonen mit einem BDI-II Score \\(&gt;7\\) sollten in die Analyse mit aufgenommen werden.\n\n\n\n\n\n\nEs gibt verschiedene Normwerteverteilungen (z, IQ, T, SW, etc.), die anhand von Mittelwert und Standardabweichungen definiert sind. Wenn Mittelwert und Standardabweichung der Testwerte in einer Normstichprobe bekannt sind, können die Testwerte entsprechend normiert werden.\n\n\n\n\n\n\n\nNormbezeichnung\nTransformation\n\n\n\n\nz-Skala\n\\(z_i = \\frac{x_i - \\overline{x}}{SD(x)}\\)\n\n\nIQ-Abweichungsskala\n\\(IQ_i = 100 + 15 z_i\\)\n\n\nT-Werte\n\\(T_i = 50 + 10 z_i\\)\n\n\nStandardwerte\n\\(SW_i = 100 + 10 z_i\\)\n\n\nPISA-Skala\n\\(P_i = 500 + 100 z_i\\)\n\n\nStanine-Normwert\n\\(S_i \\approx 5 + 2 z_i\\)\n\n\nProzentrang\n\\(PR_i = 100 \\frac{freq_{\\text{cum}}(X_i)}{N}\\)\n\n\n\n\nEine Person erzielt einen Testwert von \\(36\\). In der Normstichprobe weisen die Testwerte einen Mittelwert von \\(\\overline{x} = 31\\) und eine Standardabweichung von \\(SD(x) = 5\\) auf.\n\nWelchen z-Wert hat die Person im Vergleich zur Normstichprobe?\nDer z-Wert lässt sich anhand der Formeln in andere Normwerte transformieren. Welcher T-Wert ergibt sich daraus?\n\n\n\n\n\n\n\n\nLösung (a)\n\n\n\n\n\nGegeben:\n\\(x = 36\\)\n\\(\\overline{x} = 31\\)\n\\(SD(x) = 5\\)\nGesucht:\n\\(z = \\frac{x - \\overline{x}}{SD(x)} = \\frac{36 - 31}{5} = 1\\)\n\n\n\n\n\n\n\n\n\nLösung (b)\n\n\n\n\n\nGegeben:\n\\(z = 1\\)\nGesucht:\n\\(T = 50 + 10z = 50 + 10 = 60\\)\n\n\n\n\n\n\n\nNutzen Sie den Code um die Daten der darunter folgenden Abbildung zu samplen.\n\nset.seed(101)\n        \n# Daten samplen\nN &lt;- 100\nx &lt;- rnorm(N, 2, 5)\nx &lt;- round(x)\n\nHistogramm:\n\n\n\n\n\n\n\n\n\n\nBerechnen Sie die Prozentränge in R und überprüfen Sie Ihr Ergebnis anhand der Abbildung.\n\nProzentränge:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nSie benötigen die Funktionen {r} table und {r} cumsum.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nset.seed(101)\n        \n# Daten samplen\nN &lt;- 100\nx &lt;- rnorm(N, 2, 5)\nx &lt;- round(x)\n\n# Prozentränge berechnen\ncumsum(table(x) / N)*100\n\n-10  -8  -7  -6  -5  -4  -3  -2  -1   0   1   2   3   4   5   6   7   8   9  10 \n  1   3   5   6  12  15  17  25  30  35  45  52  60  72  77  83  86  92  96  99 \n 11 \n100 \n\n\n\n\n\n\n\n\nDie Lesefähigkeit von Emilia wurde mit Hilfe eines validierten Leistungstests für Kinder erhoben. Um Emilias Leistung mit der Leistung von 9-Klässlerinnen in Rheinland-Pfälzer Gymnasien vergleichbar zu machen, wurde ihre Punktzahl von der leitenden Diagnostikerin zu einem \\(T\\)-Wert von \\(T = 56\\) transformiert.\n\n\nBerechnen Sie Emilias Leistung als IQ-Wert.\nBerechnen Sie den Prozentrang von Emilia innerhalb ihrer Schulklasse. In der Abbildung finden Sie dazu Häufigkeiten der T-Normwerte der Schüler:innen in Emilias Klasse.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLösung (a)\n\n\n\n\n\nGegeben:\n\\(T = 56\\)\nGesucht:\n\\(IQ = 100 + 15z\\)\n\\(z = \\frac{T - 50}{10}\\)\nAlso \\(IQ = 100 + 15 \\cdot \\Big(\\frac{T - 50}{10}\\Big) = 109\\)\n\n\n\n\n\n\n\n\n\nLösung (b)\n\n\n\n\n\nGesucht:\n\\(PR = 100 \\cdot \\frac{freq_{cum}(x)}{N}\\)\n\\(x = 56\\)\nAbgelesen:\n\\(freq_{cum}(56) = 5\\)\n\\(N = 15\\)\nAlso \\(PR = 100 \\frac{5}{15} \\approx 33.33\\)\n\n\n\n\n\n\nDie nächste Aufgabe ist etwas länger als die anderen. Sie werden in diesem Abschnitt Daten in R simulieren und selbst eine Normtabelle für einen Test erstellen.\nStellen Sie sich vor, Sie hätten in einem Forschungsprojekt einen Test mit drei Items entwickelt - zum Beispiel ein Screening Instrument zur Detektion von Spinnenangst. \\(N = 1000\\) Personen aus der Gesamtbevölkerung bewerteten die drei Items auf einer fünfstufigen Ratingskala (stimme nicht zu, stimme eher nicht zu, weder noch, stimme eher zu, stimme zu). Alle Items sind positiv gepolt.\nIhre Aufgabe wird es sein, anhand dieser Daten eine Normtabelle zu generieren, die nach Geschlecht (Mann, Frau, Divers) und fünf Altersbändern ([18, 25), [25, 35), [35, 45), [45, 55), [55, 65)) differenziert. Anwender:innen sollten anhand der Tabelle Summenscores in Standardwerte umwandeln können. Die folgenden Aufgaben leiten Sie schrittweise zu diesem Ergebnis.\nDer erste Schritt ist es, die Antworten der \\(N = 1000\\) Versuchspersonen in Ihrer R-Session zu generieren. Da es sich um ein fiktives Beispiel handelt, können wir selbst Übungsdaten simulieren. Genau das ist Ihre erste Aufgabe.\n\nKopieren Sie den folgenden Code-Abschnitt in Ihre IDE (z.B. RStudio) und führen sie den Code vollständig aus.\n\n# Seed setzen\nset.seed(5546)\n\n# Anzahl der Personen\nN &lt;- 1000\n\n# Anzahl der Items\nI &lt;- 3\n\n# Geschlecht der Personen festlegen\ngeschlecht &lt;- sample(\n  x = c(\"mann\", \"frau\", \"divers\"),\n  size = N, \n  replace = TRUE,\n  prob = c(0.46, 0.46, 0.08)\n  )\n\n# Altersgruppe der Personen festlegen\nalter &lt;- sample(\n  x = c(\"[18, 25)\", \"[25, 35)\", \"[35, 45)\", \"[45, 55)\", \"[55, 65)\"),\n  size = N,\n  replace = TRUE,\n  prob = c(0.15, 0.25, 0.25, 0.20, 0.15)\n)\n\n# Fragebogenantworten simulieren\nU &lt;- teachIRT::sim_pcm(n = N, m = I, m_star = 4) + 1\n\n# Fragebogenantworten und Datensatz mergen\ndat &lt;- dplyr::bind_cols(\n  person = 1:N,\n  geschlecht = geschlecht,\n  alter = alter,\n  U\n  )\n\n# Oberste zehn Zeilen des Datensatzes anzeigen\ndat &lt;- dplyr::as_tibble(dat)\nprint(dat)\n\n# A tibble: 1,000 × 6\n   person geschlecht alter    item_1 item_2 item_3\n    &lt;int&gt; &lt;chr&gt;      &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1      1 mann       [35, 45)      4      3      4\n 2      2 mann       [45, 55)      4      5      5\n 3      3 frau       [25, 35)      4      4      3\n 4      4 frau       [45, 55)      2      1      1\n 5      5 mann       [35, 45)      4      5      2\n 6      6 mann       [25, 35)      3      2      2\n 7      7 frau       [35, 45)      3      3      1\n 8      8 mann       [55, 65)      3      5      4\n 9      9 frau       [55, 65)      4      3      4\n10     10 mann       [18, 25)      4      4      3\n# ℹ 990 more rows\n\n\n\nNun sollten Sie in Ihrer R-Session auf den Datensatz dat zugreifen können. Da Sie zu Beginn mit dem Befehl set.seed() einen bestimmten Startwert für die Zufallsziehungen im Code-Abschnitt festlegen, sollten Sie, wenn Sie den Code-Abschnitt wiederholt vollständig ausführen auch immer wieder die gleichen Daten generieren.\nZuerst verschaffen wir uns einen Überblick über den Datensatz. Versuchen Sie Folgendes herauszufinden:\n\n\nWelche Variablen hat der Datensatz?\nWelche möglichen Werte haben die Variablen jeweils?\nWie viele Zeilen hat der Datensatz?\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWelche Variablen hat der Datensatz?\nUm das herauszufinden, kann man den Befehl colnames(dat) verwenden.\n\ncolnames(dat)\n\n[1] \"person\"     \"geschlecht\" \"alter\"      \"item_1\"     \"item_2\"    \n[6] \"item_3\"    \n\n\nWelche möglichen Werte haben die Variablen jeweils?\ndat$person enthält natürliche Zahlen von \\(1\\) bis \\(1000\\) und kodiert, zu welcher Person eine Zeile jeweils gehört. Hier die ersten 10 Personen:\n\ndat$person[1:10]\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nDie möglichen Werte (und Häufigkeiten) der Geschlechtsvariable, dat$geschlecht, und der Altersvariable, dat$alter, können Sie sich so anzeigen:\n\ntable(dat$geschlecht)\n\n\ndivers   frau   mann \n    60    452    488 \n\ntable(dat$alter)\n\n\n[18, 25) [25, 35) [35, 45) [45, 55) [55, 65) \n     153      235      251      191      170 \n\n\nDie Variablen dat$item_1 bis dat$item_5 enthalten die Antworten auf die fünf Fragebogenitems:\n\ntable(dat$item_1)\n\n\n  1   2   3   4   5 \n 58 225 391 256  70 \n\ntable(dat$item_2)\n\n\n  1   2   3   4   5 \n 59 215 389 264  73 \n\ntable(dat$item_3)\n\n\n  1   2   3   4   5 \n 74 237 340 258  91 \n\n\nWie viele Zeilen hat der Datensatz?\nDafür können wir den Befehl nrow() verwenden.\n\nnrow(dat)\n\n[1] 1000\n\n\n\n\n\n\nWenn Sie der Struktur dieser Aufgabe folgen, werden Sie recht kleinschrittig zur fertigen Normtabelle geleitet. Überlegen Sie dennoch vorher selbst, welche Schritte Sie unternehmen müssten, um aus den simulierten Daten eine Tabelle zu erzeugen, die es Ihnen ermöglicht, jeden Rohwert in einen Standardwert zu transformieren.\n\nIm nächsten Schritt Berechnen Sie aus den Antworten auf die drei Items für jede Person einen Summenscore. Später in der Vorlesung und Übung werden Sie Alternativen zum Summenscore kennenlernen. Für diese Aufgabe wird es aber ausreichen, Test-Scores durch einfache Summen zu erzeugen.\n\nErzeugen Sie eine neue Variable dat$score im Datensatz, indem Sie die Antworten auf die drei Items summieren.\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\n\ndat$score &lt;- ...\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat$score &lt;- dat$item_1 + dat$item_2 + dat$item_3\n\n\n\n\nWenn wir nun den Datensatz anzeigen, ist die neue Variable score zu sehen:\n\nprint(dat)\n\n# A tibble: 1,000 × 7\n   person geschlecht alter    item_1 item_2 item_3 score\n    &lt;int&gt; &lt;chr&gt;      &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1      1 mann       [35, 45)      4      3      4    11\n 2      2 mann       [45, 55)      4      5      5    14\n 3      3 frau       [25, 35)      4      4      3    11\n 4      4 frau       [45, 55)      2      1      1     4\n 5      5 mann       [35, 45)      4      5      2    11\n 6      6 mann       [25, 35)      3      2      2     7\n 7      7 frau       [35, 45)      3      3      1     7\n 8      8 mann       [55, 65)      3      5      4    12\n 9      9 frau       [55, 65)      4      3      4    11\n10     10 mann       [18, 25)      4      4      3    11\n# ℹ 990 more rows\n\n\nIn den vorherigen Rechenaufgaben haben Sie verwendet, dass man einen Score in einen beliebigen Normwert transformieren kann, wenn man den Mittelwert und die Standardabweichung der Scores in Normstichprobe kennt. In der nächsten Aufgabe werden Sie daher Mittelwert und Standardabweichung für jede Kombination von Geschlecht und Altersbändern berechnen.\n\nBerechnen Sie für jede Kombination von Geschlecht und Altersband einen mittleren Score und eine Standardabweichung der Scores. Das Ergebnis sollte ein data.frame (oder tibble) mit den Spalten geschlecht, alter, score_mean (Mittelwert in der Zelle), score_sd (Standardabweichung in der Zelle) sein. Nennen Sie den data.frame dstats.\n\nFür diesen Schritt können Sie auch die Lösung kopieren, falls Sie selten mit R arbeiten.\n\n\n\n\n\n\nTipp\n\n\n\n\n\n\n# Mittelwert\nm &lt;- aggregate(score ~ geschlecht + ???, dat, mean)\n\n# Standardabweichung\ns &lt;- aggregate(???, dat, ???)\n\n# Neu berechnete Spalten umbenennen\nnames(m)[3] &lt;- \"score_mean\"\nnames(s)[3] &lt;- \"score_sd\"\n\n# Zu dstats mergen\ndstats &lt;- merge(???, s, by = c(???, \"alter\"))\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# Mittelwert\nm &lt;- aggregate(score ~ geschlecht + alter, dat, mean)\n\n# Standardabweichung\ns &lt;- aggregate(score ~ geschlecht + alter, dat, sd)\n\n# Neu berechnete Spalten umbenennen\nnames(m)[3] &lt;- \"score_mean\"\nnames(s)[3] &lt;- \"score_sd\"\n\n# Zu dstats mergen\ndstats &lt;- merge(m, s, by = c(\"geschlecht\", \"alter\"))\n\n# Optional für schöneres Printing in tibble umwandeln:\ndstats &lt;- dplyr::as_tibble(dstats)\n\n\n\n\n\n\n\n\n\n\nExkurs\n\n\n\n\n\nWenn Sie planen noch lange mit R zu arbeiten, lohnt sich an dieser Stelle ein Blick in das https://tidyverse.org/. Mit dem Paket dplyr gelangen Sie folgendermaßen an das gleiche Ziel:\n\nlibrary(dplyr)\n\ndstats &lt;- dat |&gt; \n\n  # Daten gruppieren\n  group_by(geschlecht, alter) |&gt; \n\n  # Mittelwert und Standardabweichung berechnen\n  summarise(\n    score_mean = mean(score),\n    score_sd = sd(score),\n    .groups = \"drop\"\n    )\n\nDie Denkweise beliebig zu gruppieren und dann Zeilen in Gruppen zusammenzufassen finde ich persönlich etwas angenehmer.\n\n\n\nDer resultierende data.frame sollte so aussehen:\n\nprint(dstats)\n\n# A tibble: 15 × 4\n   geschlecht alter    score_mean score_sd\n   &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n 1 divers     [18, 25)       8.55     1.63\n 2 divers     [25, 35)       8        2.36\n 3 divers     [35, 45)       8.35     3.10\n 4 divers     [45, 55)       8.82     2.32\n 5 divers     [55, 65)      10.1      2.39\n 6 frau       [18, 25)       9        2.58\n 7 frau       [25, 35)       9.44     2.35\n 8 frau       [35, 45)       9.51     2.43\n 9 frau       [45, 55)       9.08     2.32\n10 frau       [55, 65)       9.13     2.04\n11 mann       [18, 25)       9.49     2.39\n12 mann       [25, 35)       8.97     2.31\n13 mann       [35, 45)       9.06     2.32\n14 mann       [45, 55)       9.39     2.32\n15 mann       [55, 65)       9.06     2.43\n\n\nFür jede Kombination der Geschlechts- und Altersvariable können Sie nun den Score-Mittelwert und die Standardabweichung ablesen. Diese Information ist ausreichend, um Summenscores (/Rohwerte) in z-Werte und anschließend in Standardwerte umzuwandeln. Berechnen Sie vor der Erstellung der gesamten Tabelle ein einzelnes Wertebeispiel.\n\nBerechnen Sie den Standardwert einer 32-jährigen Frau mit einem Summenscore von \\(4\\).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben:\n\\(x_i = 4\\) Summenscore\n\\(\\overline{x} = 9.44\\) Score-Mittelwert in der Normstichprobe\n\\(SD(x) = 2.35\\) Score-Standardabweichung in der Normstichprobe\nGesucht:\n\\(SW_i = 100 + 10 \\cdot z_i\\) Standardwert\nBerechnung:\n\\(z_i = \\frac{x_i - \\overline{x}}{SD(x)} = \\frac{4 - 9.44}{2.35}\\)\n\\(SW_i = 100 + 10 \\cdot \\frac{4 - 9.44}{2.35}\\)\nMit dem Taschenrechner:\n\nz_i &lt;- (4 - 9.44) / 2.35\nSW_i &lt;- 100 + 10 * z_i\nprint(SW_i)\n\n[1] 76.85106\n\n\nGerundet ergibt sich \\(SW_i \\approx 76.85\\), ein weit unterdurchschnittlicher Wert.\n\n\n\nNun können wir uns an die gesamte Tabelle machen. Überlegen Sie dafür zuerst, welcher Wert der minimal erreichbare Summenscore und welcher der maximal erreichbare Summenscore wäre.\n\nWas sind jeweils der minimal und maximal erreichbare Summenscore im Beispiel?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDen kleinstmöglichen Wert erhalten Sie, wenn Sie in allen drei Items Kategorie \\(1\\) wählen, also \\(1 + 1+ 1 = 3\\).\nDen höchstmöglichen Wert erhalten Sie, wenn Sie in allen drei Items Kategorie \\(5\\) wählen, also \\(5 + 5 + 5 = 15\\).\nDie Spanne/Range der simulierten Summenscores spiegelt diese Überlegung wider:\n\nrange(dat$score)\n\n[1]  3 15\n\n\n\n\n\nWir benötigen also für jede Kombination von Geschlecht und Alter sowie jeden Summenscore zwischen 3 und 15 einen Standardwert. Um die Aufgabe etwas zu reduzieren, können Sie sich auf die möglichen Scores \\(8, 10, 12\\) beschränken.\n\nBerechnen Sie für jede Kombination von Geschlecht und Altersband den Standardwert der Summenscores \\(8\\), \\(10\\) und \\(12\\).\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nBei dieser Aufgabe müssen Sie für jeden möglichen Summenscore (\\(8\\), \\(10\\), \\(12\\)) eine Spalte an dstats anfügen, die Standardwerte enthält.\n\n\n\n\n\n\n\n\n\nTipp: z-Werte für Rohwert 8\n\n\n\n\n\nAls Zwischenschritt ist es sinnvoll, zunächst z-Werte für jede Kombination von Geschlecht und Altersband zu berechnen. Das geht für einen Summenscore von \\(8\\) so:\n\ndstats$z_8 &lt;- (8 - dstats$score_mean)/dstats$score_sd\n\n\n\n\n\n\n\n\n\n\nTipp: Standardwerte für Rohwert 8\n\n\n\n\n\nAls nächstes muss man die z-Werte mit der Formel \\(SW_i = 100 + 10 \\cdot z_i\\) in Standardwerte transformieren. So geht das im Fall eines Summenscores von \\(8\\):\n\ndstats$sw_8 &lt;- 100 + 10*dstats$z_8\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# z-Werte berechnen\ndstats$z_8 &lt;- (8 - dstats$score_mean)/dstats$score_sd\ndstats$z_10 &lt;- (10 - dstats$score_mean)/dstats$score_sd\ndstats$z_12 &lt;- (12 - dstats$score_mean)/dstats$score_sd\n\n# Standardwerte berechnen\ndstats$sw_8 &lt;- 100 + 10*dstats$z_8\ndstats$sw_10 &lt;- 100 + 10*dstats$z_10\ndstats$sw_12 &lt;- 100 + 10*dstats$z_12\n\n# z-Wert wieder löschen\ndstats$z_8 &lt;- NULL\ndstats$z_10 &lt;- NULL\ndstats$z_12 &lt;- NULL\n\n\n\n\nDie fertige Normtabelle sollte etwa so aussehen:\n\nprint(dstats)\n\n# A tibble: 15 × 7\n   geschlecht alter    score_mean score_sd  sw_8 sw_10 sw_12\n   &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 divers     [18, 25)       8.55     1.63  96.7 109.   121.\n 2 divers     [25, 35)       8        2.36 100   108.   117.\n 3 divers     [35, 45)       8.35     3.10  98.9 105.   112.\n 4 divers     [45, 55)       8.82     2.32  96.5 105.   114.\n 5 divers     [55, 65)      10.1      2.39  91.2  99.6  108.\n 6 frau       [18, 25)       9        2.58  96.1 104.   112.\n 7 frau       [25, 35)       9.44     2.35  93.9 102.   111.\n 8 frau       [35, 45)       9.51     2.43  93.8 102.   110.\n 9 frau       [45, 55)       9.08     2.32  95.3 104.   113.\n10 frau       [55, 65)       9.13     2.04  94.4 104.   114.\n11 mann       [18, 25)       9.49     2.39  93.7 102.   111.\n12 mann       [25, 35)       8.97     2.31  95.8 104.   113.\n13 mann       [35, 45)       9.06     2.32  95.4 104.   113.\n14 mann       [45, 55)       9.39     2.32  94.0 103.   111.\n15 mann       [55, 65)       9.06     2.43  95.6 104.   112.\n\n\n\nLesen Sie zuletzt den Standardwert eines 45-jährigen Mannes mit einem Summenscore von 12 ab.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(111\\)\n\n\n\n\nZu Beginn diser Aufgabe sollten Sie selbst überlegen, welche Schritte Sie unternehmen müssten, um aus den Daten eine Normtabelle zu erzeugen. Vergleichen Sie nun Ihre Erwartung mit den durchgeführten Schritten."
  },
  {
    "objectID": "sections/rechenkompetenzen_diagnostik/rechenkompetenzen_diagnostik.html#sensitivität-spezifität-roc-kurven-youden-index",
    "href": "sections/rechenkompetenzen_diagnostik/rechenkompetenzen_diagnostik.html#sensitivität-spezifität-roc-kurven-youden-index",
    "title": "Rechenkompetenzen der Diagnostik",
    "section": "",
    "text": "Leider sind Diagnosen nicht immer zutreffend. Es kann durchaus passieren, dass eine Person, die eigentlich geeignet wäre, als ungeeignet klassifiert wird. Genauso kann es passieren, dass eine Person, die eigentlich ungeeignet ist, als geeignet klassifiziert wird.\n\n\n\n\nErstellen Sie eine Tabelle aller möglichen Kombinationen aus wahren Zuständen \\({\\text{geeignet}, \\text{ungeeignet}}\\) und Diagnosen \\({\\text{geeignet}, \\text{ungeeignet}}\\).\nBenennen Sie jede der vier Kombinationen. Verwenden Sie dazu die folgenden Begriffe:\n\n\nFalsch positiv (FP)\nRichtig positiv (RP)\nFalsch negativ (FN)\nRichtig negativ (RN)\nFalse negative (FN)\nFalse positive (FP)\nTrue negative (TN)\nTrue positive (TP)\n\n\nNehmen Sie an, dass eine Person mit einem Testwert \\(&gt;20\\) als geeignet eingestuft wird. Finden Sie einen beispielhaften Testwert für jeden der vier Zustände.\n\n\n\n\n\n\n\n\nTipp: Tabellengerüst\n\n\n\n\n\nSo soll die Tabelle am Ende aussehen:\n\n\n\n\n\n\n\n\n\n\nWahrer Zustand\nTestwert Beispiel\nDiagnose\nPrüfung [De]\nPrüfung [Eng]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJetzt fehlen noch die Werte.\n\n\n\n\n\n\n\n\n\nTipp: Teile von a. vorgeben\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWahrer Zustand\nTestwert Beispiel\nDiagnose\nPrüfung [De]\nPrüfung [Eng]\n\n\n\n\nGeeignet\n\n\n\n\n\n\n\n\nUngeeignet\n\n\n\n\nUngeeignet\n\n\n\n\n\n\n\n\nUngeeignet\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipp: Teile von b. vorgeben\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWahrer Zustand\nTestwert Beispiel\nDiagnose\nPrüfung [De]\nPrüfung [Eng]\n\n\n\n\nGeeignet\n\n\nRP\n\n\n\n\n\nUngeeignet\n\nFN\n\n\nUngeeignet\n\n\n\n\n\n\n\n\nUngeeignet\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nTabelle aller Kreuzungen von wahren Zuständen und Diagnosen (dichotom)\n\n\n\n\n\n\n\n\n\nWahrer Zustand\nTestwert Beispiel\nDiagnose\nPrüfung [De]\nPrüfung [Eng]\n\n\n\n\nGeeignet\n\\(21\\)\nGeeignet\nRP\nTP\n\n\nGeeignet\n\\(20\\)\nUngeeignet\nFN\nFN\n\n\nUngeeignet\n\\(23\\)\nGeeignet\nFP\nFP\n\n\nUngeeignet\n\\(13\\)\nUngeeignet\nRN\nTN\n\n\n\n\n\n\n\n\n\nErgänzen Sie die Formeln für die Sensitivität und Spezifität. Versuchen Sie es zuerst ohne die Vorlesungsfolien und überprüfen Sie dann Ihr Ergebnis.\n\n\\(\\text{Sensitivität} = \\frac{RP}{? + ?}\\)\n\\(\\text{Spezifität} = \\frac{?}{? + RN}\\)\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(\\text{Sensitivität} = \\frac{RP}{RP + FN}\\)\n\\(\\text{Spezifität} = \\frac{RN}{FP + RN}\\)\n\n\n\n\n\n\n\nEine Schule möchte einen neuen Test verwenden, um hochbegabte Schüler:innen frühzeitig zu identifizieren. Ein etablierter Intelligenztest wird als Vergleichsstandard zur Überprüfung der Testvorhersagen herangezogen. Die Testergebnisse für eine Stichprobe von 500 Kindern sind:\n\n\n\nUrteil neuer Test\nUrteil etablierter Test\n\\(n\\)\n\n\n\n\nHochbegabt\nHochbegabt\n\\(10\\)\n\n\nHochbegabt\nNicht hochbegabt\n\\(3\\)\n\n\nNicht hochbegabt\nNicht hochbegabt\n\\(482\\)\n\n\nNicht hochbegabt\nHochbegabt\n\\(5\\)\n\n\n\nBerechnen Sie die Sensitivität und Spezifität des neuen Tests.\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nGegeben:\n\\(RP = ?\\)\n\\(FP = ?\\)\n\\(RN = ?\\)\n\\(FN = ?\\)\nGesucht:\nSensitivität \\(= \\frac{RP}{RP + FN} = ?\\)\nSpezifität \\(= \\frac{RN}{FP + RN} = ?\\)\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben:\n\\(RP = 10\\)\n\\(FP = 3\\)\n\\(RN = 482\\)\n\\(FN = 5\\)\nGesucht:\nSensitivität \\(= \\frac{RP}{RP + FN} = \\frac{10}{10 + 5} \\approx .67\\)\nSpezifität \\(= \\frac{RN}{FP + RN} = \\frac{482}{3 + 482} \\approx .99\\)\n\n\n\n\n\n\nDie Testwerte ungeeigneter Testpersonen sind normalverteilt mit \\(X_u \\sim N(-1.5, 3)\\). Die Testwerte geeigneter Testpersonen sind normalverteilt mit \\(X_g \\sim N(4, 3)\\). Eine Person wird als geeignet klassifiziert, wenn Sie einen Testwert \\(&gt;3\\) aufweist. In der Abbildung sehen Sie die Dichterverteilungen der Testwerte ungeeigneter und geeigneter Personen.\n\n\n\n\n\n\n\n\n\nDie gelb markierte Fläche umfasst \\(93\\%\\) der Fläche unter der linken Verteilung. Die blau markierte Fläche umfasst \\(63\\%\\) der Fläche unter der rechten Verteilung.\n\nBerechnen Sie den Youden-Index.\n\n\n\n\n\n\n\nTipp 1\n\n\n\n\n\nGegeben:\n\\(RN = ?\\)\n\\(RP = ?\\)\n\n\n\n\n\n\n\n\n\nTipp 2\n\n\n\n\n\nGesucht:\nSensitivität \\(=?\\)\nSpezifität \\(=?\\)\nYouden-Index \\(=?\\)\n\n\n\n\n\n\n\n\n\nTipp 3\n\n\n\n\n\nGegeben:\n\\(RN = ?\\)\n\\(RP = ?\\)\nGesucht:\nSensitivität \\(= \\frac{RP}{FN + RP} = ?\\)\nSpezifität \\(= \\frac{RN}{FP + RN} = ?\\)\n\\(\\text{Youden-Index} = \\text{Sensitivität} + \\text{Spezifität} - 1 = ?\\)\n\n\n\n\n\n\n\n\n\nTipp 4: RN und RP vorgeben\n\n\n\n\n\nGegeben:\n\\(RN = .93\\)\n\\(RP = .63\\)\nGesucht:\nSensitivität \\(= \\frac{RP}{FN + RP} = ?\\)\nSpezifität \\(= \\frac{RN}{FP + RN} = ?\\)\n\\(\\text{Youden-Index} = \\text{Sensitivität} + \\text{Spezifität} - 1 = ?\\)\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben:\n\\(RN = .93\\)\n\\(RP = .63\\)\nGesucht:\nSensitivität \\(= \\frac{RP}{FN + RP} = \\frac{.63}{(1-.63) + .63} = .63\\)\nSpezifität \\(= \\frac{RN}{FP + RN} = \\frac{.93}{(1-.93) + .93} = .93\\)\n\\(\\text{Youden-Index} = \\text{Sensitivität} + \\text{Spezifität} - 1 = .63 + .93 - 1 = .56\\)"
  },
  {
    "objectID": "sections/ktt_messmodelle/ktt_messmodelle.html",
    "href": "sections/ktt_messmodelle/ktt_messmodelle.html",
    "title": "Messmodelle der Klassischen Testtheorie",
    "section": "",
    "text": "Neben den behandelten IRT-Modellen können Modelle, die auf Überlegungen der Klassischen Testtheorie (KTT) beruhen, verwendet werden, um Testdaten durch Personen- und Itemparameter zu erklären. Sie können sich also auch bei den KTT-Modellen eine Datenmatrix vorstellen, dessen Werte durch verschiedene Modelle erklärt werden soll. Zu Beginn müssen wir aber festhalten, dass sich mit dem Wechsel zur KTT auch die Notation der Vorlesung ändert.\nSie haben in den Abschnitten zur IRT die Datenmatrix \\(\\mathbf{U}\\) kennengelernt, die beobachtete Werte \\(u_{ij}\\) enthielt. In diesem Abschnitt bezeichnet die Vorlesung diese Datenpunkte stattdessen als \\(y_{mi}\\). Diese könnten in einer Matrix wie folgt angeordnet sein:\n\\[\\begin{equation}\n    \\begin{bmatrix}\n        3.43 & 5.54 & 1.12 \\\\\n        -5.2 & 1.2 & -0.3 \\\\\n        0.03 & -0.04 & -1.5 \\\\\n    \\end{bmatrix}\n\\end{equation}\\]\nIn diesem Beispiel ist \\(y_{21} = -5.2\\). Der Index \\(m\\) bezeichnet eine bestimmte Person und der Index \\(i\\) bezeichnet eine bestimmte Variable. Üblicherweise sind mit Variablen Items gemeint.\n\n\nDer Grundgedanke der behandelten KTT-Modelle ist es, einen beobachteten Wert \\(y_{mi}\\) einer Person \\(m\\) auf einer Variablen \\(i\\) linear in einen wahren Wert \\(\\tau_{mi}\\) und einen Messfehler \\(\\epsilon_{mi}\\) zu zerlegen:\n\\[y_{mi} = \\tau_{mi} + \\epsilon_{mi}\\]\nNimmt man an, dass die Messfehler und wahren Werte in der Population unkorreliert sind, folgt daraus die folgende Varianzzerlegung der beobachteten Variablen:\n\\[Var(Y_i) = Var(\\tau_i) + Var(\\epsilon_i)\\]\n\n\n\n\n\n\nExkurs: Warum ist das so?\n\n\n\n\n\nAddiert man zwei Zufallsvariablen \\(X\\) und \\(Y\\) miteinander, so ist\n\\[Var(X + Y) = Var(X) + Var(Y) + 2 Cov(X, Y)\\]\n(siehe Wikipedia)\nIn diesem Fall ist\n\\[Var(Y_i)\\]\n\\[= Var(\\tau_i + \\epsilon_i)\\]\n\\[= Var(\\tau_i) + Var(\\epsilon_i) + 2 \\cdot Cov(\\tau_i, \\epsilon_i)\\]\nNach Annahme ist \\(Cov(\\tau_i, \\epsilon_i):= 0\\). Es folgt\n\\[Var(Y_i) = Var(\\tau_i) + Var(\\epsilon_i)\\]\n\n\n\n\n\n\nNimmt man an, dass sich der wahre Wert durch eine Kombination von Personen- und Itemparametern darstellen lässt, resultieren Messmodelle mit Personen- und Itemparametern. Im allgemeinsten Fall wird der wahre Wert als Funktion eines Item-Intercepts \\(\\alpha_i\\), einer Faktorladung \\(\\lambda_i\\) und eines latenten Traitwerts \\(\\eta\\) ausgedrückt:\n\\[\\tau_{mi} = \\alpha_i + \\lambda_i \\cdot \\eta_m\\]\nDurch Einsetzen resultiert ein \\(\\tau\\)-kongenerisches Messmodell:\n\\[y_{mi} = \\alpha_i + \\lambda_i \\cdot \\eta_m + \\epsilon_{mi}\\]\n\nVergleichen Sie das \\(\\tau\\)-kongenerisches Messmodell mit der einfachen Regression. Was sind Unterschiede und was sind Gemeinsamkeiten?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nAuch in der linearen Regression sagt man Werte in einem Kriterium \\(y_{m}\\) durch eine lineare Funktion vorher. Eine einfache lineare Regression für \\(y_{m}\\) sähe so aus:\n\\(y_{m} = \\beta_0 + \\beta_1 x_{m} + \\epsilon_{m}\\)\nDas sieht dem \\(\\tau\\)-kongenerisches Messmodell sehr ähnlich. Das Intercept der Regression \\(\\beta_0\\) entspricht konzeptuell dem Item-Intercept \\(\\alpha_i\\), der Slope der Regression \\(\\beta_1\\) entspricht konzeptuell der Faktorladung \\(\\lambda_i\\), und der Prädiktor \\(x_m\\) entspricht konzeptuell dem latenten Trait \\(\\eta_m\\).\nEs gibt aber zwei wichtige Unterschiede: (1) Während die Prädiktorvariable \\(x_m\\) direkt im Datensatz vorliegt, muss der Personenparameter \\(\\eta_m\\) aus den Daten geschätzt werden. (2) Die einfache lineare Regression geht davon aus, dass es nur eine beobachtete Variable \\(y_m\\) gibt. Um, wie im vorherigen Punkt gefordert, eine latente Variable schätzen zu können, sind in Messmodellen hingegen mehrere Items notwendig. Daher liegt bei den Messmodellen noch ein weiterer Index \\(i\\) am \\(y_{mi}\\) vor. Ein Messmodell ist daher ein System von Gleichungen, die die Form der linearen Regression haben.\nZusammengefasst lässt sich sagen, dass die behandelten Messmodelle Systeme einfacher Regressionen sind, in denen die Werte der Prädiktorvariable (also der latenten Traits) aus den Daten geschätzt werden.\n\n\n\nWie die lineare Regression auch, lassen sich durch Messmodelle vorhergesagte Werte anschaulich graphisch darstellen. Auf der y-Achse finden Sie die durch ein \\(\\tau\\)-kongenerisches Modell vorhergesagten Itemantworten. Auf der x-Achse finden Sie Werte des latenten Traits.\n\n\n\n\n\n\n\n\n\n\nLesen Sie jeweils die Itemparameter des zur blauen, roten und schwarzen Gerade korrespondierenden Items ab.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nItem \\(1\\) (blau):\n\\(\\alpha_1 = 2\\), \\(\\lambda_1 = 0.5\\)\nItem \\(2\\) (rot):\n\\(\\alpha_2 = 0\\), \\(\\lambda_2 = 1\\)\nItem \\(3\\) (schwarz):\n\\(\\alpha_3 = -1\\), \\(\\lambda_3 = 2\\)\n\n\n\nKennt man die Item- und Personenparameter, lässt sich berechnen, welche Itemantwort ein Messmodell für eine Person vorhersagt.\n\nWelchen Wert sagt das skizzierte \\(\\tau\\)-kongenerische Messmodell für eine Person mit einem Personenparameter von \\(\\eta_m = 1.5\\) auf Item \\(2\\) vorher?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(\\hat{y}_{m2} = 0 + 1 \\cdot 1.5 = 1.5\\)\nDas Modell sagt einen Wert von \\(1.5\\) vorher.\n\n\n\nBei der letzten Aufgabe konnten Sie bereits feststellen, dass das \\(\\tau\\)-kongenerische Messmodell in der Form, wie wir es in der Veranstaltung behandeln, kontinuierliche Werte vorhersagt - z.B. den Wert \\(1.5\\) in der letzten Aufgabe. Nach der intensiven Behandlung von IRT-Modellen kommt Ihnen das vielleicht suspekt vor, denn bei testtheoretischen Anwendungen beobachten wir i.d.R. ordinale Daten. Daher möchte ich hier kurz anmerken, dass sich die KTT-Messmodelle durch einen sogenannten threshold-Prozess so erweitern lassen, dass sie, wie die IRT-Modelle auch, ordinale Vorhersagen treffen. Diese Erweiterung nehmen wir im Laufe der Veranstaltung der Einfachheit halber aber nicht vor. Stattdessen akzeptieren wir zur Heranführung an die Modelle, dass die KTT-Messmodelle kontinuierliche Werte vorhersagen, die Daten aber oft ordinal sind.\nIn der nächsten Aufgabe geht es darum explizit zu machen, dass Messmodelle Systeme linearer Gleichungen sind.\n\nSchreiben Sie das lineare Gleichungssystem auf, das aus dem Modell mit den abgelesenen Itemparametern resultiert. Ignorieren Sie dabei latente und Fehlervarianzen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(y_{m1} = 2 + 0.5 \\cdot \\eta_m + \\epsilon_{m1}\\)\n\\(y_{m2} = 0 + 1 \\cdot \\eta_m + \\epsilon_{m2}\\)\n\\(y_{m3} = -1 + 2 \\cdot \\eta_m + \\epsilon_{m3}\\)\n\n\n\n\nWelchen Antwortvektor sagt das \\(\\tau\\)-kongenerische Messmodell für eine Person mit einem latenten Trait von \\(\\eta_m = -2\\) vorher?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(2 + 0.5 \\cdot (-2) = 1\\)\n\\(0 + 1 \\cdot (-2) = -2\\)\n\\(-1 + 2 \\cdot (-2) = -5\\)\nDas Modell sagt den Antwortvektor \\(=[1, -2, -5]\\) vorher.\n\n\n\n\nSeien \\(\\epsilon_{m1} = 0.2\\), \\(\\epsilon_{m2} = -1\\), \\(\\epsilon_{m3} = 1.2\\), \\(\\eta_m = -2\\) und die Itemparameter wie in den vorherigen Aufgaben.\nRekonstruieren Sie die beobachteten Itemantworten.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEs wurden die Werte\n\\(y_{m1} = 2 + 0.5 \\cdot (-2) + 0.2 = 1.2\\)\n\\(y_{m2} = 0 + 1 \\cdot (-2) - 1 = -3\\)\n\\(y_{m3} = -1 + 2 \\cdot (-2) + 1.2 = -3.8\\)\nbeobachtet.\n\n\n\n\n\n\nMit der Einführung von Restriktionen auf den Itemparametern resultieren strengere Messmodelle.\n\nDie Restriktionen der Messmodelle beziehen sich auf Intercepts, Faktorladungen und Fehlervarianzen. Wie könnte man den oben gezeigten Plot (blaues, rotes, schwarzes Item) ergänzen, um die Fehlervarianzen sichtbar zu machen?\n\nDas eben behandelte \\(\\tau\\)-kongenerische Messmodell ist unter den behandelten Modellen das flexibelste Modell. Das restriktivste Modell nennt sich \\(\\tau\\)-paralleles Messmodell. Im \\(\\tau\\)-parallelen Messmodell wird angenommen, dass die Item-Intercepts, Faktorladungen und Fehlervarianzen aller Items gleich sind. Durch das “Fallenlassen” von Indices in der Modellgleichung kann man diese Gleichsetzung deutlich machen:\n\\[y_{mi} = \\alpha + \\lambda \\cdot \\eta_m + \\epsilon_{mi}\\]\n\\[Var(\\epsilon_i) = Var(\\epsilon_j)\\]\nfür alle \\(i \\ne j\\)\nDas \\(\\alpha\\) und \\(\\lambda\\) haben hier keinen Index \\(i\\) mehr. Das ist hier gleichbedeutend damit, dass es nur einen Parameterwert für alle Items gibt. Ausgehend von dem dadurch beschriebenen \\(\\tau\\)-parallelen Messmodell lassen sich schrittweise Parametergruppen zwischen Items befreien, bis Sie wieder beim \\(\\tau\\)-kongenerischen Modell ankommen. Die folgende Grafik stellt diese Schritte schematisch dar:\n\n\nEin beispielhaftes Messmodell impliziert das lineare Gleichungssystem\n\n\\(y_{m1} = \\alpha_1 + \\lambda \\cdot \\eta_m + \\epsilon_{m1}\\)\n\\(y_{m2} = \\alpha_2 + \\lambda \\cdot \\eta_m + \\epsilon_{m2}\\)\n\\(y_{m3} = \\alpha_3 + \\lambda \\cdot \\eta_m + \\epsilon_{m3}\\)\n\\(y_{m4} = \\alpha_4 + \\lambda \\cdot \\eta_m + \\epsilon_{m4}\\)\nmit Fehlervarianzen \\(Var(\\epsilon_1)\\), \\(Var(\\epsilon_2)\\), \\(Var(\\epsilon_3)\\), \\(Var(\\epsilon_4)\\).\nUm welches Messmodell handelt es sich?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nAlle Itemparameter bis auf die Faktorladungen sind itemspezifisch. Das lineare Gleichungssystem resultiert aus einem essentiell \\(\\tau\\)-äquivalenten Messmodell.\n\n\n\n\nPassen Sie den Plot zu den vorhergesagten Werten im \\(\\tau\\)-kongenerischen Messmodell so an, dass er jeweils aus einem essentiell \\(\\tau\\)-äquivalenten, \\(\\tau\\)-äquivalenten, essentiell \\(\\tau\\)-parallelen und \\(\\tau\\)-parallelen Messmodell hätte resultieren können.\n\n\n\n\nSie haben in der Vorlesung gelernt, wie man Messmodelle in R schätzt. In den folgenden Aufgaben geht es darum, anhand eines Datenbeispiels mit dem R-Output eines Messmodells aus der Software lavaan zu arbeiten.\n\n\nEs wurden \\(253\\) Antworten auf einen Test mit fünf Items im 6-Punkt Ratingskalenformat erhoben. Die ersten Zeilen des Datensatzes sehen so aus:\n\nhead(dat)\n\n        item_1 item_2 item_3 item_4 item_5\nperson1      3      1      2      2      1\nperson2      3      2      4      2      1\nperson3      2      1      3      2      2\nperson4      2      4      3      2      4\nperson5      3      2      2      2      2\nperson6      2      2      3      3      1\n\n\n\n\n\nMit Hilfe des folgenden Codes wurde ein Messmodell geschätzt:\n\nlibrary(lavaan)\n\nThis is lavaan 0.6-19\nlavaan is FREE software! Please report any bugs.\n\nmodel_1 &lt;- '\nf =~ 1*item_1 + 1*item_2 + 1*item_3 + 1*item_4 + 1*item_5\n\nitem_1 ~ int1*1\nitem_2 ~ int2*1\nitem_3 ~ int3*1\nitem_4 ~ int4*1\nitem_5 ~ int5*1\n\nitem_1 ~~ eps1*item_1\nitem_2 ~~ eps2*item_2\nitem_3 ~~ eps3*item_3\nitem_4 ~~ eps4*item_4\nitem_5 ~~ eps5*item_5\n\n# Make latent variance explicit (would also be added automatically)\nf ~~ lvar*f\n'\n\nmodel_1_fit &lt;- sem(model_1, data = dat, std.lv = FALSE)\n\n\nErstellen Sie ein Pfaddiagramm des Modells.\n\n\nSchreiben Sie das lineare Gleichungssystem auf, das durch das Modell impliziert wird. Schreiben Sie auch alle latenten und Fehlervarianzen mit auf.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\[y_{m1} = \\alpha_1 + 1 \\cdot \\eta_m + \\epsilon_{m1}\\]\n\\[y_{m2} = \\alpha_2 + 1 \\cdot \\eta_m + \\epsilon_{m2}\\]\n\\[y_{m3} = \\alpha_3 + 1 \\cdot \\eta_m + \\epsilon_{m3}\\]\n\\[y_{m4} = \\alpha_4 + 1 \\cdot \\eta_m + \\epsilon_{m4}\\]\n\\[y_{m5} = \\alpha_5 + 1 \\cdot \\eta_m + \\epsilon_{m5}\\]\nmit freien Fehlervarianzen \\(Var(\\epsilon_1), ..., Var(\\epsilon_5)\\) und freier latenter Varianz \\(Var(\\eta)\\).\n\n\n\n\nUm welche Art von Messmodell handelt es sich?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Intercepts und Residualvarianzen werden frei geschätzt. Die Faktorladungen sind zwischen Items fixiert. Es handelt sich um ein essentiell \\(\\tau\\)-äquivalentes Modell.\n\n\n\n\n\n\nMan kann die geschätzten Parameter folgendermaßen anzeigen:\n\nsummary(model_1_fit, standardized = TRUE)\n\nlavaan 0.6-19 ended normally after 18 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        11\n\n  Number of observations                           253\n\nModel Test User Model:\n                                                      \n  Test statistic                                 7.908\n  Degrees of freedom                                 9\n  P-value (Chi-square)                           0.543\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f =~                                                                  \n    item_1            1.000                               0.756    0.643\n    item_2            1.000                               0.756    0.554\n    item_3            1.000                               0.756    0.600\n    item_4            1.000                               0.756    0.700\n    item_5            1.000                               0.756    0.677\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .item_1  (int1)    2.466    0.074   33.354    0.000    2.466    2.097\n   .item_2  (int2)    2.553    0.086   29.761    0.000    2.553    1.871\n   .item_3  (int3)    2.451    0.079   30.941    0.000    2.451    1.945\n   .item_4  (int4)    2.443    0.068   35.956    0.000    2.443    2.261\n   .item_5  (int5)    2.494    0.070   35.500    0.000    2.494    2.232\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .item_1  (eps1)    0.811    0.086    9.459    0.000    0.811    0.587\n   .item_2  (eps2)    1.290    0.127   10.130    0.000    1.290    0.693\n   .item_3  (eps3)    1.015    0.103    9.823    0.000    1.015    0.640\n   .item_4  (eps4)    0.596    0.068    8.800    0.000    0.596    0.510\n   .item_5  (eps5)    0.677    0.074    9.097    0.000    0.677    0.542\n    f       (lvar)    0.572    0.066    8.697    0.000    1.000    1.000\n\n\n\nIst das Modell konvergiert?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nJa, das erkennt man an ended normally after 18 iterations.\n\n\n\n\nWofür steht vermutlich ESTIMATOR ML? Hier dürfen Sie raten.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nML: Maximum Likelihood\n\n\n\n\nWie viele freie Parameter hat das Modell?\nListen Sie die Parameter in formaler Notation auf.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEs lässt sich ablesen: Number of model parameters 11\nDiese sind 5 Intercepts \\(\\alpha_{1}, ..., \\alpha_{5}\\), 5 Residualvarianzen \\(Var(\\epsilon_1), ..., Var(\\epsilon_5)\\) und eine latente Varianze \\(Var(\\eta)\\).\n\n\n\n\nWofür steht Number of observations?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Stichprobengröße\n\n\n\n\nWofür stehen jeweils die Spalten Estimate, Std.Err, z-value, P(&gt;|z|), Std.lv, Std.all im Output?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEstimate: Unstandardisierte Parameterwerte\nStd.Err: Standardfehler\nz-value: Der Bruch Estimate / Std.Err. Das entspricht der Prüfstatistik des Wald Tests gegen die H0, dass der Parameter gleich Null ist.\nP(&gt;|z|): Zweiseitiger p-Wert des Wald Tests gegen die H0, dass der Parameter gleich Null ist.\nStd.lv: Standardisierte Lösung, in der die latente Varianz auf 1 gesetzt wurde\nStd.all: Standardisierte Lösung, in der die latente Varianz und die Gesamtvarianz aller Items auf 1 gesetzt wurden\n\n\n\n\nWarum ist die Spalte Std.Err bei manchen Parameter leer?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWenn Parameter fixiert werden, lässt sich für diese kein Standardfehler und folglich auch keine Wald-Statistik berechnen. Das betrifft im gezeigten Output die Faktorladungen.\n\n\n\n\n\n\n\nSie haben in der Vorlesung gelernt, wie man \\(Var(\\tau_i)\\) und \\(Var(Y_i)\\) berechnet. Berechnen Sie \\(Var(\\tau_3)\\) und \\(Var(Y_3)\\) für die unstandardisierte und beide standardisierten Lösungen. Stellen Sie zuvor eine Vermutung an, welche Werte zwangsweise gleich \\(1\\) sein müssen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEs sind\n\\[Var(\\tau_i) = Var(\\alpha_i + \\lambda_i \\cdot \\eta) = \\lambda_i^2 \\cdot Var(\\eta)\\]\nund\n\\[Var(Y_i) = Var(\\tau_i) + Var(\\epsilon_i)\\]\nUnstandardisiert\n\\(Var(\\tau_3) = 1^2 \\cdot 0.572 = 0.572\\)\n\\(Var(Y_3) = 0.572 + 1.015 = 1.587\\)\nStandardisierte latente Variable\n\\(Var(\\tau_3) = 0.756^2 \\cdot 1 \\approx 0.572\\)\n\\(Var(Y_3) = 0.572 + 1.015 = 1.587\\)\nLatente Variable und Itemvariablen standardisiert\n\\(Var(\\tau_3) = 0.600^2 \\cdot 1 = 0.36\\)\n\\(Var(Y_3) = 0.360 + 0.640 = 1\\)\n\n\n\n\nBerechnen Sie den Anteil systematischer Varianz an der Gesamtvarianz für Item \\(2\\).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(Var(\\tau_2) = \\lambda_2^2 \\cdot Var(\\eta) = 1^2 \\cdot 0.572 = 0.572\\)\n\\(Var(Y_2) = Var(\\tau_2) + Var(\\epsilon_2) = 0.572 + 1.290 = 1.862\\)\n\\(Rel(Y_2) = \\frac{Var(\\tau_2)}{Var(Y_2)} = \\frac{0.572}{1.862} \\approx 0.31\\)\n\n\n\n\nStellen Sie eine Vermutung an: Kann sich \\(Rel(Y_i)\\) zwischen Items unterscheiden, obwohl die Faktorladungen fixiert sind? Warum (nicht)?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nJa. In die Berechnung gehen die Werte \\(\\lambda_i\\), \\(Var(\\eta)\\) und \\(Var(\\epsilon_i)\\) ein. Es sind zwar \\(\\lambda_i\\) und \\(Var(\\eta)\\) zwischen Items fixiert, aber durch unterschiedliche Werte von \\(Var(\\epsilon_i)\\) können auch unterschiedliche Anteile systematischer Varianz an der Gesamtvarianz des Items entstehen.\n\n\n\n\nWie könnte man das Messmodell verändern, damit alle Items die gleiche \\(Rel(Y_i)\\) haben?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nMan könnte die Fehlervarianzen zwischen Items fixieren. Dann gölte ein essentiell \\(\\tau\\)-paralleles Messmodell.\nWürde man zusätzlich die Intercepts zwischen Items fixieren gölte ein \\(\\tau\\)-paralleles Messmodell. Auch hier wären die Werte von \\(Rel(Y_i)\\) zwischen Items gleich. Das wäre aber ein Schritt mehr als notwendig.\nIn einem \\(\\tau\\)-äquivalenten Messmodell wären Unterschiede zwischen den \\(Rel(Y_i)\\) weiterhin möglich.\n\n\n\n\n\nWelchen Reliabilitätsschätzer für den Gesamttest sollte man verwenden, wenn das spezifierte Messmodell das beste wäre?\nWelcher Reliabilitätsschätzer für den Gesamttest sollte verwendet werden, wenn man die Faktorladungen befreien würde?\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nCronbach’s Alpha\nMcDonald’s Omega\n\n\n\n\n\nExtrahieren Sie Cronbach’s alpha.\n\npsych::alpha(dat)\n\n\nReliability analysis   \nCall: psych::alpha(x = dat)\n\n  raw_alpha std.alpha G6(smc) average_r S/N   ase mean   sd median_r\n      0.76      0.77    0.73       0.4 3.3 0.024  2.5 0.86      0.4\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.71  0.76  0.81\nDuhachek  0.72  0.76  0.81\n\n Reliability if an item is dropped:\n       raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nitem_1      0.72      0.72    0.67      0.40 2.6    0.029 0.0059  0.39\nitem_2      0.74      0.75    0.69      0.42 2.9    0.026 0.0037  0.41\nitem_3      0.74      0.74    0.69      0.42 2.9    0.027 0.0039  0.40\nitem_4      0.70      0.70    0.64      0.37 2.4    0.031 0.0019  0.38\nitem_5      0.70      0.71    0.65      0.38 2.4    0.030 0.0030  0.38\n\n Item statistics \n         n raw.r std.r r.cor r.drop mean  sd\nitem_1 253  0.72  0.72  0.62   0.54  2.5 1.2\nitem_2 253  0.70  0.68  0.55   0.48  2.6 1.4\nitem_3 253  0.69  0.69  0.56   0.49  2.5 1.2\nitem_4 253  0.75  0.76  0.69   0.59  2.4 1.1\nitem_5 253  0.74  0.75  0.67   0.58  2.5 1.1\n\nNon missing response frequency for each item\n          0    1    2    3    4    5 miss\nitem_1 0.04 0.18 0.29 0.32 0.13 0.04    0\nitem_2 0.06 0.19 0.23 0.26 0.18 0.08    0\nitem_3 0.05 0.17 0.32 0.27 0.12 0.07    0\nitem_4 0.05 0.12 0.37 0.28 0.17 0.02    0\nitem_5 0.05 0.13 0.30 0.34 0.14 0.03    0\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nSiehe raw_alpha\n\\(0.76\\)\n\n\n\n\n\n\nAuf den gleichen Daten wurde ein Alternativmodell geschätzt:\n\nmodel_2 &lt;- '\nf =~ 1*item_1 + item_2 + item_3 + item_4 + item_5\n\nitem_1 ~ int1*1\nitem_2 ~ int2*1\nitem_3 ~ int3*1\nitem_4 ~ int4*1\nitem_5 ~ int5*1\n\nitem_1 ~~ eps1*item_1\nitem_2 ~~ eps2*item_2\nitem_3 ~~ eps3*item_3\nitem_4 ~~ eps4*item_4\nitem_5 ~~ eps5*item_5\n\n# Make latent variance explicit (would also be added automatically)\nf ~~ lvar*f\n'\n\nmodel_2_fit &lt;- sem(model_2, data = dat, std.lv = FALSE)\n\n\nUm welches Messmodell handelt es sich?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Faktorladungen wurden zusätzlich befreit. Es handelt sich nun um ein \\(\\tau\\)-kongenerisches Modell.\n\n\n\nDie Modellparameter sind im folgenden hinter einem Dropdown Menü versteckt.\n\nÜberlegen Sie bevor Sie sich den Output anschauen:\n\nWie viele zusätzliche Parameter sollte das Modell nun haben?\nWie viele Parameter hat das Modell also insgesamt?\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEs kommen 4 Parameter hinzu. Warum nicht 5 für 5 Items? Weil die erste Faktorladung zur Identifikation auf Null fixiert wurde.\nAus einer vorherigen Aufgabe wissen Sie, dass das essentiell \\(\\tau\\)-äquivalente Modell 11 Parameter hatte. Wenn 4 hinzukommen, muss das \\(\\tau\\)-kongenerische Modell 15 Parameter haben. Das finden Sie so auch im Output.\n\n\n\n\n\n\n\n\n\nModellparameter\n\n\n\n\n\nDie Parameter des \\(\\tau\\)-kongenerischen Modells kann man so anzeigen:\n\nsummary(model_2_fit, standardized = TRUE)\n\nlavaan 0.6-19 ended normally after 25 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        15\n\n  Number of observations                           253\n\nModel Test User Model:\n                                                      \n  Test statistic                                 6.579\n  Degrees of freedom                                 5\n  P-value (Chi-square)                           0.254\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f =~                                                                  \n    item_1            1.000                               0.718    0.618\n    item_2            1.030    0.153    6.745    0.000    0.740    0.543\n    item_3            0.988    0.141    7.008    0.000    0.709    0.572\n    item_4            1.109    0.137    8.119    0.000    0.796    0.725\n    item_5            1.098    0.138    7.971    0.000    0.788    0.697\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .item_1  (int1)    2.466    0.073   33.793    0.000    2.466    2.125\n   .item_2  (int2)    2.553    0.086   29.844    0.000    2.553    1.876\n   .item_3  (int3)    2.451    0.078   31.450    0.000    2.451    1.977\n   .item_4  (int4)    2.443    0.069   35.420    0.000    2.443    2.227\n   .item_5  (int5)    2.494    0.071   35.097    0.000    2.494    2.207\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .item_1  (eps1)    0.833    0.090    9.241    0.000    0.833    0.618\n   .item_2  (eps2)    1.305    0.132    9.902    0.000    1.305    0.705\n   .item_3  (eps3)    1.034    0.107    9.681    0.000    1.034    0.673\n   .item_4  (eps4)    0.570    0.075    7.607    0.000    0.570    0.474\n   .item_5  (eps5)    0.657    0.081    8.140    0.000    0.657    0.514\n    f       (lvar)    0.515    0.107    4.800    0.000    1.000    1.000\n\n\n\n\n\nNun stellt sich die Frage, welches der Modelle besser auf die Daten passt. Schauen Sie sich den Modelloutput an und stellen Sie ein Vermutung an, ob sich die zusätzliche Flexibilität im Alternativmodell lohnen könnte.\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Faktorladungen im \\(\\tau\\)-kongenerischen Modell sind alle nahe \\(1\\). Das spricht dafür, dass sich die Befreiung der Faktorladungen nicht lohnen könnte.\n\n\n\nDie Modelle lassen sich auch mit Hilfe eines Tests miteinander vergleichen:\n\nanova(model_2_fit, model_1_fit)\n\n\nChi-Squared Difference Test\n\n            Df    AIC    BIC  Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)\nmodel_2_fit  5 3785.7 3838.7 6.5789                                    \nmodel_1_fit  9 3779.0 3817.9 7.9082     1.3293     0       4     0.8564\n\n\n\nWelches Modell sollte entsprechend des Tests verwendet werden?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nH0: Die Restriktionen verschlechtern den Fit nicht\nH1: Die Restriktionen verschlechtern den Fit\nDer p-Wert ist nicht kleiner als \\(0.05\\). Die H0 kann nicht verworfen werden. Dem Modellvergleich folgend sollte man das restriktivere essentiell \\(\\tau\\)-äquivalente Modell beibehalten."
  },
  {
    "objectID": "sections/ktt_messmodelle/ktt_messmodelle.html#grundgleichung-der-ktt",
    "href": "sections/ktt_messmodelle/ktt_messmodelle.html#grundgleichung-der-ktt",
    "title": "Messmodelle der Klassischen Testtheorie",
    "section": "",
    "text": "Der Grundgedanke der behandelten KTT-Modelle ist es, einen beobachteten Wert \\(y_{mi}\\) einer Person \\(m\\) auf einer Variablen \\(i\\) linear in einen wahren Wert \\(\\tau_{mi}\\) und einen Messfehler \\(\\epsilon_{mi}\\) zu zerlegen:\n\\[y_{mi} = \\tau_{mi} + \\epsilon_{mi}\\]\nNimmt man an, dass die Messfehler und wahren Werte in der Population unkorreliert sind, folgt daraus die folgende Varianzzerlegung der beobachteten Variablen:\n\\[Var(Y_i) = Var(\\tau_i) + Var(\\epsilon_i)\\]\n\n\n\n\n\n\nExkurs: Warum ist das so?\n\n\n\n\n\nAddiert man zwei Zufallsvariablen \\(X\\) und \\(Y\\) miteinander, so ist\n\\[Var(X + Y) = Var(X) + Var(Y) + 2 Cov(X, Y)\\]\n(siehe Wikipedia)\nIn diesem Fall ist\n\\[Var(Y_i)\\]\n\\[= Var(\\tau_i + \\epsilon_i)\\]\n\\[= Var(\\tau_i) + Var(\\epsilon_i) + 2 \\cdot Cov(\\tau_i, \\epsilon_i)\\]\nNach Annahme ist \\(Cov(\\tau_i, \\epsilon_i):= 0\\). Es folgt\n\\[Var(Y_i) = Var(\\tau_i) + Var(\\epsilon_i)\\]"
  },
  {
    "objectID": "sections/ktt_messmodelle/ktt_messmodelle.html#tau-kongenerische-messmodelle",
    "href": "sections/ktt_messmodelle/ktt_messmodelle.html#tau-kongenerische-messmodelle",
    "title": "Messmodelle der Klassischen Testtheorie",
    "section": "",
    "text": "Nimmt man an, dass sich der wahre Wert durch eine Kombination von Personen- und Itemparametern darstellen lässt, resultieren Messmodelle mit Personen- und Itemparametern. Im allgemeinsten Fall wird der wahre Wert als Funktion eines Item-Intercepts \\(\\alpha_i\\), einer Faktorladung \\(\\lambda_i\\) und eines latenten Traitwerts \\(\\eta\\) ausgedrückt:\n\\[\\tau_{mi} = \\alpha_i + \\lambda_i \\cdot \\eta_m\\]\nDurch Einsetzen resultiert ein \\(\\tau\\)-kongenerisches Messmodell:\n\\[y_{mi} = \\alpha_i + \\lambda_i \\cdot \\eta_m + \\epsilon_{mi}\\]\n\nVergleichen Sie das \\(\\tau\\)-kongenerisches Messmodell mit der einfachen Regression. Was sind Unterschiede und was sind Gemeinsamkeiten?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nAuch in der linearen Regression sagt man Werte in einem Kriterium \\(y_{m}\\) durch eine lineare Funktion vorher. Eine einfache lineare Regression für \\(y_{m}\\) sähe so aus:\n\\(y_{m} = \\beta_0 + \\beta_1 x_{m} + \\epsilon_{m}\\)\nDas sieht dem \\(\\tau\\)-kongenerisches Messmodell sehr ähnlich. Das Intercept der Regression \\(\\beta_0\\) entspricht konzeptuell dem Item-Intercept \\(\\alpha_i\\), der Slope der Regression \\(\\beta_1\\) entspricht konzeptuell der Faktorladung \\(\\lambda_i\\), und der Prädiktor \\(x_m\\) entspricht konzeptuell dem latenten Trait \\(\\eta_m\\).\nEs gibt aber zwei wichtige Unterschiede: (1) Während die Prädiktorvariable \\(x_m\\) direkt im Datensatz vorliegt, muss der Personenparameter \\(\\eta_m\\) aus den Daten geschätzt werden. (2) Die einfache lineare Regression geht davon aus, dass es nur eine beobachtete Variable \\(y_m\\) gibt. Um, wie im vorherigen Punkt gefordert, eine latente Variable schätzen zu können, sind in Messmodellen hingegen mehrere Items notwendig. Daher liegt bei den Messmodellen noch ein weiterer Index \\(i\\) am \\(y_{mi}\\) vor. Ein Messmodell ist daher ein System von Gleichungen, die die Form der linearen Regression haben.\nZusammengefasst lässt sich sagen, dass die behandelten Messmodelle Systeme einfacher Regressionen sind, in denen die Werte der Prädiktorvariable (also der latenten Traits) aus den Daten geschätzt werden.\n\n\n\nWie die lineare Regression auch, lassen sich durch Messmodelle vorhergesagte Werte anschaulich graphisch darstellen. Auf der y-Achse finden Sie die durch ein \\(\\tau\\)-kongenerisches Modell vorhergesagten Itemantworten. Auf der x-Achse finden Sie Werte des latenten Traits.\n\n\n\n\n\n\n\n\n\n\nLesen Sie jeweils die Itemparameter des zur blauen, roten und schwarzen Gerade korrespondierenden Items ab.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nItem \\(1\\) (blau):\n\\(\\alpha_1 = 2\\), \\(\\lambda_1 = 0.5\\)\nItem \\(2\\) (rot):\n\\(\\alpha_2 = 0\\), \\(\\lambda_2 = 1\\)\nItem \\(3\\) (schwarz):\n\\(\\alpha_3 = -1\\), \\(\\lambda_3 = 2\\)\n\n\n\nKennt man die Item- und Personenparameter, lässt sich berechnen, welche Itemantwort ein Messmodell für eine Person vorhersagt.\n\nWelchen Wert sagt das skizzierte \\(\\tau\\)-kongenerische Messmodell für eine Person mit einem Personenparameter von \\(\\eta_m = 1.5\\) auf Item \\(2\\) vorher?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(\\hat{y}_{m2} = 0 + 1 \\cdot 1.5 = 1.5\\)\nDas Modell sagt einen Wert von \\(1.5\\) vorher.\n\n\n\nBei der letzten Aufgabe konnten Sie bereits feststellen, dass das \\(\\tau\\)-kongenerische Messmodell in der Form, wie wir es in der Veranstaltung behandeln, kontinuierliche Werte vorhersagt - z.B. den Wert \\(1.5\\) in der letzten Aufgabe. Nach der intensiven Behandlung von IRT-Modellen kommt Ihnen das vielleicht suspekt vor, denn bei testtheoretischen Anwendungen beobachten wir i.d.R. ordinale Daten. Daher möchte ich hier kurz anmerken, dass sich die KTT-Messmodelle durch einen sogenannten threshold-Prozess so erweitern lassen, dass sie, wie die IRT-Modelle auch, ordinale Vorhersagen treffen. Diese Erweiterung nehmen wir im Laufe der Veranstaltung der Einfachheit halber aber nicht vor. Stattdessen akzeptieren wir zur Heranführung an die Modelle, dass die KTT-Messmodelle kontinuierliche Werte vorhersagen, die Daten aber oft ordinal sind.\nIn der nächsten Aufgabe geht es darum explizit zu machen, dass Messmodelle Systeme linearer Gleichungen sind.\n\nSchreiben Sie das lineare Gleichungssystem auf, das aus dem Modell mit den abgelesenen Itemparametern resultiert. Ignorieren Sie dabei latente und Fehlervarianzen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(y_{m1} = 2 + 0.5 \\cdot \\eta_m + \\epsilon_{m1}\\)\n\\(y_{m2} = 0 + 1 \\cdot \\eta_m + \\epsilon_{m2}\\)\n\\(y_{m3} = -1 + 2 \\cdot \\eta_m + \\epsilon_{m3}\\)\n\n\n\n\nWelchen Antwortvektor sagt das \\(\\tau\\)-kongenerische Messmodell für eine Person mit einem latenten Trait von \\(\\eta_m = -2\\) vorher?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(2 + 0.5 \\cdot (-2) = 1\\)\n\\(0 + 1 \\cdot (-2) = -2\\)\n\\(-1 + 2 \\cdot (-2) = -5\\)\nDas Modell sagt den Antwortvektor \\(=[1, -2, -5]\\) vorher.\n\n\n\n\nSeien \\(\\epsilon_{m1} = 0.2\\), \\(\\epsilon_{m2} = -1\\), \\(\\epsilon_{m3} = 1.2\\), \\(\\eta_m = -2\\) und die Itemparameter wie in den vorherigen Aufgaben.\nRekonstruieren Sie die beobachteten Itemantworten.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEs wurden die Werte\n\\(y_{m1} = 2 + 0.5 \\cdot (-2) + 0.2 = 1.2\\)\n\\(y_{m2} = 0 + 1 \\cdot (-2) - 1 = -3\\)\n\\(y_{m3} = -1 + 2 \\cdot (-2) + 1.2 = -3.8\\)\nbeobachtet."
  },
  {
    "objectID": "sections/ktt_messmodelle/ktt_messmodelle.html#restringierte-messmodelle",
    "href": "sections/ktt_messmodelle/ktt_messmodelle.html#restringierte-messmodelle",
    "title": "Messmodelle der Klassischen Testtheorie",
    "section": "",
    "text": "Mit der Einführung von Restriktionen auf den Itemparametern resultieren strengere Messmodelle.\n\nDie Restriktionen der Messmodelle beziehen sich auf Intercepts, Faktorladungen und Fehlervarianzen. Wie könnte man den oben gezeigten Plot (blaues, rotes, schwarzes Item) ergänzen, um die Fehlervarianzen sichtbar zu machen?\n\nDas eben behandelte \\(\\tau\\)-kongenerische Messmodell ist unter den behandelten Modellen das flexibelste Modell. Das restriktivste Modell nennt sich \\(\\tau\\)-paralleles Messmodell. Im \\(\\tau\\)-parallelen Messmodell wird angenommen, dass die Item-Intercepts, Faktorladungen und Fehlervarianzen aller Items gleich sind. Durch das “Fallenlassen” von Indices in der Modellgleichung kann man diese Gleichsetzung deutlich machen:\n\\[y_{mi} = \\alpha + \\lambda \\cdot \\eta_m + \\epsilon_{mi}\\]\n\\[Var(\\epsilon_i) = Var(\\epsilon_j)\\]\nfür alle \\(i \\ne j\\)\nDas \\(\\alpha\\) und \\(\\lambda\\) haben hier keinen Index \\(i\\) mehr. Das ist hier gleichbedeutend damit, dass es nur einen Parameterwert für alle Items gibt. Ausgehend von dem dadurch beschriebenen \\(\\tau\\)-parallelen Messmodell lassen sich schrittweise Parametergruppen zwischen Items befreien, bis Sie wieder beim \\(\\tau\\)-kongenerischen Modell ankommen. Die folgende Grafik stellt diese Schritte schematisch dar:\n\n\nEin beispielhaftes Messmodell impliziert das lineare Gleichungssystem\n\n\\(y_{m1} = \\alpha_1 + \\lambda \\cdot \\eta_m + \\epsilon_{m1}\\)\n\\(y_{m2} = \\alpha_2 + \\lambda \\cdot \\eta_m + \\epsilon_{m2}\\)\n\\(y_{m3} = \\alpha_3 + \\lambda \\cdot \\eta_m + \\epsilon_{m3}\\)\n\\(y_{m4} = \\alpha_4 + \\lambda \\cdot \\eta_m + \\epsilon_{m4}\\)\nmit Fehlervarianzen \\(Var(\\epsilon_1)\\), \\(Var(\\epsilon_2)\\), \\(Var(\\epsilon_3)\\), \\(Var(\\epsilon_4)\\).\nUm welches Messmodell handelt es sich?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nAlle Itemparameter bis auf die Faktorladungen sind itemspezifisch. Das lineare Gleichungssystem resultiert aus einem essentiell \\(\\tau\\)-äquivalenten Messmodell.\n\n\n\n\nPassen Sie den Plot zu den vorhergesagten Werten im \\(\\tau\\)-kongenerischen Messmodell so an, dass er jeweils aus einem essentiell \\(\\tau\\)-äquivalenten, \\(\\tau\\)-äquivalenten, essentiell \\(\\tau\\)-parallelen und \\(\\tau\\)-parallelen Messmodell hätte resultieren können."
  },
  {
    "objectID": "sections/ktt_messmodelle/ktt_messmodelle.html#messmodelle-in-r",
    "href": "sections/ktt_messmodelle/ktt_messmodelle.html#messmodelle-in-r",
    "title": "Messmodelle der Klassischen Testtheorie",
    "section": "",
    "text": "Sie haben in der Vorlesung gelernt, wie man Messmodelle in R schätzt. In den folgenden Aufgaben geht es darum, anhand eines Datenbeispiels mit dem R-Output eines Messmodells aus der Software lavaan zu arbeiten.\n\n\nEs wurden \\(253\\) Antworten auf einen Test mit fünf Items im 6-Punkt Ratingskalenformat erhoben. Die ersten Zeilen des Datensatzes sehen so aus:\n\nhead(dat)\n\n        item_1 item_2 item_3 item_4 item_5\nperson1      3      1      2      2      1\nperson2      3      2      4      2      1\nperson3      2      1      3      2      2\nperson4      2      4      3      2      4\nperson5      3      2      2      2      2\nperson6      2      2      3      3      1\n\n\n\n\n\nMit Hilfe des folgenden Codes wurde ein Messmodell geschätzt:\n\nlibrary(lavaan)\n\nThis is lavaan 0.6-19\nlavaan is FREE software! Please report any bugs.\n\nmodel_1 &lt;- '\nf =~ 1*item_1 + 1*item_2 + 1*item_3 + 1*item_4 + 1*item_5\n\nitem_1 ~ int1*1\nitem_2 ~ int2*1\nitem_3 ~ int3*1\nitem_4 ~ int4*1\nitem_5 ~ int5*1\n\nitem_1 ~~ eps1*item_1\nitem_2 ~~ eps2*item_2\nitem_3 ~~ eps3*item_3\nitem_4 ~~ eps4*item_4\nitem_5 ~~ eps5*item_5\n\n# Make latent variance explicit (would also be added automatically)\nf ~~ lvar*f\n'\n\nmodel_1_fit &lt;- sem(model_1, data = dat, std.lv = FALSE)\n\n\nErstellen Sie ein Pfaddiagramm des Modells.\n\n\nSchreiben Sie das lineare Gleichungssystem auf, das durch das Modell impliziert wird. Schreiben Sie auch alle latenten und Fehlervarianzen mit auf.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\[y_{m1} = \\alpha_1 + 1 \\cdot \\eta_m + \\epsilon_{m1}\\]\n\\[y_{m2} = \\alpha_2 + 1 \\cdot \\eta_m + \\epsilon_{m2}\\]\n\\[y_{m3} = \\alpha_3 + 1 \\cdot \\eta_m + \\epsilon_{m3}\\]\n\\[y_{m4} = \\alpha_4 + 1 \\cdot \\eta_m + \\epsilon_{m4}\\]\n\\[y_{m5} = \\alpha_5 + 1 \\cdot \\eta_m + \\epsilon_{m5}\\]\nmit freien Fehlervarianzen \\(Var(\\epsilon_1), ..., Var(\\epsilon_5)\\) und freier latenter Varianz \\(Var(\\eta)\\).\n\n\n\n\nUm welche Art von Messmodell handelt es sich?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Intercepts und Residualvarianzen werden frei geschätzt. Die Faktorladungen sind zwischen Items fixiert. Es handelt sich um ein essentiell \\(\\tau\\)-äquivalentes Modell.\n\n\n\n\n\n\nMan kann die geschätzten Parameter folgendermaßen anzeigen:\n\nsummary(model_1_fit, standardized = TRUE)\n\nlavaan 0.6-19 ended normally after 18 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        11\n\n  Number of observations                           253\n\nModel Test User Model:\n                                                      \n  Test statistic                                 7.908\n  Degrees of freedom                                 9\n  P-value (Chi-square)                           0.543\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f =~                                                                  \n    item_1            1.000                               0.756    0.643\n    item_2            1.000                               0.756    0.554\n    item_3            1.000                               0.756    0.600\n    item_4            1.000                               0.756    0.700\n    item_5            1.000                               0.756    0.677\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .item_1  (int1)    2.466    0.074   33.354    0.000    2.466    2.097\n   .item_2  (int2)    2.553    0.086   29.761    0.000    2.553    1.871\n   .item_3  (int3)    2.451    0.079   30.941    0.000    2.451    1.945\n   .item_4  (int4)    2.443    0.068   35.956    0.000    2.443    2.261\n   .item_5  (int5)    2.494    0.070   35.500    0.000    2.494    2.232\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .item_1  (eps1)    0.811    0.086    9.459    0.000    0.811    0.587\n   .item_2  (eps2)    1.290    0.127   10.130    0.000    1.290    0.693\n   .item_3  (eps3)    1.015    0.103    9.823    0.000    1.015    0.640\n   .item_4  (eps4)    0.596    0.068    8.800    0.000    0.596    0.510\n   .item_5  (eps5)    0.677    0.074    9.097    0.000    0.677    0.542\n    f       (lvar)    0.572    0.066    8.697    0.000    1.000    1.000\n\n\n\nIst das Modell konvergiert?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nJa, das erkennt man an ended normally after 18 iterations.\n\n\n\n\nWofür steht vermutlich ESTIMATOR ML? Hier dürfen Sie raten.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nML: Maximum Likelihood\n\n\n\n\nWie viele freie Parameter hat das Modell?\nListen Sie die Parameter in formaler Notation auf.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEs lässt sich ablesen: Number of model parameters 11\nDiese sind 5 Intercepts \\(\\alpha_{1}, ..., \\alpha_{5}\\), 5 Residualvarianzen \\(Var(\\epsilon_1), ..., Var(\\epsilon_5)\\) und eine latente Varianze \\(Var(\\eta)\\).\n\n\n\n\nWofür steht Number of observations?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Stichprobengröße\n\n\n\n\nWofür stehen jeweils die Spalten Estimate, Std.Err, z-value, P(&gt;|z|), Std.lv, Std.all im Output?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEstimate: Unstandardisierte Parameterwerte\nStd.Err: Standardfehler\nz-value: Der Bruch Estimate / Std.Err. Das entspricht der Prüfstatistik des Wald Tests gegen die H0, dass der Parameter gleich Null ist.\nP(&gt;|z|): Zweiseitiger p-Wert des Wald Tests gegen die H0, dass der Parameter gleich Null ist.\nStd.lv: Standardisierte Lösung, in der die latente Varianz auf 1 gesetzt wurde\nStd.all: Standardisierte Lösung, in der die latente Varianz und die Gesamtvarianz aller Items auf 1 gesetzt wurden\n\n\n\n\nWarum ist die Spalte Std.Err bei manchen Parameter leer?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWenn Parameter fixiert werden, lässt sich für diese kein Standardfehler und folglich auch keine Wald-Statistik berechnen. Das betrifft im gezeigten Output die Faktorladungen.\n\n\n\n\n\n\n\nSie haben in der Vorlesung gelernt, wie man \\(Var(\\tau_i)\\) und \\(Var(Y_i)\\) berechnet. Berechnen Sie \\(Var(\\tau_3)\\) und \\(Var(Y_3)\\) für die unstandardisierte und beide standardisierten Lösungen. Stellen Sie zuvor eine Vermutung an, welche Werte zwangsweise gleich \\(1\\) sein müssen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEs sind\n\\[Var(\\tau_i) = Var(\\alpha_i + \\lambda_i \\cdot \\eta) = \\lambda_i^2 \\cdot Var(\\eta)\\]\nund\n\\[Var(Y_i) = Var(\\tau_i) + Var(\\epsilon_i)\\]\nUnstandardisiert\n\\(Var(\\tau_3) = 1^2 \\cdot 0.572 = 0.572\\)\n\\(Var(Y_3) = 0.572 + 1.015 = 1.587\\)\nStandardisierte latente Variable\n\\(Var(\\tau_3) = 0.756^2 \\cdot 1 \\approx 0.572\\)\n\\(Var(Y_3) = 0.572 + 1.015 = 1.587\\)\nLatente Variable und Itemvariablen standardisiert\n\\(Var(\\tau_3) = 0.600^2 \\cdot 1 = 0.36\\)\n\\(Var(Y_3) = 0.360 + 0.640 = 1\\)\n\n\n\n\nBerechnen Sie den Anteil systematischer Varianz an der Gesamtvarianz für Item \\(2\\).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(Var(\\tau_2) = \\lambda_2^2 \\cdot Var(\\eta) = 1^2 \\cdot 0.572 = 0.572\\)\n\\(Var(Y_2) = Var(\\tau_2) + Var(\\epsilon_2) = 0.572 + 1.290 = 1.862\\)\n\\(Rel(Y_2) = \\frac{Var(\\tau_2)}{Var(Y_2)} = \\frac{0.572}{1.862} \\approx 0.31\\)\n\n\n\n\nStellen Sie eine Vermutung an: Kann sich \\(Rel(Y_i)\\) zwischen Items unterscheiden, obwohl die Faktorladungen fixiert sind? Warum (nicht)?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nJa. In die Berechnung gehen die Werte \\(\\lambda_i\\), \\(Var(\\eta)\\) und \\(Var(\\epsilon_i)\\) ein. Es sind zwar \\(\\lambda_i\\) und \\(Var(\\eta)\\) zwischen Items fixiert, aber durch unterschiedliche Werte von \\(Var(\\epsilon_i)\\) können auch unterschiedliche Anteile systematischer Varianz an der Gesamtvarianz des Items entstehen.\n\n\n\n\nWie könnte man das Messmodell verändern, damit alle Items die gleiche \\(Rel(Y_i)\\) haben?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nMan könnte die Fehlervarianzen zwischen Items fixieren. Dann gölte ein essentiell \\(\\tau\\)-paralleles Messmodell.\nWürde man zusätzlich die Intercepts zwischen Items fixieren gölte ein \\(\\tau\\)-paralleles Messmodell. Auch hier wären die Werte von \\(Rel(Y_i)\\) zwischen Items gleich. Das wäre aber ein Schritt mehr als notwendig.\nIn einem \\(\\tau\\)-äquivalenten Messmodell wären Unterschiede zwischen den \\(Rel(Y_i)\\) weiterhin möglich.\n\n\n\n\n\nWelchen Reliabilitätsschätzer für den Gesamttest sollte man verwenden, wenn das spezifierte Messmodell das beste wäre?\nWelcher Reliabilitätsschätzer für den Gesamttest sollte verwendet werden, wenn man die Faktorladungen befreien würde?\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nCronbach’s Alpha\nMcDonald’s Omega\n\n\n\n\n\nExtrahieren Sie Cronbach’s alpha.\n\npsych::alpha(dat)\n\n\nReliability analysis   \nCall: psych::alpha(x = dat)\n\n  raw_alpha std.alpha G6(smc) average_r S/N   ase mean   sd median_r\n      0.76      0.77    0.73       0.4 3.3 0.024  2.5 0.86      0.4\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.71  0.76  0.81\nDuhachek  0.72  0.76  0.81\n\n Reliability if an item is dropped:\n       raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nitem_1      0.72      0.72    0.67      0.40 2.6    0.029 0.0059  0.39\nitem_2      0.74      0.75    0.69      0.42 2.9    0.026 0.0037  0.41\nitem_3      0.74      0.74    0.69      0.42 2.9    0.027 0.0039  0.40\nitem_4      0.70      0.70    0.64      0.37 2.4    0.031 0.0019  0.38\nitem_5      0.70      0.71    0.65      0.38 2.4    0.030 0.0030  0.38\n\n Item statistics \n         n raw.r std.r r.cor r.drop mean  sd\nitem_1 253  0.72  0.72  0.62   0.54  2.5 1.2\nitem_2 253  0.70  0.68  0.55   0.48  2.6 1.4\nitem_3 253  0.69  0.69  0.56   0.49  2.5 1.2\nitem_4 253  0.75  0.76  0.69   0.59  2.4 1.1\nitem_5 253  0.74  0.75  0.67   0.58  2.5 1.1\n\nNon missing response frequency for each item\n          0    1    2    3    4    5 miss\nitem_1 0.04 0.18 0.29 0.32 0.13 0.04    0\nitem_2 0.06 0.19 0.23 0.26 0.18 0.08    0\nitem_3 0.05 0.17 0.32 0.27 0.12 0.07    0\nitem_4 0.05 0.12 0.37 0.28 0.17 0.02    0\nitem_5 0.05 0.13 0.30 0.34 0.14 0.03    0\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nSiehe raw_alpha\n\\(0.76\\)\n\n\n\n\n\n\nAuf den gleichen Daten wurde ein Alternativmodell geschätzt:\n\nmodel_2 &lt;- '\nf =~ 1*item_1 + item_2 + item_3 + item_4 + item_5\n\nitem_1 ~ int1*1\nitem_2 ~ int2*1\nitem_3 ~ int3*1\nitem_4 ~ int4*1\nitem_5 ~ int5*1\n\nitem_1 ~~ eps1*item_1\nitem_2 ~~ eps2*item_2\nitem_3 ~~ eps3*item_3\nitem_4 ~~ eps4*item_4\nitem_5 ~~ eps5*item_5\n\n# Make latent variance explicit (would also be added automatically)\nf ~~ lvar*f\n'\n\nmodel_2_fit &lt;- sem(model_2, data = dat, std.lv = FALSE)\n\n\nUm welches Messmodell handelt es sich?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Faktorladungen wurden zusätzlich befreit. Es handelt sich nun um ein \\(\\tau\\)-kongenerisches Modell.\n\n\n\nDie Modellparameter sind im folgenden hinter einem Dropdown Menü versteckt.\n\nÜberlegen Sie bevor Sie sich den Output anschauen:\n\nWie viele zusätzliche Parameter sollte das Modell nun haben?\nWie viele Parameter hat das Modell also insgesamt?\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEs kommen 4 Parameter hinzu. Warum nicht 5 für 5 Items? Weil die erste Faktorladung zur Identifikation auf Null fixiert wurde.\nAus einer vorherigen Aufgabe wissen Sie, dass das essentiell \\(\\tau\\)-äquivalente Modell 11 Parameter hatte. Wenn 4 hinzukommen, muss das \\(\\tau\\)-kongenerische Modell 15 Parameter haben. Das finden Sie so auch im Output.\n\n\n\n\n\n\n\n\n\nModellparameter\n\n\n\n\n\nDie Parameter des \\(\\tau\\)-kongenerischen Modells kann man so anzeigen:\n\nsummary(model_2_fit, standardized = TRUE)\n\nlavaan 0.6-19 ended normally after 25 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        15\n\n  Number of observations                           253\n\nModel Test User Model:\n                                                      \n  Test statistic                                 6.579\n  Degrees of freedom                                 5\n  P-value (Chi-square)                           0.254\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f =~                                                                  \n    item_1            1.000                               0.718    0.618\n    item_2            1.030    0.153    6.745    0.000    0.740    0.543\n    item_3            0.988    0.141    7.008    0.000    0.709    0.572\n    item_4            1.109    0.137    8.119    0.000    0.796    0.725\n    item_5            1.098    0.138    7.971    0.000    0.788    0.697\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .item_1  (int1)    2.466    0.073   33.793    0.000    2.466    2.125\n   .item_2  (int2)    2.553    0.086   29.844    0.000    2.553    1.876\n   .item_3  (int3)    2.451    0.078   31.450    0.000    2.451    1.977\n   .item_4  (int4)    2.443    0.069   35.420    0.000    2.443    2.227\n   .item_5  (int5)    2.494    0.071   35.097    0.000    2.494    2.207\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .item_1  (eps1)    0.833    0.090    9.241    0.000    0.833    0.618\n   .item_2  (eps2)    1.305    0.132    9.902    0.000    1.305    0.705\n   .item_3  (eps3)    1.034    0.107    9.681    0.000    1.034    0.673\n   .item_4  (eps4)    0.570    0.075    7.607    0.000    0.570    0.474\n   .item_5  (eps5)    0.657    0.081    8.140    0.000    0.657    0.514\n    f       (lvar)    0.515    0.107    4.800    0.000    1.000    1.000\n\n\n\n\n\nNun stellt sich die Frage, welches der Modelle besser auf die Daten passt. Schauen Sie sich den Modelloutput an und stellen Sie ein Vermutung an, ob sich die zusätzliche Flexibilität im Alternativmodell lohnen könnte.\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Faktorladungen im \\(\\tau\\)-kongenerischen Modell sind alle nahe \\(1\\). Das spricht dafür, dass sich die Befreiung der Faktorladungen nicht lohnen könnte.\n\n\n\nDie Modelle lassen sich auch mit Hilfe eines Tests miteinander vergleichen:\n\nanova(model_2_fit, model_1_fit)\n\n\nChi-Squared Difference Test\n\n            Df    AIC    BIC  Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)\nmodel_2_fit  5 3785.7 3838.7 6.5789                                    \nmodel_1_fit  9 3779.0 3817.9 7.9082     1.3293     0       4     0.8564\n\n\n\nWelches Modell sollte entsprechend des Tests verwendet werden?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nH0: Die Restriktionen verschlechtern den Fit nicht\nH1: Die Restriktionen verschlechtern den Fit\nDer p-Wert ist nicht kleiner als \\(0.05\\). Die H0 kann nicht verworfen werden. Dem Modellvergleich folgend sollte man das restriktivere essentiell \\(\\tau\\)-äquivalente Modell beibehalten."
  },
  {
    "objectID": "sections/software/software.html",
    "href": "sections/software/software.html",
    "title": "Software",
    "section": "",
    "text": "Für die Übung ist es hilfreich, eine Reihe von R-Paketen zu installieren.\n\n\n\nmirt und eRm sind R-Pakete, mit denen Sie IRT-Modelle schätzen können.\n\ninstall.packages(\"mirt\")\ninstall.packages(\"eRm\")\n\n\n\n\nlavaan ist ein R-Paket, mit dem Sie Strukturgleichungsmodelle in R schätzen können. Eine Spezialfall von Strukturgleichungsmodellen sind konfirmatorische Faktoranalysen (CFA), mit denen wir uns im späteren Teil der Übung beschäftigen werden.\n\ninstall.packages(\"lavaan\")\n\n\n\n\nteachIRT ist ein R-Paket, das wir speziell für die Übung M.B.2 geschrieben haben. Mit teachIRT können Sie viele Aufgaben im IRT-Abschnitt selbst überprüfen und sich selbst neue Aufgaben stellen. Da das Paket auf GitHub gehostet ist, benötigen Sie zur Installation auch das Paket devtools.\n\ninstall.packages(\"devtools\")\ndevtools::install_github(\"jkillisch/teachIRT\")\n\n\n\n\nSie können die Inhalte des Übungshefts gerne mit ChatGPT teilen, etwa um sich Tipps statt der gesamten Lösung geben zu lassen. Eine andere Anwendung ist es, Wissen zu erfragen, das über die behandelten Inhalte hinausgeht. Wir empfehlen Ihnen dennoch, die Aufgaben vorrangig mit den Vorlesungsmaterialien zu bearbeiten, da dieses Material die direkteste Grundlage für die Prüfung darstellt.\n\n\n\nHier finden Sie einen super Blogbeitrag zum Schätzen von Rasch- und 2PL-Modellen in R.\nIm Laufe der Veranstaltung kommen wir hin und wieder auf Generalisierte Lineare Modelle zu sprechen. Als Vertiefung empfehlen wir das Buch Generalized Linear Models With Examples in R."
  },
  {
    "objectID": "sections/software/software.html#r-pakete",
    "href": "sections/software/software.html#r-pakete",
    "title": "Software",
    "section": "",
    "text": "Für die Übung ist es hilfreich, eine Reihe von R-Paketen zu installieren."
  },
  {
    "objectID": "sections/software/software.html#mirt-erm",
    "href": "sections/software/software.html#mirt-erm",
    "title": "Software",
    "section": "",
    "text": "mirt und eRm sind R-Pakete, mit denen Sie IRT-Modelle schätzen können.\n\ninstall.packages(\"mirt\")\ninstall.packages(\"eRm\")"
  },
  {
    "objectID": "sections/software/software.html#lavaan",
    "href": "sections/software/software.html#lavaan",
    "title": "Software",
    "section": "",
    "text": "lavaan ist ein R-Paket, mit dem Sie Strukturgleichungsmodelle in R schätzen können. Eine Spezialfall von Strukturgleichungsmodellen sind konfirmatorische Faktoranalysen (CFA), mit denen wir uns im späteren Teil der Übung beschäftigen werden.\n\ninstall.packages(\"lavaan\")"
  },
  {
    "objectID": "sections/software/software.html#teachirt",
    "href": "sections/software/software.html#teachirt",
    "title": "Software",
    "section": "",
    "text": "teachIRT ist ein R-Paket, das wir speziell für die Übung M.B.2 geschrieben haben. Mit teachIRT können Sie viele Aufgaben im IRT-Abschnitt selbst überprüfen und sich selbst neue Aufgaben stellen. Da das Paket auf GitHub gehostet ist, benötigen Sie zur Installation auch das Paket devtools.\n\ninstall.packages(\"devtools\")\ndevtools::install_github(\"jkillisch/teachIRT\")"
  },
  {
    "objectID": "sections/software/software.html#umgang-mit-ai",
    "href": "sections/software/software.html#umgang-mit-ai",
    "title": "Software",
    "section": "",
    "text": "Sie können die Inhalte des Übungshefts gerne mit ChatGPT teilen, etwa um sich Tipps statt der gesamten Lösung geben zu lassen. Eine andere Anwendung ist es, Wissen zu erfragen, das über die behandelten Inhalte hinausgeht. Wir empfehlen Ihnen dennoch, die Aufgaben vorrangig mit den Vorlesungsmaterialien zu bearbeiten, da dieses Material die direkteste Grundlage für die Prüfung darstellt."
  },
  {
    "objectID": "sections/software/software.html#literatur",
    "href": "sections/software/software.html#literatur",
    "title": "Software",
    "section": "",
    "text": "Hier finden Sie einen super Blogbeitrag zum Schätzen von Rasch- und 2PL-Modellen in R.\nIm Laufe der Veranstaltung kommen wir hin und wieder auf Generalisierte Lineare Modelle zu sprechen. Als Vertiefung empfehlen wir das Buch Generalized Linear Models With Examples in R."
  },
  {
    "objectID": "sections/diagnostischer_prozess/diagnostischer_prozess.html",
    "href": "sections/diagnostischer_prozess/diagnostischer_prozess.html",
    "title": "Der Diagnostische Prozess",
    "section": "",
    "text": "In der Vorlesung haben Sie sechs Kriterien kennengelernt, die bei der Formulierung diagnostischer Hypothesen beachtet werden sollten.\n\nNennen Sie die sechs Kriterien zur Formulierung diagnostischer Hypothesen. Die Lösung finden Sie auf den Vorlesungsfolien.\n\nBeachten Sie, dass diese Kriterien nicht vollständig analog für Forschungshypothesen gelten. Es wäre zum Beispiel ungewöhnlich, eine Forschungshypothese als Frage zu formulieren.\n\n\n\nWelche Aspekte der folgenden Hypothesen zu gegebenen Fragestellungen sind problematisch? Wie könnten die Hypothesen besser formuliert werden?\n\nFragestellung: Ist Marijke hochbegabt?\nHypothese: Löst Marijke mindestens 84% der Aufgaben eines Intelligenztests für Hochbegabtendiagnostik?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nNormbezug fehlt\n\n\n\n\nFragestellung: Ist Mona geeignet, um eine Ausbildung als Fluglotsin zu beginnen?\nHypothese: Sind Monas Konzentrationsfähigkeit und Gewissenhaftigkeit überdurchschnittlich im Vergleich zur einer gleichaltrigen Referenzstichprobe?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nNur ein Sachverhalt pro Hypothese\nNicht trennscharf genug, da kein Cutoff genannt wird\n\n\n\n\n\nFragestellung: Sind Verenas schlechte Klausurnoten auf Prüfungsangst zurückzuführen?\nHypothese: Weißt Verena im Vergleich zu Gleichaltrigen extreme Werte (\\(|z|&gt;1\\)) in der Ängstlichkeitsfacette des NEO-PI-R auf?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nBezug zur Fragestellung: Ängstlichkeit ist nicht gleich Prüfungsangst\nGerichtete Hypothese notwendig\n\n\n\n\n\nFragestellung: Sollte Emre auf Grund seiner depressiven Verstimmung eine Psychotherapie beginnen?\nHypothese: Weißt Emre depressive Symptome im klinisch relevanten Ausmaß auf?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nUnscharfe Hypothese\nNormbezug fehlt\nCutoff fehlt\n\n\n\n\n\nFragestellung: Besteht bei Hubert Verdacht auf eine beginnende Demenz?\nHypothese: Ist Huberts Leistung in einem Gedächtnistest Test &lt; 40 (T-Werte)?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nNormbezug unvollständig, da keine Referenzgruppe genannt wird\n\n\n\n\n\n\n\nHäufig muss eine globale diagnostische Fragestellung zunächst in eine spezifischere Fragestellung überführt werden, bevor (eine oder mehrere) Hypothesen abgeleitet werden können. Zum Beispiel:\n\n\n\n\n\n\n\nGlobale Fragestellung\nHat Erik die nötigen kognitiven Fähigkeiten für ein Kunststudium?\n\n\nSpezifische Fragestellung\nIst Erik mindestens durchschnittlich intelligent und überdurchschnittlich kreativ?\n\n\nHypothese(n)\nH1: Ist Eriks Leistung in einem Intelligenztest im Vergleich zu Gleichaltrigen mindestens durchschnittlich (IQ ≥ 100)?H2: Ist Eriks Leistung in einem Kreativitätstest im Vergleich zu Gleichaltrigen überdurchschnittlich (SW ≥ 110)?\n\n\n\n\nSpezifizieren Sie die folgende Fragestellung und leiten Sie eine oder mehr passende Hypothesen ab. Über die notwendigen Eigenschaften, um an der Arktisexpedition teilzunehmen können Sie selbst entscheiden.\n\n\n\n\n\n\n\nGlobale Fragestellung\nVerfügt Sonja über die notwendigen Persönlichkeitseigenschaften um an einer 3-monatigen, winterlichen Arktis-Expedition teilzunehmen?\n\n\nSpezifische Fragestellung\n…\n\n\nHypothese(n)\n…\n\n\n\n\n\n\n\n\nWenn mehrere Hypothesen zur selben diagnostischen Fragestellung aufgestellt wurden, müssen die Ergebnisse anhand zuvor definierter Entscheidungsregeln integriert werden. Sie haben in der Vorlesung verschiedene Typen von Entscheidungsregeln kennengelernt.\nBei Entscheidungen anhand von zwei Kriterien, lassen sich die Wertebereiche, in denen entweder eine positive oder eine negative Entscheidung getroffen wird, leicht in einem Plot darstellen:\n\n\n\n\n\n\n\n\n\nDie konkrete Entscheidungsregel im Beispiel könnte auch so beschrieben werden:\n\nDer Intelligenzwert muss mindestens 100 betragen und der Kreativitätswert muss mindestens 50 betragen.\n\nFormal kann man die Bedingung, die erfüllt sein muss, um gewählt zu werden, auch so beschreiben:\n\n\\(IQ_{Intelligenz} \\ge 100 \\wedge T_{Kreativität} \\ge  50\\)\n\nDa in der Regel zwei Bedingungen mit einem logischen Und verknüpft werden, handelt es sich um eine konjunktive Entscheidungsregel.\n\nBenennen Sie für die folgenden Beispiele um welche Art Entscheidungsregel es sich handelt. Beschreiben Sie die konkrete Entscheidungsregel entweder verbal oder mathematisch.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(IQ_{Intelligenz} \\ge 100 \\vee T_{Kreativität} \\ge  50\\)\nOder-Regel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDer Punkt \\((100, 51)\\) liegt auf der schwarz markierten Geraden. Da Kreativität und Intelligez in der Entscheidungsregel gleichgewichtet werden, ist die absolute Steigung der Geraden \\(1\\).\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(IQ_{Intelligenz} + T_{Kreativität} &gt; 150\\)\nKompensatorisch\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDer Punkt \\((99, 32)\\) liegt auf der Geraden, die eine Steigung von \\(-1\\) hat.\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\((IQ_{Intelligenz} \\ge 100 \\vee T_{Kreativität} \\ge 50) \\vee (IQ_{Intelligenz} + T_{Kreativität} &gt; 130)\\)\nSchwache Oder-Regel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDer Punkt \\((100, 51)\\) liegt auf der Geraden, die eine Steigung von \\(-1\\) hat.\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\((IQ_{Intelligenz} &gt; 85 \\wedge T_{Kreativität} &gt; 40) \\wedge (IQ_{Intelligenz} + T_{Kreativität} &gt; 150)\\)\nSchwache Konjunktive-Regel\n\n\n\n\n\n\n\nFinden Sie je ein Beispiel für die folgenden Untersuchungspläne:\n\nSingle screen\nNicht-sequenzielle Untersuchungsbatterie\nVorauswahl Untersuchungsplan (pre-reject)\nVorentscheidungs-Untersuchungsplan (pre-select)\nVollständig sequenzieller Untersuchungsplan"
  },
  {
    "objectID": "sections/diagnostischer_prozess/diagnostischer_prozess.html#formulierung-diagnostischer-hypothesen",
    "href": "sections/diagnostischer_prozess/diagnostischer_prozess.html#formulierung-diagnostischer-hypothesen",
    "title": "Der Diagnostische Prozess",
    "section": "",
    "text": "In der Vorlesung haben Sie sechs Kriterien kennengelernt, die bei der Formulierung diagnostischer Hypothesen beachtet werden sollten.\n\nNennen Sie die sechs Kriterien zur Formulierung diagnostischer Hypothesen. Die Lösung finden Sie auf den Vorlesungsfolien.\n\nBeachten Sie, dass diese Kriterien nicht vollständig analog für Forschungshypothesen gelten. Es wäre zum Beispiel ungewöhnlich, eine Forschungshypothese als Frage zu formulieren.\n\n\n\nWelche Aspekte der folgenden Hypothesen zu gegebenen Fragestellungen sind problematisch? Wie könnten die Hypothesen besser formuliert werden?\n\nFragestellung: Ist Marijke hochbegabt?\nHypothese: Löst Marijke mindestens 84% der Aufgaben eines Intelligenztests für Hochbegabtendiagnostik?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nNormbezug fehlt\n\n\n\n\nFragestellung: Ist Mona geeignet, um eine Ausbildung als Fluglotsin zu beginnen?\nHypothese: Sind Monas Konzentrationsfähigkeit und Gewissenhaftigkeit überdurchschnittlich im Vergleich zur einer gleichaltrigen Referenzstichprobe?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nNur ein Sachverhalt pro Hypothese\nNicht trennscharf genug, da kein Cutoff genannt wird\n\n\n\n\n\nFragestellung: Sind Verenas schlechte Klausurnoten auf Prüfungsangst zurückzuführen?\nHypothese: Weißt Verena im Vergleich zu Gleichaltrigen extreme Werte (\\(|z|&gt;1\\)) in der Ängstlichkeitsfacette des NEO-PI-R auf?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nBezug zur Fragestellung: Ängstlichkeit ist nicht gleich Prüfungsangst\nGerichtete Hypothese notwendig\n\n\n\n\n\nFragestellung: Sollte Emre auf Grund seiner depressiven Verstimmung eine Psychotherapie beginnen?\nHypothese: Weißt Emre depressive Symptome im klinisch relevanten Ausmaß auf?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nUnscharfe Hypothese\nNormbezug fehlt\nCutoff fehlt\n\n\n\n\n\nFragestellung: Besteht bei Hubert Verdacht auf eine beginnende Demenz?\nHypothese: Ist Huberts Leistung in einem Gedächtnistest Test &lt; 40 (T-Werte)?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nNormbezug unvollständig, da keine Referenzgruppe genannt wird\n\n\n\n\n\n\n\nHäufig muss eine globale diagnostische Fragestellung zunächst in eine spezifischere Fragestellung überführt werden, bevor (eine oder mehrere) Hypothesen abgeleitet werden können. Zum Beispiel:\n\n\n\n\n\n\n\nGlobale Fragestellung\nHat Erik die nötigen kognitiven Fähigkeiten für ein Kunststudium?\n\n\nSpezifische Fragestellung\nIst Erik mindestens durchschnittlich intelligent und überdurchschnittlich kreativ?\n\n\nHypothese(n)\nH1: Ist Eriks Leistung in einem Intelligenztest im Vergleich zu Gleichaltrigen mindestens durchschnittlich (IQ ≥ 100)?H2: Ist Eriks Leistung in einem Kreativitätstest im Vergleich zu Gleichaltrigen überdurchschnittlich (SW ≥ 110)?\n\n\n\n\nSpezifizieren Sie die folgende Fragestellung und leiten Sie eine oder mehr passende Hypothesen ab. Über die notwendigen Eigenschaften, um an der Arktisexpedition teilzunehmen können Sie selbst entscheiden.\n\n\n\n\n\n\n\nGlobale Fragestellung\nVerfügt Sonja über die notwendigen Persönlichkeitseigenschaften um an einer 3-monatigen, winterlichen Arktis-Expedition teilzunehmen?\n\n\nSpezifische Fragestellung\n…\n\n\nHypothese(n)\n…"
  },
  {
    "objectID": "sections/diagnostischer_prozess/diagnostischer_prozess.html#entscheidungsregeln",
    "href": "sections/diagnostischer_prozess/diagnostischer_prozess.html#entscheidungsregeln",
    "title": "Der Diagnostische Prozess",
    "section": "",
    "text": "Wenn mehrere Hypothesen zur selben diagnostischen Fragestellung aufgestellt wurden, müssen die Ergebnisse anhand zuvor definierter Entscheidungsregeln integriert werden. Sie haben in der Vorlesung verschiedene Typen von Entscheidungsregeln kennengelernt.\nBei Entscheidungen anhand von zwei Kriterien, lassen sich die Wertebereiche, in denen entweder eine positive oder eine negative Entscheidung getroffen wird, leicht in einem Plot darstellen:\n\n\n\n\n\n\n\n\n\nDie konkrete Entscheidungsregel im Beispiel könnte auch so beschrieben werden:\n\nDer Intelligenzwert muss mindestens 100 betragen und der Kreativitätswert muss mindestens 50 betragen.\n\nFormal kann man die Bedingung, die erfüllt sein muss, um gewählt zu werden, auch so beschreiben:\n\n\\(IQ_{Intelligenz} \\ge 100 \\wedge T_{Kreativität} \\ge  50\\)\n\nDa in der Regel zwei Bedingungen mit einem logischen Und verknüpft werden, handelt es sich um eine konjunktive Entscheidungsregel.\n\nBenennen Sie für die folgenden Beispiele um welche Art Entscheidungsregel es sich handelt. Beschreiben Sie die konkrete Entscheidungsregel entweder verbal oder mathematisch.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(IQ_{Intelligenz} \\ge 100 \\vee T_{Kreativität} \\ge  50\\)\nOder-Regel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDer Punkt \\((100, 51)\\) liegt auf der schwarz markierten Geraden. Da Kreativität und Intelligez in der Entscheidungsregel gleichgewichtet werden, ist die absolute Steigung der Geraden \\(1\\).\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(IQ_{Intelligenz} + T_{Kreativität} &gt; 150\\)\nKompensatorisch\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDer Punkt \\((99, 32)\\) liegt auf der Geraden, die eine Steigung von \\(-1\\) hat.\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\((IQ_{Intelligenz} \\ge 100 \\vee T_{Kreativität} \\ge 50) \\vee (IQ_{Intelligenz} + T_{Kreativität} &gt; 130)\\)\nSchwache Oder-Regel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDer Punkt \\((100, 51)\\) liegt auf der Geraden, die eine Steigung von \\(-1\\) hat.\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\((IQ_{Intelligenz} &gt; 85 \\wedge T_{Kreativität} &gt; 40) \\wedge (IQ_{Intelligenz} + T_{Kreativität} &gt; 150)\\)\nSchwache Konjunktive-Regel"
  },
  {
    "objectID": "sections/diagnostischer_prozess/diagnostischer_prozess.html#untersuchungspläne",
    "href": "sections/diagnostischer_prozess/diagnostischer_prozess.html#untersuchungspläne",
    "title": "Der Diagnostische Prozess",
    "section": "",
    "text": "Finden Sie je ein Beispiel für die folgenden Untersuchungspläne:\n\nSingle screen\nNicht-sequenzielle Untersuchungsbatterie\nVorauswahl Untersuchungsplan (pre-reject)\nVorentscheidungs-Untersuchungsplan (pre-select)\nVollständig sequenzieller Untersuchungsplan"
  },
  {
    "objectID": "sections/rasch_modell/rasch_modell.html",
    "href": "sections/rasch_modell/rasch_modell.html",
    "title": "Das Rasch-Modell",
    "section": "",
    "text": "Was bedeuten die folgenden Wahrscheinlichkeiten inhaltlich?\n\n\\(P(U_{14} = u_{14})\\)\n\\(P(U_{1m} = u_{1m})\\)\n\\(P(U_{im} = 0)\\)\n\\(P(U_{2j} = 1)\\)\n\\(P(U_{14} = u_{15})\\)\n\\(P(U_{ij} = 1)\\)\n\\(P(U_{ij} = 0)\\)\n\\(P(U_{ij} = u_{ij})\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nWahrscheinlichkeit, dass die Antwort von Person 1 auf Item 4 der tatsächlich beobachteten Antwort \\(u_{14}\\) entspricht.\nWahrscheinlichkeit, dass die Antwort von Person 1 auf das letzte Item \\(m\\) der tatsächlich beobachteten Antwort \\(u_{1m}\\) entspricht.\nWahrscheinlichkeit, dass Person \\(i\\) auf dem letzten Item \\(m\\) die Antwort \\(0\\) gibt.\nWahrscheinlichkeit, dass Person 2 auf einem bestimmten Item \\(j\\) die Antwort \\(1\\) gibt.\nWahrscheinlichkeit, dass die Antwort von Person 1 auf Item 4 dem beobachteten Wert auf Item 5 (\\(u_{15}\\)) entspricht.\nWahrscheinlichkeit, dass Person \\(i\\) auf Item \\(j\\) die Antwort \\(1\\) gibt.\nWahrscheinlichkeit, dass Person \\(i\\) auf Item \\(j\\) die Antwort \\(0\\) gibt.\nWahrscheinlichkeit, dass Person \\(i\\) auf Item \\(j\\) der tatsächlich beobachteten Antwort \\(u_{ij}\\) entspricht.\n\n\n\n\nDie Wahrscheinlichkeiten in dieser Aufgabe sind teilweise inhaltlich etwas ungewöhnlich. Einer Wahrscheinlichkeit wie \\(P(U_{14} = u_{15})\\) werden Sie in der IRT vermutlich nie begegnen. Dennoch ist es hilfreich, die Notation Zeichen für Zeichen lesen zu können. Den Wahrscheinlichkeiten in den Aufgaben (f)-(h) werden Sie hingegen noch öfter begegnen.\n\nBetrachten Sie die binäre Datenmatrix aus der Aufgabe zu Summenscores. Welche der folgenden Aufgaben wäre prinzipiell lösbar? Begründen Sie.\n\nLesen Sie \\(U_{12}\\) aus der binären Datenmatrix ab.\nLesen Sie \\(u_{23}\\) aus der binären Datenmatrix ab.\nLesen Sie \\(P(U_{14} = u_{14})\\) aus der binären Datenmatrix ab.\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nNicht lösbar\nLösbar\nNicht lösbar\n\n\n\n\n\n\n\nDas Rasch-Modell definiert explizit die Wahrscheinlichkeit einer Testantwort \\(u_{ij}\\):\n\\[\\begin{equation}\n    P(U_{ij} = u_{ij} | \\theta_?, \\beta_?) =\n    \\frac{\n        exp(u_{ij}(\\theta_? - \\beta_?))\n    }{\n        1 + exp(\\theta_? - \\beta_?)\n    }\n\\end{equation}\\]\n\n\n\nWofür stehen \\(\\theta\\) und \\(\\beta\\) im Rasch-Modell?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(\\theta\\): Personenparameter\n\\(\\beta\\): Itemparameter\n\n\n\n\nDie Indizes für \\(\\theta\\) und \\(\\beta\\) fehlen in der Formel zum Rasch-Modell. Versuchen Sie, die Indizes zu ergänzen, ohne auf den Folien oder in der Formelsammlung nachzusehen. Überprüfen Sie Ihre Antwort mit der Formelsammlung.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\[\\begin{equation}\n    P(U_{ij} = u_{ij} | \\theta_i, \\beta_j) =\n    \\frac{\n        exp(u_{ij}(\\theta_i - \\beta_j))\n    }{\n        1 + exp(\\theta_i - \\beta_j)\n    }\n\\end{equation}\\]\n\n\n\n\nIn welchem Wertebereich sind \\(\\theta\\) und \\(\\beta\\) jeweils definiert?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(\\theta, \\beta \\in \\mathbb{R}\\)\n\n\n\n\n\n\n\nSie haben in der ersten Aufgabe in diesem Abschnitt geübt, die Notation von Wahrscheinlichkeiten für Ereignisse in der Datenmatrix zu lesen. Dieses Wissen können Sie hier direkt anwenden. Erklären Sie die linke Seite der Gleichung zum Rasch Modell mit Worten.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Wahrscheinlichkeit (\\(P\\)), dass die Antwort von Person \\(i\\) auf Item \\(j\\) (Zufallsvariable; \\(U_{ij}\\)), dem beobachteten Wert von Person \\(i\\) auf item \\(j\\) (\\(u_{ij}\\)) entspricht (\\(=\\)), gegeben (\\(|\\)) des Personenparameters von Person \\(i\\) (\\(\\theta_i\\)), und des Itemparameters von Item \\(j\\) (\\(\\beta_j\\)).\n\n\n\n\nLeiten Sie aus der allgemeinen Formel der Antwortwahrscheinlichkeit im Rasch-Modell (siehe oben) je eine Formel für die Lösungs- und Nichtlösewahrscheinlichkeit im Rasch-Modell her. Überprüfen Sie Ihr Ergebnis mit der Formelsammlung, die Ihnen auch in der Prüfung zur Verfügung stehen wird.\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nUm die Aufgaben zu Lösen, müssen Sie jeweils für die Lösungs- und Nicht-Lösewahrscheinlichkeit den Wert von \\(u_{ij}\\) ersetzen und vereinfachen. Sie schaffen das! : -)\n\n\n\n\n\n\n\n\n\nTipp: Vollständige Herangehensweise\n\n\n\n\n\nFall 1: Lösewahrscheinlichkeit\nNehmen Sie die Formel für die Antwortwahrscheinlichkeit im Rasch-Modell und setzen Sie den beobachteten Wert, \\(u_{ij}\\) auf \\(1\\). Wenn Sie nun noch einmal vereinfachen, sind Sie schon am Ziel.\nFall 2: Nicht-Lösewahrscheinlichkeit\nNehmen Sie die Formel für die Antwortwahrscheinlichkeit im Rasch-Modell und setzen Sie den beobachteten Wert, \\(u_{ij}\\) auf \\(0\\). Nun folgenden noch zwei Vereinfachungen: (1) Wenn Sie eine Zahl mit \\(0\\) multiplizieren, erhalten Sie den Wert \\(0\\). (2) Das Ergebnis von \\(exp(0)\\) haben Sie in den grundlegenden Rechenkompetenzen schon kennengelernt.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben ist die allgemeine Formel für die Antwortwahrscheinlichkeit im Rasch-Modell:\n\\[\\begin{equation}\nP(U_{ij} = u_{ij} | \\theta_i, \\beta_j) =\n    \\frac{\n        exp(u_{ij}(\\theta_i - \\beta_j))\n    }{\n        1 + exp(\\theta_i - \\beta_j)\n    }\n\\end{equation}\\]\nFall 1: Lösewahrscheinlichkeit\nDie Lösewahrscheinlichkeit erhalten Sie, wenn Sie \\(u_{ij} = 1\\) setzen:\n\\(P(U_{ij} = 1 | \\theta_i, \\beta_j) =\n    \\frac{\n        exp(1 \\cdot (\\theta_i - \\beta_j))\n    }{\n        1 + exp(\\theta_i - \\beta_j)\n    } =\n    \\frac{\n        exp((\\theta_i - \\beta_j))\n    }{\n        1 + exp(\\theta_i - \\beta_j)\n    }\\)\nFall 2: Nicht-Lösewahrscheinlichkeit\nDie Nicht-Lösewahrscheinlichkeit erhalten Sie, wenn Sie \\(u_{ij} = 0\\) setzen:\n\\(P(U_{ij} = 0 | \\theta_i, \\beta_j) =\n    \\frac{\n        exp(0 \\cdot (\\theta_i - \\beta_j))\n    }{\n        1 + exp(\\theta_i - \\beta_j)\n    }=\n    \\frac{\n        exp(0)\n    }{\n        1 + exp(\\theta_i - \\beta_j)\n    }\n    =\\frac{\n        1\n    }{\n        1 + exp(\\theta_i - \\beta_j)\n    }\\)\n\n\n\n\nVerwenden Sie die alternative Schreibweise der logistischen Funktion aus den grundlegenden Rechenkompetenzen, um eine Schreibweise der Lösungswahrscheinlichkeit zu erhalten, die man leichter im Taschenrechner eingeben kann.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(P(U_{ij} = 1 | \\theta_i, \\beta_j) =\n    \\frac{\n        exp(\\theta_i - \\beta_j)\n    }{\n        1 + exp(\\theta_i - \\beta_j)\n    }=\n    \\frac{\n        1\n    }{\n        1 + exp(-(\\theta_i - \\beta_j))\n    }=\n    \\frac{\n        1\n    }{\n        1 + exp(-\\theta_i + \\beta_j))\n    }=\n    \\frac{\n        1\n    }{\n        1 + exp(\\beta_j-\\theta_i)\n    }\\)\n\n\n\n\nBerechnen Sie die Wahrscheinlichkeit, dass eine Person \\(i\\) mit \\(\\theta_i = 2\\) ein Item \\(1\\) mit \\(\\beta_1 = -2\\) löst. Berechnen Sie die Wahrscheinlichkeit, dass die selbe Person ein Item \\(2\\) mit \\(\\beta_2 = 0\\) nicht löst.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nLösewahrscheinlichkeit\n\\(P(U_{ij} = 1 | \\theta_i = 2, \\beta_1 = -2) =\n    \\frac{\n        1\n    }{\n        1 + exp(\\beta_j-\\theta_i)\n    }=\n    \\frac{\n        1\n    }{\n        1 + exp(-2-2)\n    }\\approx.98\\)\n\nteachIRT::p_rasch(theta = 2, beta = -2)\n\n[1] 0.9820138\n\n\nNicht-Lösewahrscheinlichkeit\n\\(P(U_{ij} = 0 | \\theta_i = 2, \\beta_2 = 0) =\n\\frac{\n        1\n    }{\n        1 + exp(\\theta_i - \\beta_j)\n    }=\n    \\frac{\n        1\n    }{\n        1 + exp(2 - 0)\n    }=\n    \\frac{\n        1\n    }{\n        1 + exp(2)\n    }\\approx 0.12\\)\n\n1-teachIRT::p_rasch(theta = 2, beta = 0)\n\n[1] 0.1192029\n\n\n\n\n\nDen Umgang mit Lösungswahrscheinlichkeiten im Rasch- und den noch folgenden IRT-Modellen sollten Sie im Schlaf beherrschen. Mit der Funktion teachIRT::p_rasch(theta, beta) können Sie sich zum Üben selbst Aufgaben zur Berechnung von Lösungswahrscheinlichkeiten stellen. Kopieren Sie dazu einfach den R-Code in Ihre IDE (z.B. RStudio):\n\n# Zufällige Parameterwerte ziehen\ntheta &lt;- rnorm(1) |&gt; round(2)\nbeta &lt;- rnorm(1) |&gt; round(2)\npaste(\"Personenparameter:\", theta) |&gt; print()\n\n[1] \"Personenparameter: 0.94\"\n\npaste(\"Itemparameter:\", beta) |&gt; print()\n\n[1] \"Itemparameter: -0.68\"\n\nloesung &lt;- teachIRT::p_rasch(theta, beta)\npaste(\"Lösewahrscheinlichkeit:\", loesung) |&gt; print()\n\n[1] \"Lösewahrscheinlichkeit: 0.834795129809385\"\n\npaste(\"Nicht-Lösewahrscheinlichkeit:\", 1-loesung) |&gt; print()\n\n[1] \"Nicht-Lösewahrscheinlichkeit: 0.165204870190615\"\n\n\n\n\n\n\nIn der Vorlesung haben Sie sogenannte Item Characteristic Curves (ICCs) kennengelernt.\n\nWas befindet sich bei ICCs jeweils auf der x- und y-Achse?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\ny-Achse: Die Wahrscheinlichkeit ein Item zu lösen\nx-Achse: Fähigkeitskontinuum\n\n\n\n\nErzeugen Sie händisch die ICC für ein Item mit \\(\\beta = 1\\) im Rasch-Modell.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nSie könnten Näherungsweise die folgenden Wahrscheinlichkeiten berechnen und in einem Graph eintragen:\n\ntheta &lt;- seq(-5, 5, 1)\nfor (i in 1:length(theta)) {\n    paste(\n        \"Lösungswahrscheinlichkeit bei einer Fähigkeit von\", \n        theta[i], \":\",\n        round(teachIRT::p_rasch(theta[i], beta = 1), 2)\n        ) |&gt; print()\n    }\n\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von -5 : 0\"\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von -4 : 0.01\"\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von -3 : 0.02\"\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von -2 : 0.05\"\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von -1 : 0.12\"\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von 0 : 0.27\"\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von 1 : 0.5\"\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von 2 : 0.73\"\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von 3 : 0.88\"\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von 4 : 0.95\"\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von 5 : 0.98\"\n\n\nZur Kontrolle:\n\nteachIRT::icc_rasch(beta = 1)\n\n\n\n\n\n\n\n\n\n\n\n\nLesen Sie die Itemschwierigkeiten der Items aus den folgenden ICCs ab:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(\\beta_1 = -1.5\\)\n\\(\\beta_2 = 0\\)\n\\(\\beta_2 = 1\\)\n\\(\\beta_2 = 2.5\\)\n\n\n\n\nPlotten Sie die ICC für ein Item mit \\(\\beta = -1\\) mit Hilfe der Funktion teachIRT::icc_rasch() und probieren Sie aus, was passiert, wenn Sie andere Werte einsetzen.\nMit ?teachIRT::icc_rasch() können Sie sich die Hilfe-Datei anzeigen lassen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nteachIRT::icc_rasch(beta = -1)\n\n\n\n\n\n\n\nteachIRT::icc_rasch(beta = 1)\n\n\n\n\n\n\n\n\nDie ICC wird entlang der \\(\\theta\\)-Achse verschoben.\n\n\n\nDas Rasch Modell kann in zwei Komponenten aufgeteilt werden: (1) Der lineare Prädiktor, \\(\\theta_i - \\beta_j\\) und (2) die logistische Link-Funktion, \\(f(x) = \\frac{exp(x)}{1 + exp(x)}\\). Setzt man den linearen Prädiktor für \\(x\\) in die logistische Funktion ein, entsteht das Rasch-Modell.\n\nWelchen Zweck erfüllt die logistische Link-Funktion im Rasch-Modell?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Funktion bildet den Wert des linearen Prädiktors (reelle Zahl) auf eine Wahrscheinlichkeit, also einen Wert im Intervall \\([0, 1]\\) ab. Aus der Statistik wissen Sie vielleicht schon, dass man binäre Variablen nicht mit einer linearen Regression vorhersagen sollte. Das gleiche Prinzip gilt in der IRT. Mit Hilfe der Link-Funktion wird aus dem linearen Prädiktor \\(\\theta_i - \\beta_j\\) eine logistische Regression, dessen Prädiktoren ein Personen- und ein Itemparameter sind.\n\n\n\n\n\n\n\n\nGegeben ist eine binäre Datenmatrix:\n\\[\\begin{equation}\n    \\label{eq:databin}\n    \\textbf{U} =\n    \\begin{bmatrix}\n        1 & 0 & 1 & 1 & 1 & 1 \\\\\n        1 & 1 & 0 & 1 & 1 & 0 \\\\\n        1 & 1 & 1 & 1 & 0 & 1 \\\\\n        0 & 1 & 1 & 0 & 1 & 1 \\\\\n    \\end{bmatrix}\n\\end{equation}\\]\n\nWelche Personen werden die gleichen geschätzten Fähigkeiten erhalten, wenn Sie ein Rasch-Modell mit Hilfe dieser Datenmatrix schätzen?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nProbieren wir es aus!\nDie Datenmatrix in R hinterlegen:\n\n# Matrix in R hinterlegen\nU &lt;- matrix(\n  c(\n    1, 0, 1, 1, 1, 1,\n    1, 1, 0, 1, 1, 0,\n    1, 1, 1, 1, 0, 1,\n    0, 1, 1, 0, 1, 1\n  ),\n  nrow = 4,\n  byrow = TRUE\n)\n\nSummenscores berechnen:\n\nrowSums(U)\n\n[1] 5 4 5 4\n\n\nAufgrund der Eigenschaft suffizienter Statistiken, sollten Personen \\(1\\) und \\(3\\) sowie Personen \\(2\\) und \\(4\\) den gleichen Personenparameter erhalten. Diese Personen haben nämlich die gleichen Summenscores.\nRasch-Modell schätzen:\n\nrasch &lt;- eRm::RM(U)\n\nPersonenparameter anzeigen:\n\neRm::person.parameter(rasch)\n\n\nPerson Parameters:\n\n Raw Score  Estimate Std.Error\n         4 0.6931467  0.866040\n         5 1.6094364  1.095503\n\n\nVon eRm erhalten wir nicht für jede Person einen Personenparameter, sondern einen Wert pro Summenscore. Das passt zu unserer zuvor formulierten Erwartung.\n\n\n\n\nWelche Items werden die gleichen geschätzten Schwierigkeiten erhalten, wenn Sie ein Rasch-Modell mit Hilfe dieser Datenmatrix schätzen?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDa die Eigenschaft suffizienter Statistiken im Rasch-Modell für Personen- und Itemparameter gilt, sollten alle Items, die gleich häufig gelöst wurden, auch den gleichen Schwierigkeitsparameter erhalten. Die Lösungshäufigkeiten können wir wie die Summenscores berechnen. Das Summenzeichen läuft nun aber über den Personen- statt den Item-Index.\n\ncolSums(U)\n\n[1] 3 3 3 3 3 3\n\n\nAlle Items wurden genau 3 Mal gelöst. Es sollten also alle Items den gleichen Schwierigkeitsparameter erhalten. In Fortsetzung der Lösung der vorherigen Aufgabe, können wir nun noch die Itemparameter extrahieren.\n\n-coef(rasch) |&gt; round(2)\n\nbeta I1 beta I2 beta I3 beta I4 beta I5 beta I6 \n      0       0       0       0       0       0 \n\n\nAuch das ist der Fall. \\(\\beta_j = 0\\) für alle \\(1 \\le j \\le 6\\).\n\n\n\nIn der Abbildung sieht man die ICCs von zwei einfachen Items (rot; Items \\(1\\) und \\(2\\)) und zwei schwierigen Items (blau, Items \\(3\\), und \\(4\\)) in einem Rechentest. Eine Person A, die nur Items \\(1\\) und \\(2\\) löst, erhält im Rasch-Modell den gleichen Fähigkeitsschätzer, wie eine Person B, die nur Items \\(3\\) und \\(4\\) löst.\n\n\n\n\n\n\n\n\n\nDie Items sind:\nItem \\(1\\): \\(4 \\cdot 5 =\\)\nItem \\(2\\): \\(6 \\cdot 8 =\\)\nItem \\(3\\): \\(\\sqrt{25} \\pi =\\)\nItem \\(4\\): \\(exp(0) - log(20) =\\)\n\nWie bewerten Sie den folgenden Dialog zwischen den beiden Diagnostiker:innen Betti und Joe?\nBetti: Es kann nicht sein, dass Personen A und B die gleichen Fähigkeitsschätzer erhalten. Person A hätte Items \\(3\\) und \\(4\\) niemals lösen können. Es wäre unfair, Personen A und B gleich zu bewerten.\nJoe: Die Summenscores sind suffiziente Statistiken für die Personenfähigkeiten. Es ist nunmal eine mathematische Konsequenz des Rasch-Modells, dass beide Personen gleich fähig sind. Daran können wir nichts ändern, auch wenn es kontraintuitiv erscheint.\n\n\n\n\n\n\n\nDie Wahrscheinlichkeit, dass ein Wurf von Münze A Kopf ergibt, ist \\(0.5\\). Die Wahrscheinlichkeit, dass ein Wurf von Münze B Kopf ergibt, ist \\(0.7\\). Zeichnen Sie einen Entscheidungsbaum für alle möglichen Ereignissenkombination der Münzwürfe A und B. Berechnen Sie anschließend die Wahrscheinlichkeiten aller möglichen Kombinationen von Münzwürfen A und B unter der Annahme, dass die Münzwürfe unabhängige Ereignisse sind. Sie können den Münzwurf A als Zufallsvariable \\(X_1\\) und den Münzwurf B als Zufallsvariable \\(X_2\\) auffassen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\n\n\n\nWas hat die Formel zur gemeinsamen Wahrscheinlichkeit unabhängiger Ereignisse aus den grundlegenden Rechenkompetenzen mit der Aufgabe zum Münzwurf zu tun?\n\\[\\begin{equation}\n    P(A \\cap B) = P(A)P(B)\n\\end{equation}\\]\ngenutzt?\n\\(A\\): Ereignis \\(A\\)\n\\(B\\): Ereignis \\(B\\)\n\\(\\cap\\): Schnittmenge zweier Ereignisse\n\n\n\n\nAus der Vorlesung wissen Sie, dass die lokale stochastische Unabhängigkeit gegeben ist, wenn gilt:\n\\[\\begin{equation}\n    P(U_1 = u_1, ..., U_m = u_m | \\theta) = \\prod_{j = 1}^{m} P(U_j = u_j | \\theta)\n\\end{equation}\\]\n\nAuf Basis der diagnostischen Rechenkompetenzen und der Sitzung zu Datenmatrizen haben Sie ausreichend Vorwissen, um die Formel zur lokalen stochastischen Unabhängigkeit vollständig nachzuvollziehen. Verbalisieren Sie die Formel von links nach rechts und Symbol für Symbol.\nTipp: Die Kommata in der ersten Klammer können Sie als “und” lesen. Also “\\(U_1 = u_1\\) und … und \\(U_m = u_m\\)”.\n\n\nErklären Sie, wie die Formel zur gemeinsamen Wahrscheinlichkeit unabhängiger Ereignisse und zur lokalen stochastischen Unabhängigkeit miteinander im Zusammenhang stehen.\n\nEine Person bearbeitet einen Test mit zwei binären Items. Der Antwortvektor der Person enthält daher zwei Elemente, \\([U_{1}, U_{2}]\\). Mögliche Realisationen des Antwortvektors sind \\([0, 0]\\) (beide Items nicht gelöst), \\([1, 0]\\) (erstes Item gelöst), \\([0, 1]\\) (zweites Items gelöst), \\([1, 1]\\) (beide Items gelöst).\n\nZeichnen Sie analog zum Münzwurf einen Entscheidungsbaum für die möglichen Realisationen des Antwortvektors. Verwenden Sie dafür die folgenden Beschriftungen:\n\n\\(P(U_1 = 0 | \\theta)\\)\n\\(P(U_1 = 0 | \\theta)\\)\n\\(P(U_2 = 1 | \\theta)\\)\n\\(P(U_2 = 1 | \\theta)\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\n\n\n\n\n\n\nDie beiden Items aus der vorherigen Aufgabe haben die Itemschwierigkeiten \\(\\beta_1 = 0\\) und \\(\\beta_2 = -1\\). Eine Person hat eine Fähigkeit von \\(\\theta = 0\\). Berechnen Sie die Wahrscheinlichkeit des Antwortvektors \\([1, 0]\\) für diese Person mit Hilfe des Rasch Modells.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben:\n\\(\\beta_1 = 0\\), \\(\\beta_2 = -1\\), \\(\\theta = 0\\)\nGesucht:\n\\(P(U_1 = 1 \\cap U_2 = 0 | \\theta)\\)\n\\(= P(U_1 = 1 | \\theta) \\cdot P(U_2 = 0 | \\theta)\\) (Unter Annahme lokaler stochastischer Unabhängigkeit)\n\\(\\approx .13\\) (Durch Einsetzen in das Rasch-Modell)\nMit teachIRT:\n\np1 &lt;- teachIRT::p_rasch(theta = 0, beta = 0)\np2 &lt;- 1 - teachIRT::p_rasch(theta = 0, beta = -1)\np1*p2\n\n[1] 0.1344707\n\n\nTipp: Die (Nicht-)Lösewahrscheinlichkeit eines Items ist im Rasch-Modell genau dann \\(0.5\\), wenn \\(\\theta = \\beta\\) ist. Diesen Fall müssen Sie also nicht separat im Taschenrechner eingeben.\n\n\n\n\nIn welchem Verhältnis stehen die Likelhood eines Antwortvektors im Rasch-Modell und die Formel zur lokalen stochastischen Unabhängigkeit?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Likelihood ist die Wahrscheinlichkeit der Daten gegeben der Parameter. Die Formel zur stochastischen Unabhängigkeit ist also eigentlich die Likelihood eines Antwortvektors im Rasch-Modell.\n\n\n\n\nErweitern Sie die rechte Seite der Formel der Likelihood eines Antwortvektors im Rasch-Modell zu einer Formel für die Likelihood der gesamten Datenmatrix im Rasch-Modell.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\[\\begin{equation}\n    \\prod_{i = 1}^{n} \\prod_{j = 1}^{m} P(U_{ij} = u_{ij} | \\theta_i)\n\\end{equation}\\]\n\n\n\n\n\n\nDie folgende Frage ist eher schwierig und gut geeignet, in einer Lerngruppe diskutiert zu werden.\n\nBegründen Sie, warum die folgende Aussage falsch ist:\n\nWenn man mehrere Items \\(j = 1, ..., m\\) zur Messung eines latenten Konstrukts im Rasch-Modell verwenden möchte, sollten die Spaltenvektoren der Datenmatrix, \\(\\textbf{u}_{.1}, ..., \\textbf{u}_{.j}, ..., \\textbf{u}_{.m}\\), paarweise möglichst unkorreliert sein, um die Annahme der lokalen stochastischen Unabhängigkeit nicht zu verletzen.\n\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nIntuitiv muss die Aussage falsch sein: Wenn man mit \\(m\\) Items tatsächlich ein gemeinsames Konstrukt misst, werden Itemantworten (also die Spaltenvektoren) miteinander korrelieren. Stellen Sie sich zum Beispiel vor, es würde sich um \\(m = 2\\) Offenheits-Items handeln. Sicherlich werden die Antworten auf zwei Items “Ich mag Gedichte” und “Ich glaube, dass Kunst wichtig ist.” sehr hoch miteinander korrelieren, denn sie messen das gleiche Konstrukt. Die Rohdaten sind also, entgegen der Behauptung, mit hoher Wahrscheinlichkeit paarweise korreliert.\nDenken Sie von hier aus weiter: Wie könnte man unter Einbezug des Rasch-Modells eine Form der Unabhängigkeit einführen?\n\n\n\n\n\n\n\nIn der Vorlesung haben Sie die Anwendung des Rasch-Modells anhand eines Algebratests kennengelernt. In der folgenden Aufgabe wurden ebenfalls die Ergebnisse eines Mathetests mit einem Rasch-Modell analysiert.\nDer Mathetest mit 20 Items wurde einer Stichprobe von 500 Testand:innen vorgegeben. Um die Passung der Items zu Testand:innenpopulation zu beurteilen, wurde ein Rasch-Modell mit dem R-Paket eRm geschätzt. Der Befehl zum Schätzen des Rasch-Modells mit dem Paket eRm heißt RM(). Die default Einstellungen der Argumente des Befehls wurden nicht überschrieben. Im Folgenden finden Sie eine Übersicht der R-Outputs der Analyse.\nDie ersten Zeilen der Datenmatrix anzeigen:\n\nhead(responses)\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n[1,]    0    1    0    1    1    1    1    1    0     0     1     0     0     1\n[2,]    1    1    1    1    1    1    1    1    0     1     1     0     0     0\n[3,]    1    1    1    1    1    1    1    1    1     1     1     1     1     1\n[4,]    1    1    1    0    1    1    1    1    0     1     1     0     1     1\n[5,]    1    1    0    1    1    1    0    1    1     1     1     0     0     1\n[6,]    1    1    1    0    1    1    1    1    1     1     1     1     1     1\n     [,15] [,16] [,17] [,18] [,19] [,20]\n[1,]     1     1     1     1     1     1\n[2,]     1     1     1     1     1     1\n[3,]     1     1     0     1     1     1\n[4,]     1     1     1     0     1     1\n[5,]     1     1     1     1     1     1\n[6,]     1     1     1     1     1     1\n\n\nDas Rasch-Modell schätzen:\n\nlibrary(eRm)\nrasch &lt;- RM(responses)\n\nItemparameter anzeigen:\n\n-coef(rasch) |&gt; round(2)\n\n beta I1  beta I2  beta I3  beta I4  beta I5  beta I6  beta I7  beta I8 \n   -0.27    -0.71     1.15     1.12    -1.46     0.28    -0.34    -1.87 \n beta I9 beta I10 beta I11 beta I12 beta I13 beta I14 beta I15 beta I16 \n    0.21     0.30     0.14     0.38     1.21     0.65    -0.42    -0.50 \nbeta I17 beta I18 beta I19 beta I20 \n    0.00     0.72    -0.66     0.05 \n\n\nPersonenparameter anzeigen:\n\nperson.parameter(rasch)\n\n\nPerson Parameters:\n\n Raw Score    Estimate Std.Error\n         5 -1.23500913 0.5489663\n         6 -0.95007794 0.5202698\n         7 -0.69012523 0.5006537\n         8 -0.44640489 0.4876778\n         9 -0.21264923 0.4800182\n        10  0.01594931 0.4770026\n        11  0.24376811 0.4784114\n        12  0.47519467 0.4844354\n        13  0.71490156 0.4957207\n        14  0.96894149 0.5135911\n        15  1.24582921 0.5405160\n        16  1.55890515 0.5812633\n        17  1.93255540 0.6461145\n        18  2.42039459 0.7621342\n        19  3.19268581 1.0382662\n        20  4.03400309        NA\n\n\nPerson-Item Map plotten:\n\nplotPImap(rasch)\n\n\n\n\n\n\n\n\n\nInstallieren Sie ggf. das Paket eRm in R (siehe Software und Literatur) und entnehmen Sie der help-File des Befehls RM(), wie die latente Skala im Paket identifiziert wird.\n\n?eRm::RM()\n\n\n\nWelches Item des Tests ist am leichtesten? Welches Item des Tests ist am schwierigsten?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nI8 ist am leichtesten.\nI13 ist am schwierigsten.\n\n\n\n\nWas ist der Mittelwert der Itemparameter? Warum?\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nDer Mittelwert der Itemparameter mit der Modellidentifikation auf einen arbiträren Wert der \\(\\theta\\)-Achse festgelegt. Überprüfen Sie noch einmal ?eRm::RM().\n\n\n\n\nBeurteilen Sie die Passung der Items zu den Testand:innen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Items liegen auf der latenten Skala links der Verteilung der Personenparameter. Wie schwierig Items für Proband:innen sein sollten hängt auch vom Testzweck ab. Wenn das Ziel wäre, die maximale Information über die Personen zu gewinnen, wären die Items eher zu leicht.\nSpäter in der Veranstaltung lernen Sie das Konzept der statistischen Information genauer kennen. Für’s Erste reicht die Intuition, dass ein Item dann am informativsten ist, wenn Sie vorab nicht wissen, ob die Person das Item lösen oder nicht lösen wird. Im Idealfall geben Sie einer Person mit einem gegebenen \\(\\theta\\) ein Rasch-skaliertes Item mit \\(\\beta = \\theta\\) vor.\n\n\n\n\nEs wurden 500 Testand:innen gemessen. Warum hat die Tabelle der Personenparameter nur 16 Zeilen?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWeil die Summenscores suffiziente Statistiken für die Personenfähigkeiten sind. Es reicht aus für jeden einzigartigen Summenscore eine Personenfähigkeit anzugeben.\n\n\n\n\nLesen Sie den geschätzten Personenparameter einer Person mit 10 richtig gelösen Items ab.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(0.02\\)\n\n\n\n\nWelche besondere Bedeutung hat der Personenparameter von 0 in diesem Fall?\n\n\nWarum fehlt der Wert Std.Error in der letzten Zeile?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nFür Personen, die alle Items gelöst haben, kann kein Standardfehler berechnet werden, da die Person theoretisch unendlich fähig sein könnte.\n\n\n\n\nDie Daten der Aufgabe sind keine empirischen Daten. Sie wurden simuliert mit \\(\\beta \\sim N(-1.5, 1)\\) und \\(\\theta \\sim N(0, 1)\\). Warum sind die geschätzten Personenparameter linksschief verteilt, obwohl sie in der Population einer Standardnormalverteilung folgen?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEs handelt sich um einen Deckeneffekt. Da die Verteilung der Personenparameter auf der latenten Dimension über der Verteilung der Itemparameter liegt, gibt es einen oberen Fähigkeitsbereich, in dem der Test nicht mehr zwischen Personen diskriminieren kann. Diese Personen erhalten gemeinsam einen hohen Personenparameter."
  },
  {
    "objectID": "sections/rasch_modell/rasch_modell.html#notation-von-wahrscheinlichkeiten-im-zusammenhang-mit-der-datenmatrix",
    "href": "sections/rasch_modell/rasch_modell.html#notation-von-wahrscheinlichkeiten-im-zusammenhang-mit-der-datenmatrix",
    "title": "Das Rasch-Modell",
    "section": "",
    "text": "Was bedeuten die folgenden Wahrscheinlichkeiten inhaltlich?\n\n\\(P(U_{14} = u_{14})\\)\n\\(P(U_{1m} = u_{1m})\\)\n\\(P(U_{im} = 0)\\)\n\\(P(U_{2j} = 1)\\)\n\\(P(U_{14} = u_{15})\\)\n\\(P(U_{ij} = 1)\\)\n\\(P(U_{ij} = 0)\\)\n\\(P(U_{ij} = u_{ij})\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nWahrscheinlichkeit, dass die Antwort von Person 1 auf Item 4 der tatsächlich beobachteten Antwort \\(u_{14}\\) entspricht.\nWahrscheinlichkeit, dass die Antwort von Person 1 auf das letzte Item \\(m\\) der tatsächlich beobachteten Antwort \\(u_{1m}\\) entspricht.\nWahrscheinlichkeit, dass Person \\(i\\) auf dem letzten Item \\(m\\) die Antwort \\(0\\) gibt.\nWahrscheinlichkeit, dass Person 2 auf einem bestimmten Item \\(j\\) die Antwort \\(1\\) gibt.\nWahrscheinlichkeit, dass die Antwort von Person 1 auf Item 4 dem beobachteten Wert auf Item 5 (\\(u_{15}\\)) entspricht.\nWahrscheinlichkeit, dass Person \\(i\\) auf Item \\(j\\) die Antwort \\(1\\) gibt.\nWahrscheinlichkeit, dass Person \\(i\\) auf Item \\(j\\) die Antwort \\(0\\) gibt.\nWahrscheinlichkeit, dass Person \\(i\\) auf Item \\(j\\) der tatsächlich beobachteten Antwort \\(u_{ij}\\) entspricht.\n\n\n\n\nDie Wahrscheinlichkeiten in dieser Aufgabe sind teilweise inhaltlich etwas ungewöhnlich. Einer Wahrscheinlichkeit wie \\(P(U_{14} = u_{15})\\) werden Sie in der IRT vermutlich nie begegnen. Dennoch ist es hilfreich, die Notation Zeichen für Zeichen lesen zu können. Den Wahrscheinlichkeiten in den Aufgaben (f)-(h) werden Sie hingegen noch öfter begegnen.\n\nBetrachten Sie die binäre Datenmatrix aus der Aufgabe zu Summenscores. Welche der folgenden Aufgaben wäre prinzipiell lösbar? Begründen Sie.\n\nLesen Sie \\(U_{12}\\) aus der binären Datenmatrix ab.\nLesen Sie \\(u_{23}\\) aus der binären Datenmatrix ab.\nLesen Sie \\(P(U_{14} = u_{14})\\) aus der binären Datenmatrix ab.\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nNicht lösbar\nLösbar\nNicht lösbar"
  },
  {
    "objectID": "sections/rasch_modell/rasch_modell.html#das-rasch-modell-1",
    "href": "sections/rasch_modell/rasch_modell.html#das-rasch-modell-1",
    "title": "Das Rasch-Modell",
    "section": "",
    "text": "Das Rasch-Modell definiert explizit die Wahrscheinlichkeit einer Testantwort \\(u_{ij}\\):\n\\[\\begin{equation}\n    P(U_{ij} = u_{ij} | \\theta_?, \\beta_?) =\n    \\frac{\n        exp(u_{ij}(\\theta_? - \\beta_?))\n    }{\n        1 + exp(\\theta_? - \\beta_?)\n    }\n\\end{equation}\\]\n\n\n\nWofür stehen \\(\\theta\\) und \\(\\beta\\) im Rasch-Modell?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(\\theta\\): Personenparameter\n\\(\\beta\\): Itemparameter\n\n\n\n\nDie Indizes für \\(\\theta\\) und \\(\\beta\\) fehlen in der Formel zum Rasch-Modell. Versuchen Sie, die Indizes zu ergänzen, ohne auf den Folien oder in der Formelsammlung nachzusehen. Überprüfen Sie Ihre Antwort mit der Formelsammlung.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\[\\begin{equation}\n    P(U_{ij} = u_{ij} | \\theta_i, \\beta_j) =\n    \\frac{\n        exp(u_{ij}(\\theta_i - \\beta_j))\n    }{\n        1 + exp(\\theta_i - \\beta_j)\n    }\n\\end{equation}\\]\n\n\n\n\nIn welchem Wertebereich sind \\(\\theta\\) und \\(\\beta\\) jeweils definiert?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(\\theta, \\beta \\in \\mathbb{R}\\)\n\n\n\n\n\n\n\nSie haben in der ersten Aufgabe in diesem Abschnitt geübt, die Notation von Wahrscheinlichkeiten für Ereignisse in der Datenmatrix zu lesen. Dieses Wissen können Sie hier direkt anwenden. Erklären Sie die linke Seite der Gleichung zum Rasch Modell mit Worten.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Wahrscheinlichkeit (\\(P\\)), dass die Antwort von Person \\(i\\) auf Item \\(j\\) (Zufallsvariable; \\(U_{ij}\\)), dem beobachteten Wert von Person \\(i\\) auf item \\(j\\) (\\(u_{ij}\\)) entspricht (\\(=\\)), gegeben (\\(|\\)) des Personenparameters von Person \\(i\\) (\\(\\theta_i\\)), und des Itemparameters von Item \\(j\\) (\\(\\beta_j\\)).\n\n\n\n\nLeiten Sie aus der allgemeinen Formel der Antwortwahrscheinlichkeit im Rasch-Modell (siehe oben) je eine Formel für die Lösungs- und Nichtlösewahrscheinlichkeit im Rasch-Modell her. Überprüfen Sie Ihr Ergebnis mit der Formelsammlung, die Ihnen auch in der Prüfung zur Verfügung stehen wird.\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nUm die Aufgaben zu Lösen, müssen Sie jeweils für die Lösungs- und Nicht-Lösewahrscheinlichkeit den Wert von \\(u_{ij}\\) ersetzen und vereinfachen. Sie schaffen das! : -)\n\n\n\n\n\n\n\n\n\nTipp: Vollständige Herangehensweise\n\n\n\n\n\nFall 1: Lösewahrscheinlichkeit\nNehmen Sie die Formel für die Antwortwahrscheinlichkeit im Rasch-Modell und setzen Sie den beobachteten Wert, \\(u_{ij}\\) auf \\(1\\). Wenn Sie nun noch einmal vereinfachen, sind Sie schon am Ziel.\nFall 2: Nicht-Lösewahrscheinlichkeit\nNehmen Sie die Formel für die Antwortwahrscheinlichkeit im Rasch-Modell und setzen Sie den beobachteten Wert, \\(u_{ij}\\) auf \\(0\\). Nun folgenden noch zwei Vereinfachungen: (1) Wenn Sie eine Zahl mit \\(0\\) multiplizieren, erhalten Sie den Wert \\(0\\). (2) Das Ergebnis von \\(exp(0)\\) haben Sie in den grundlegenden Rechenkompetenzen schon kennengelernt.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben ist die allgemeine Formel für die Antwortwahrscheinlichkeit im Rasch-Modell:\n\\[\\begin{equation}\nP(U_{ij} = u_{ij} | \\theta_i, \\beta_j) =\n    \\frac{\n        exp(u_{ij}(\\theta_i - \\beta_j))\n    }{\n        1 + exp(\\theta_i - \\beta_j)\n    }\n\\end{equation}\\]\nFall 1: Lösewahrscheinlichkeit\nDie Lösewahrscheinlichkeit erhalten Sie, wenn Sie \\(u_{ij} = 1\\) setzen:\n\\(P(U_{ij} = 1 | \\theta_i, \\beta_j) =\n    \\frac{\n        exp(1 \\cdot (\\theta_i - \\beta_j))\n    }{\n        1 + exp(\\theta_i - \\beta_j)\n    } =\n    \\frac{\n        exp((\\theta_i - \\beta_j))\n    }{\n        1 + exp(\\theta_i - \\beta_j)\n    }\\)\nFall 2: Nicht-Lösewahrscheinlichkeit\nDie Nicht-Lösewahrscheinlichkeit erhalten Sie, wenn Sie \\(u_{ij} = 0\\) setzen:\n\\(P(U_{ij} = 0 | \\theta_i, \\beta_j) =\n    \\frac{\n        exp(0 \\cdot (\\theta_i - \\beta_j))\n    }{\n        1 + exp(\\theta_i - \\beta_j)\n    }=\n    \\frac{\n        exp(0)\n    }{\n        1 + exp(\\theta_i - \\beta_j)\n    }\n    =\\frac{\n        1\n    }{\n        1 + exp(\\theta_i - \\beta_j)\n    }\\)\n\n\n\n\nVerwenden Sie die alternative Schreibweise der logistischen Funktion aus den grundlegenden Rechenkompetenzen, um eine Schreibweise der Lösungswahrscheinlichkeit zu erhalten, die man leichter im Taschenrechner eingeben kann.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(P(U_{ij} = 1 | \\theta_i, \\beta_j) =\n    \\frac{\n        exp(\\theta_i - \\beta_j)\n    }{\n        1 + exp(\\theta_i - \\beta_j)\n    }=\n    \\frac{\n        1\n    }{\n        1 + exp(-(\\theta_i - \\beta_j))\n    }=\n    \\frac{\n        1\n    }{\n        1 + exp(-\\theta_i + \\beta_j))\n    }=\n    \\frac{\n        1\n    }{\n        1 + exp(\\beta_j-\\theta_i)\n    }\\)\n\n\n\n\nBerechnen Sie die Wahrscheinlichkeit, dass eine Person \\(i\\) mit \\(\\theta_i = 2\\) ein Item \\(1\\) mit \\(\\beta_1 = -2\\) löst. Berechnen Sie die Wahrscheinlichkeit, dass die selbe Person ein Item \\(2\\) mit \\(\\beta_2 = 0\\) nicht löst.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nLösewahrscheinlichkeit\n\\(P(U_{ij} = 1 | \\theta_i = 2, \\beta_1 = -2) =\n    \\frac{\n        1\n    }{\n        1 + exp(\\beta_j-\\theta_i)\n    }=\n    \\frac{\n        1\n    }{\n        1 + exp(-2-2)\n    }\\approx.98\\)\n\nteachIRT::p_rasch(theta = 2, beta = -2)\n\n[1] 0.9820138\n\n\nNicht-Lösewahrscheinlichkeit\n\\(P(U_{ij} = 0 | \\theta_i = 2, \\beta_2 = 0) =\n\\frac{\n        1\n    }{\n        1 + exp(\\theta_i - \\beta_j)\n    }=\n    \\frac{\n        1\n    }{\n        1 + exp(2 - 0)\n    }=\n    \\frac{\n        1\n    }{\n        1 + exp(2)\n    }\\approx 0.12\\)\n\n1-teachIRT::p_rasch(theta = 2, beta = 0)\n\n[1] 0.1192029\n\n\n\n\n\nDen Umgang mit Lösungswahrscheinlichkeiten im Rasch- und den noch folgenden IRT-Modellen sollten Sie im Schlaf beherrschen. Mit der Funktion teachIRT::p_rasch(theta, beta) können Sie sich zum Üben selbst Aufgaben zur Berechnung von Lösungswahrscheinlichkeiten stellen. Kopieren Sie dazu einfach den R-Code in Ihre IDE (z.B. RStudio):\n\n# Zufällige Parameterwerte ziehen\ntheta &lt;- rnorm(1) |&gt; round(2)\nbeta &lt;- rnorm(1) |&gt; round(2)\npaste(\"Personenparameter:\", theta) |&gt; print()\n\n[1] \"Personenparameter: 0.94\"\n\npaste(\"Itemparameter:\", beta) |&gt; print()\n\n[1] \"Itemparameter: -0.68\"\n\nloesung &lt;- teachIRT::p_rasch(theta, beta)\npaste(\"Lösewahrscheinlichkeit:\", loesung) |&gt; print()\n\n[1] \"Lösewahrscheinlichkeit: 0.834795129809385\"\n\npaste(\"Nicht-Lösewahrscheinlichkeit:\", 1-loesung) |&gt; print()\n\n[1] \"Nicht-Lösewahrscheinlichkeit: 0.165204870190615\""
  },
  {
    "objectID": "sections/rasch_modell/rasch_modell.html#item-characteristic-curves-icc",
    "href": "sections/rasch_modell/rasch_modell.html#item-characteristic-curves-icc",
    "title": "Das Rasch-Modell",
    "section": "",
    "text": "In der Vorlesung haben Sie sogenannte Item Characteristic Curves (ICCs) kennengelernt.\n\nWas befindet sich bei ICCs jeweils auf der x- und y-Achse?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\ny-Achse: Die Wahrscheinlichkeit ein Item zu lösen\nx-Achse: Fähigkeitskontinuum\n\n\n\n\nErzeugen Sie händisch die ICC für ein Item mit \\(\\beta = 1\\) im Rasch-Modell.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nSie könnten Näherungsweise die folgenden Wahrscheinlichkeiten berechnen und in einem Graph eintragen:\n\ntheta &lt;- seq(-5, 5, 1)\nfor (i in 1:length(theta)) {\n    paste(\n        \"Lösungswahrscheinlichkeit bei einer Fähigkeit von\", \n        theta[i], \":\",\n        round(teachIRT::p_rasch(theta[i], beta = 1), 2)\n        ) |&gt; print()\n    }\n\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von -5 : 0\"\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von -4 : 0.01\"\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von -3 : 0.02\"\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von -2 : 0.05\"\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von -1 : 0.12\"\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von 0 : 0.27\"\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von 1 : 0.5\"\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von 2 : 0.73\"\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von 3 : 0.88\"\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von 4 : 0.95\"\n[1] \"Lösungswahrscheinlichkeit bei einer Fähigkeit von 5 : 0.98\"\n\n\nZur Kontrolle:\n\nteachIRT::icc_rasch(beta = 1)\n\n\n\n\n\n\n\n\n\n\n\n\nLesen Sie die Itemschwierigkeiten der Items aus den folgenden ICCs ab:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(\\beta_1 = -1.5\\)\n\\(\\beta_2 = 0\\)\n\\(\\beta_2 = 1\\)\n\\(\\beta_2 = 2.5\\)\n\n\n\n\nPlotten Sie die ICC für ein Item mit \\(\\beta = -1\\) mit Hilfe der Funktion teachIRT::icc_rasch() und probieren Sie aus, was passiert, wenn Sie andere Werte einsetzen.\nMit ?teachIRT::icc_rasch() können Sie sich die Hilfe-Datei anzeigen lassen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nteachIRT::icc_rasch(beta = -1)\n\n\n\n\n\n\n\nteachIRT::icc_rasch(beta = 1)\n\n\n\n\n\n\n\n\nDie ICC wird entlang der \\(\\theta\\)-Achse verschoben.\n\n\n\nDas Rasch Modell kann in zwei Komponenten aufgeteilt werden: (1) Der lineare Prädiktor, \\(\\theta_i - \\beta_j\\) und (2) die logistische Link-Funktion, \\(f(x) = \\frac{exp(x)}{1 + exp(x)}\\). Setzt man den linearen Prädiktor für \\(x\\) in die logistische Funktion ein, entsteht das Rasch-Modell.\n\nWelchen Zweck erfüllt die logistische Link-Funktion im Rasch-Modell?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Funktion bildet den Wert des linearen Prädiktors (reelle Zahl) auf eine Wahrscheinlichkeit, also einen Wert im Intervall \\([0, 1]\\) ab. Aus der Statistik wissen Sie vielleicht schon, dass man binäre Variablen nicht mit einer linearen Regression vorhersagen sollte. Das gleiche Prinzip gilt in der IRT. Mit Hilfe der Link-Funktion wird aus dem linearen Prädiktor \\(\\theta_i - \\beta_j\\) eine logistische Regression, dessen Prädiktoren ein Personen- und ein Itemparameter sind."
  },
  {
    "objectID": "sections/rasch_modell/rasch_modell.html#annahmen-und-eigenschaften-des-rasch-modells",
    "href": "sections/rasch_modell/rasch_modell.html#annahmen-und-eigenschaften-des-rasch-modells",
    "title": "Das Rasch-Modell",
    "section": "",
    "text": "Gegeben ist eine binäre Datenmatrix:\n\\[\\begin{equation}\n    \\label{eq:databin}\n    \\textbf{U} =\n    \\begin{bmatrix}\n        1 & 0 & 1 & 1 & 1 & 1 \\\\\n        1 & 1 & 0 & 1 & 1 & 0 \\\\\n        1 & 1 & 1 & 1 & 0 & 1 \\\\\n        0 & 1 & 1 & 0 & 1 & 1 \\\\\n    \\end{bmatrix}\n\\end{equation}\\]\n\nWelche Personen werden die gleichen geschätzten Fähigkeiten erhalten, wenn Sie ein Rasch-Modell mit Hilfe dieser Datenmatrix schätzen?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nProbieren wir es aus!\nDie Datenmatrix in R hinterlegen:\n\n# Matrix in R hinterlegen\nU &lt;- matrix(\n  c(\n    1, 0, 1, 1, 1, 1,\n    1, 1, 0, 1, 1, 0,\n    1, 1, 1, 1, 0, 1,\n    0, 1, 1, 0, 1, 1\n  ),\n  nrow = 4,\n  byrow = TRUE\n)\n\nSummenscores berechnen:\n\nrowSums(U)\n\n[1] 5 4 5 4\n\n\nAufgrund der Eigenschaft suffizienter Statistiken, sollten Personen \\(1\\) und \\(3\\) sowie Personen \\(2\\) und \\(4\\) den gleichen Personenparameter erhalten. Diese Personen haben nämlich die gleichen Summenscores.\nRasch-Modell schätzen:\n\nrasch &lt;- eRm::RM(U)\n\nPersonenparameter anzeigen:\n\neRm::person.parameter(rasch)\n\n\nPerson Parameters:\n\n Raw Score  Estimate Std.Error\n         4 0.6931467  0.866040\n         5 1.6094364  1.095503\n\n\nVon eRm erhalten wir nicht für jede Person einen Personenparameter, sondern einen Wert pro Summenscore. Das passt zu unserer zuvor formulierten Erwartung.\n\n\n\n\nWelche Items werden die gleichen geschätzten Schwierigkeiten erhalten, wenn Sie ein Rasch-Modell mit Hilfe dieser Datenmatrix schätzen?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDa die Eigenschaft suffizienter Statistiken im Rasch-Modell für Personen- und Itemparameter gilt, sollten alle Items, die gleich häufig gelöst wurden, auch den gleichen Schwierigkeitsparameter erhalten. Die Lösungshäufigkeiten können wir wie die Summenscores berechnen. Das Summenzeichen läuft nun aber über den Personen- statt den Item-Index.\n\ncolSums(U)\n\n[1] 3 3 3 3 3 3\n\n\nAlle Items wurden genau 3 Mal gelöst. Es sollten also alle Items den gleichen Schwierigkeitsparameter erhalten. In Fortsetzung der Lösung der vorherigen Aufgabe, können wir nun noch die Itemparameter extrahieren.\n\n-coef(rasch) |&gt; round(2)\n\nbeta I1 beta I2 beta I3 beta I4 beta I5 beta I6 \n      0       0       0       0       0       0 \n\n\nAuch das ist der Fall. \\(\\beta_j = 0\\) für alle \\(1 \\le j \\le 6\\).\n\n\n\nIn der Abbildung sieht man die ICCs von zwei einfachen Items (rot; Items \\(1\\) und \\(2\\)) und zwei schwierigen Items (blau, Items \\(3\\), und \\(4\\)) in einem Rechentest. Eine Person A, die nur Items \\(1\\) und \\(2\\) löst, erhält im Rasch-Modell den gleichen Fähigkeitsschätzer, wie eine Person B, die nur Items \\(3\\) und \\(4\\) löst.\n\n\n\n\n\n\n\n\n\nDie Items sind:\nItem \\(1\\): \\(4 \\cdot 5 =\\)\nItem \\(2\\): \\(6 \\cdot 8 =\\)\nItem \\(3\\): \\(\\sqrt{25} \\pi =\\)\nItem \\(4\\): \\(exp(0) - log(20) =\\)\n\nWie bewerten Sie den folgenden Dialog zwischen den beiden Diagnostiker:innen Betti und Joe?\nBetti: Es kann nicht sein, dass Personen A und B die gleichen Fähigkeitsschätzer erhalten. Person A hätte Items \\(3\\) und \\(4\\) niemals lösen können. Es wäre unfair, Personen A und B gleich zu bewerten.\nJoe: Die Summenscores sind suffiziente Statistiken für die Personenfähigkeiten. Es ist nunmal eine mathematische Konsequenz des Rasch-Modells, dass beide Personen gleich fähig sind. Daran können wir nichts ändern, auch wenn es kontraintuitiv erscheint.\n\n\n\n\n\n\n\nDie Wahrscheinlichkeit, dass ein Wurf von Münze A Kopf ergibt, ist \\(0.5\\). Die Wahrscheinlichkeit, dass ein Wurf von Münze B Kopf ergibt, ist \\(0.7\\). Zeichnen Sie einen Entscheidungsbaum für alle möglichen Ereignissenkombination der Münzwürfe A und B. Berechnen Sie anschließend die Wahrscheinlichkeiten aller möglichen Kombinationen von Münzwürfen A und B unter der Annahme, dass die Münzwürfe unabhängige Ereignisse sind. Sie können den Münzwurf A als Zufallsvariable \\(X_1\\) und den Münzwurf B als Zufallsvariable \\(X_2\\) auffassen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\n\n\n\nWas hat die Formel zur gemeinsamen Wahrscheinlichkeit unabhängiger Ereignisse aus den grundlegenden Rechenkompetenzen mit der Aufgabe zum Münzwurf zu tun?\n\\[\\begin{equation}\n    P(A \\cap B) = P(A)P(B)\n\\end{equation}\\]\ngenutzt?\n\\(A\\): Ereignis \\(A\\)\n\\(B\\): Ereignis \\(B\\)\n\\(\\cap\\): Schnittmenge zweier Ereignisse\n\n\n\n\nAus der Vorlesung wissen Sie, dass die lokale stochastische Unabhängigkeit gegeben ist, wenn gilt:\n\\[\\begin{equation}\n    P(U_1 = u_1, ..., U_m = u_m | \\theta) = \\prod_{j = 1}^{m} P(U_j = u_j | \\theta)\n\\end{equation}\\]\n\nAuf Basis der diagnostischen Rechenkompetenzen und der Sitzung zu Datenmatrizen haben Sie ausreichend Vorwissen, um die Formel zur lokalen stochastischen Unabhängigkeit vollständig nachzuvollziehen. Verbalisieren Sie die Formel von links nach rechts und Symbol für Symbol.\nTipp: Die Kommata in der ersten Klammer können Sie als “und” lesen. Also “\\(U_1 = u_1\\) und … und \\(U_m = u_m\\)”.\n\n\nErklären Sie, wie die Formel zur gemeinsamen Wahrscheinlichkeit unabhängiger Ereignisse und zur lokalen stochastischen Unabhängigkeit miteinander im Zusammenhang stehen.\n\nEine Person bearbeitet einen Test mit zwei binären Items. Der Antwortvektor der Person enthält daher zwei Elemente, \\([U_{1}, U_{2}]\\). Mögliche Realisationen des Antwortvektors sind \\([0, 0]\\) (beide Items nicht gelöst), \\([1, 0]\\) (erstes Item gelöst), \\([0, 1]\\) (zweites Items gelöst), \\([1, 1]\\) (beide Items gelöst).\n\nZeichnen Sie analog zum Münzwurf einen Entscheidungsbaum für die möglichen Realisationen des Antwortvektors. Verwenden Sie dafür die folgenden Beschriftungen:\n\n\\(P(U_1 = 0 | \\theta)\\)\n\\(P(U_1 = 0 | \\theta)\\)\n\\(P(U_2 = 1 | \\theta)\\)\n\\(P(U_2 = 1 | \\theta)\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\n\n\n\n\n\n\nDie beiden Items aus der vorherigen Aufgabe haben die Itemschwierigkeiten \\(\\beta_1 = 0\\) und \\(\\beta_2 = -1\\). Eine Person hat eine Fähigkeit von \\(\\theta = 0\\). Berechnen Sie die Wahrscheinlichkeit des Antwortvektors \\([1, 0]\\) für diese Person mit Hilfe des Rasch Modells.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGegeben:\n\\(\\beta_1 = 0\\), \\(\\beta_2 = -1\\), \\(\\theta = 0\\)\nGesucht:\n\\(P(U_1 = 1 \\cap U_2 = 0 | \\theta)\\)\n\\(= P(U_1 = 1 | \\theta) \\cdot P(U_2 = 0 | \\theta)\\) (Unter Annahme lokaler stochastischer Unabhängigkeit)\n\\(\\approx .13\\) (Durch Einsetzen in das Rasch-Modell)\nMit teachIRT:\n\np1 &lt;- teachIRT::p_rasch(theta = 0, beta = 0)\np2 &lt;- 1 - teachIRT::p_rasch(theta = 0, beta = -1)\np1*p2\n\n[1] 0.1344707\n\n\nTipp: Die (Nicht-)Lösewahrscheinlichkeit eines Items ist im Rasch-Modell genau dann \\(0.5\\), wenn \\(\\theta = \\beta\\) ist. Diesen Fall müssen Sie also nicht separat im Taschenrechner eingeben.\n\n\n\n\nIn welchem Verhältnis stehen die Likelhood eines Antwortvektors im Rasch-Modell und die Formel zur lokalen stochastischen Unabhängigkeit?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Likelihood ist die Wahrscheinlichkeit der Daten gegeben der Parameter. Die Formel zur stochastischen Unabhängigkeit ist also eigentlich die Likelihood eines Antwortvektors im Rasch-Modell.\n\n\n\n\nErweitern Sie die rechte Seite der Formel der Likelihood eines Antwortvektors im Rasch-Modell zu einer Formel für die Likelihood der gesamten Datenmatrix im Rasch-Modell.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\[\\begin{equation}\n    \\prod_{i = 1}^{n} \\prod_{j = 1}^{m} P(U_{ij} = u_{ij} | \\theta_i)\n\\end{equation}\\]\n\n\n\n\n\n\nDie folgende Frage ist eher schwierig und gut geeignet, in einer Lerngruppe diskutiert zu werden.\n\nBegründen Sie, warum die folgende Aussage falsch ist:\n\nWenn man mehrere Items \\(j = 1, ..., m\\) zur Messung eines latenten Konstrukts im Rasch-Modell verwenden möchte, sollten die Spaltenvektoren der Datenmatrix, \\(\\textbf{u}_{.1}, ..., \\textbf{u}_{.j}, ..., \\textbf{u}_{.m}\\), paarweise möglichst unkorreliert sein, um die Annahme der lokalen stochastischen Unabhängigkeit nicht zu verletzen.\n\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nIntuitiv muss die Aussage falsch sein: Wenn man mit \\(m\\) Items tatsächlich ein gemeinsames Konstrukt misst, werden Itemantworten (also die Spaltenvektoren) miteinander korrelieren. Stellen Sie sich zum Beispiel vor, es würde sich um \\(m = 2\\) Offenheits-Items handeln. Sicherlich werden die Antworten auf zwei Items “Ich mag Gedichte” und “Ich glaube, dass Kunst wichtig ist.” sehr hoch miteinander korrelieren, denn sie messen das gleiche Konstrukt. Die Rohdaten sind also, entgegen der Behauptung, mit hoher Wahrscheinlichkeit paarweise korreliert.\nDenken Sie von hier aus weiter: Wie könnte man unter Einbezug des Rasch-Modells eine Form der Unabhängigkeit einführen?\n\n\n\n\n\n\n\nIn der Vorlesung haben Sie die Anwendung des Rasch-Modells anhand eines Algebratests kennengelernt. In der folgenden Aufgabe wurden ebenfalls die Ergebnisse eines Mathetests mit einem Rasch-Modell analysiert.\nDer Mathetest mit 20 Items wurde einer Stichprobe von 500 Testand:innen vorgegeben. Um die Passung der Items zu Testand:innenpopulation zu beurteilen, wurde ein Rasch-Modell mit dem R-Paket eRm geschätzt. Der Befehl zum Schätzen des Rasch-Modells mit dem Paket eRm heißt RM(). Die default Einstellungen der Argumente des Befehls wurden nicht überschrieben. Im Folgenden finden Sie eine Übersicht der R-Outputs der Analyse.\nDie ersten Zeilen der Datenmatrix anzeigen:\n\nhead(responses)\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n[1,]    0    1    0    1    1    1    1    1    0     0     1     0     0     1\n[2,]    1    1    1    1    1    1    1    1    0     1     1     0     0     0\n[3,]    1    1    1    1    1    1    1    1    1     1     1     1     1     1\n[4,]    1    1    1    0    1    1    1    1    0     1     1     0     1     1\n[5,]    1    1    0    1    1    1    0    1    1     1     1     0     0     1\n[6,]    1    1    1    0    1    1    1    1    1     1     1     1     1     1\n     [,15] [,16] [,17] [,18] [,19] [,20]\n[1,]     1     1     1     1     1     1\n[2,]     1     1     1     1     1     1\n[3,]     1     1     0     1     1     1\n[4,]     1     1     1     0     1     1\n[5,]     1     1     1     1     1     1\n[6,]     1     1     1     1     1     1\n\n\nDas Rasch-Modell schätzen:\n\nlibrary(eRm)\nrasch &lt;- RM(responses)\n\nItemparameter anzeigen:\n\n-coef(rasch) |&gt; round(2)\n\n beta I1  beta I2  beta I3  beta I4  beta I5  beta I6  beta I7  beta I8 \n   -0.27    -0.71     1.15     1.12    -1.46     0.28    -0.34    -1.87 \n beta I9 beta I10 beta I11 beta I12 beta I13 beta I14 beta I15 beta I16 \n    0.21     0.30     0.14     0.38     1.21     0.65    -0.42    -0.50 \nbeta I17 beta I18 beta I19 beta I20 \n    0.00     0.72    -0.66     0.05 \n\n\nPersonenparameter anzeigen:\n\nperson.parameter(rasch)\n\n\nPerson Parameters:\n\n Raw Score    Estimate Std.Error\n         5 -1.23500913 0.5489663\n         6 -0.95007794 0.5202698\n         7 -0.69012523 0.5006537\n         8 -0.44640489 0.4876778\n         9 -0.21264923 0.4800182\n        10  0.01594931 0.4770026\n        11  0.24376811 0.4784114\n        12  0.47519467 0.4844354\n        13  0.71490156 0.4957207\n        14  0.96894149 0.5135911\n        15  1.24582921 0.5405160\n        16  1.55890515 0.5812633\n        17  1.93255540 0.6461145\n        18  2.42039459 0.7621342\n        19  3.19268581 1.0382662\n        20  4.03400309        NA\n\n\nPerson-Item Map plotten:\n\nplotPImap(rasch)\n\n\n\n\n\n\n\n\n\nInstallieren Sie ggf. das Paket eRm in R (siehe Software und Literatur) und entnehmen Sie der help-File des Befehls RM(), wie die latente Skala im Paket identifiziert wird.\n\n?eRm::RM()\n\n\n\nWelches Item des Tests ist am leichtesten? Welches Item des Tests ist am schwierigsten?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nI8 ist am leichtesten.\nI13 ist am schwierigsten.\n\n\n\n\nWas ist der Mittelwert der Itemparameter? Warum?\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nDer Mittelwert der Itemparameter mit der Modellidentifikation auf einen arbiträren Wert der \\(\\theta\\)-Achse festgelegt. Überprüfen Sie noch einmal ?eRm::RM().\n\n\n\n\nBeurteilen Sie die Passung der Items zu den Testand:innen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Items liegen auf der latenten Skala links der Verteilung der Personenparameter. Wie schwierig Items für Proband:innen sein sollten hängt auch vom Testzweck ab. Wenn das Ziel wäre, die maximale Information über die Personen zu gewinnen, wären die Items eher zu leicht.\nSpäter in der Veranstaltung lernen Sie das Konzept der statistischen Information genauer kennen. Für’s Erste reicht die Intuition, dass ein Item dann am informativsten ist, wenn Sie vorab nicht wissen, ob die Person das Item lösen oder nicht lösen wird. Im Idealfall geben Sie einer Person mit einem gegebenen \\(\\theta\\) ein Rasch-skaliertes Item mit \\(\\beta = \\theta\\) vor.\n\n\n\n\nEs wurden 500 Testand:innen gemessen. Warum hat die Tabelle der Personenparameter nur 16 Zeilen?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWeil die Summenscores suffiziente Statistiken für die Personenfähigkeiten sind. Es reicht aus für jeden einzigartigen Summenscore eine Personenfähigkeit anzugeben.\n\n\n\n\nLesen Sie den geschätzten Personenparameter einer Person mit 10 richtig gelösen Items ab.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(0.02\\)\n\n\n\n\nWelche besondere Bedeutung hat der Personenparameter von 0 in diesem Fall?\n\n\nWarum fehlt der Wert Std.Error in der letzten Zeile?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nFür Personen, die alle Items gelöst haben, kann kein Standardfehler berechnet werden, da die Person theoretisch unendlich fähig sein könnte.\n\n\n\n\nDie Daten der Aufgabe sind keine empirischen Daten. Sie wurden simuliert mit \\(\\beta \\sim N(-1.5, 1)\\) und \\(\\theta \\sim N(0, 1)\\). Warum sind die geschätzten Personenparameter linksschief verteilt, obwohl sie in der Population einer Standardnormalverteilung folgen?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEs handelt sich um einen Deckeneffekt. Da die Verteilung der Personenparameter auf der latenten Dimension über der Verteilung der Itemparameter liegt, gibt es einen oberen Fähigkeitsbereich, in dem der Test nicht mehr zwischen Personen diskriminieren kann. Diese Personen erhalten gemeinsam einen hohen Personenparameter."
  },
  {
    "objectID": "sections/lst/lst.html",
    "href": "sections/lst/lst.html",
    "title": "Latent State-Trait Modelle",
    "section": "",
    "text": "Latent State-Trait (LST) Modelle erweitern die Grundgleichung der KTT für Situationen, in denen mehrere Messzeitpunkte vorliegen.\n\n\nSie haben in der Vorlesung Pfaddarstellungen von LST Modellen, wie die folgende kennengelernt:\n\n\nBeschreiben Sie die Datensituation, auf die das gezeigte LST Modell passen würde, genauer:\n\nWie viele Messzeitpunkte liegen vor?\nWie viele Items gibt es zu jedem Messzeitpunkt?\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDas Modell passt zu einer Situation, in der drei Items zu jeweils drei Messzeitpunkten erhoben wurden.\n\n\n\n\nWelche der \\(y\\)-Variablen beziehen sich jeweils auf das gleiche Item?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nItem 1: \\(y_{11}\\), \\(y_{12}\\), \\(y_{13}\\)\nItem 2: \\(y_{21}\\), \\(y_{22}\\), \\(y_{23}\\)\nItem 3: \\(y_{31}\\), \\(y_{32}\\), \\(y_{33}\\)\n\n\n\n\nWelche der \\(y\\)-Variablen beziehen sich jeweils auf den gleichen Messzeitpunkt?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nMesszeitpunkt 1: \\(y_{11}\\), \\(y_{21}\\), \\(y_{31}\\)\nMesszeitpunkt 2: \\(y_{12}\\), \\(y_{22}\\), \\(y_{32}\\)\nMesszeitpunkt 3: \\(y_{13}\\), \\(y_{23}\\), \\(y_{33}\\)\n\n\n\n\nWelche Bedeutung haben die folgenden Parameter jeweils?\n\n\\(\\epsilon_{21}\\) (“epsilon”)\n\\(\\lambda_{32}\\) (“lambda”)\n\\(\\tau_3\\) (“tau”)\n\\(\\zeta_2\\) (“zeta”)\n\\(\\gamma_1\\) (“gamma”)\n\\(\\xi\\) (“xi”)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(\\epsilon_{21}\\): Residuum auf Item \\(2\\) zu Zeitpunkt \\(1\\). Dieser Term nimmt wie ein Residuum in der Regression alles auf, was das Modell in Variable \\(y_{21}\\) nicht vorhersagen kann.\n\\(\\lambda_{32}\\): Faktorladung von Item \\(3\\) zu Zeitpunkt \\(2\\) auf dem latenten State \\(\\tau_2\\). Der latente State beeinflusst das Item \\(y_{32}\\) gewichtet um \\(\\lambda_{32}\\).\n\\(\\tau_3\\): Die latente State-Variable für Zeitpunkt \\(3\\). Diese Variable erfasst Varianzanteile, die den Items zum Zeitpunkt \\(3\\) gemeinsam sind.\n\\(\\zeta_2\\): State-spezifisches Residuum zu Zeitpunkt \\(2\\). Dieser Term enthält die Anteile am latenten State, die durch die den stabilen Trait nicht erklärt werden können.\n\\(\\gamma_1\\): Faktorladung von State \\(1\\) auf der stabilen Trait-Variable \\(\\xi\\). Der stabile Trait beeinflusst den latenten State zu Zeitpunkt \\(1\\) gewichtet um \\(\\gamma_1\\).\n\\(\\xi\\): Stabile Trait-Variable. Diese Variable erfasst Varianzanteile, die den drei latenten States gemeinsam sind.\n\n\n\nDer Übersicht halber wurde der Personenindex \\(m\\) in der Übersicht ignoriert. Das kommt manchmal vor, wenn aus dem Kontext ersichtlich ist, welche Variablen und Parameter personenspezifisch geschätzt werden.\n\nWelche Variablen und Parameter sind personenspezifisch?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nAlle \\(\\epsilon\\)-Parameter\nAlle \\(y\\)-Variablen\nDie \\(\\lambda\\)-Parameter nicht\nAlle \\(\\tau\\)-Parameter\nAlle \\(\\zeta\\)-Parameter\nDie \\(\\gamma\\)-Parameter nicht\nDer \\(\\xi\\)-Parameter\n\n\n\n\n\n\nDie Pfaddarstellung des Modells sehr nützlich, um schnell einen Überblick über das Modell zu bekommen. Hinter der Pfaddarstellung steckt aber, wie bei den Messmodellen auch, ein System linearer Modellgleichungen. In der folgenden Aufgabe werden Sie gebeten, die Modellgleichung für ein Item zu einem Zeitpunkt aufzuschreiben. Das wird vielen vermutlich nicht leicht fallen. Das ist nicht schlimm. Versuchen Sie es trotzdem einmal. Auch wenn Sie falsch liegen, haben Sie danach noch Gelegenheit zu üben.\n\nWas ist die Modellgleichung für Item \\(2\\) zu Zeitpunkt \\(3\\)?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nAuf Basis der KTT setzt sich die Antwort aus den Komponenten \\(\\tau_{3}\\) und \\(\\epsilon_{23}\\) zusammen. \\(\\tau_3\\) ist für jedes Item zu Zeitpunkt \\(3\\) identisch, wird aber für jedes Item anders gewichtet, hier mit \\(\\lambda_{23}\\):\n\\(y_{23} = \\lambda_{23} \\cdot \\tau_{3} + \\epsilon_{23}\\)\nDer latente State zu Zeitpunkt \\(3\\) setzt sich zusammen aus dem stabilen Trait \\(\\xi\\) und einem messgelegenheitsspezifischen Residuum \\(\\zeta_3\\). Der stabile Trait ist für jeden Messzeitpunkt identisch, wird aber für jeden Zeitpunkt anders gewichtet, hier mit \\(\\gamma_3\\):\n\\(\\tau_{3} = \\gamma_3 \\cdot \\xi + \\zeta_3\\)\nNun muss man nurnoch \\(\\tau_3\\) in die erste Gleichung einsetzen:\n\\(y_{23} = \\lambda_{23} \\cdot (\\gamma_3 \\cdot \\xi + \\zeta_3) + \\epsilon_{23}\\)\nWenn man das lieber mag, kann man natürlich auch noch ausmultiplizieren:\n\\(y_{23} = \\lambda_{23} \\cdot \\gamma_3 \\cdot \\xi + \\lambda_{23} \\cdot \\zeta_3 + \\epsilon_{23}\\)\n\n\n\nWie versprochen der zweite Versuch:\n\nWas ist die Modellgleichung für Item \\(1\\) zu Zeitpunkt \\(2\\)?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(y_{12} = \\lambda_{12} \\cdot \\tau_{2} + \\epsilon_{12}\\)\n\\(\\tau_{2} = \\gamma_2 \\cdot \\xi + \\zeta_2\\)\n\\(y_{12} = \\lambda_{12} \\cdot (\\gamma_2 \\cdot \\xi + \\zeta_2) + \\epsilon_{12}\\)\n\n\n\nUnd noch einmal\n\nWas ist die Modellgleichung für Item \\(3\\) zu Zeitpunkt \\(3\\)?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(y_{33} = \\lambda_{33} \\cdot \\tau_{3} + \\epsilon_{33}\\)\n\\(\\tau_{3} = \\gamma_3 \\cdot \\xi + \\zeta_3\\)\n\\(y_{33} = \\lambda_{33} \\cdot (\\gamma_3 \\cdot \\xi + \\zeta_3) + \\epsilon_{33}\\)\n\n\n\nDie letzten drei Aufgaben sind meiner Meinung nach zentral für das tiefere Verständnis, denn die Pfaddarstellung ist nicht das Modell, sondern eine nützliche Darstellungsweise. Um tiefer mit einem Modell arbeiten zu können, sollte man auch mit der Gleichungsebene umgehen können. Diesen Umgang vertiefen wir nun noch einmal.\nIch nehme noch einmal ein Item zu einem Zeitpunkt heraus. Zum Beispiel Item \\(3\\) zum Zeitpunkt \\(1\\). Aufgrund der vorherigen Aufgaben wissen Sie, dass die Grafik die folgende Modellgleichung für dieses Item impliziert:\n\\[y_{31} = \\lambda_{31} \\cdot (\\gamma_3 \\cdot \\xi + \\zeta_3) + \\epsilon_{31}\\]\nDiese Darstellungsform ist schon sehr nützlich. Noch besser wäre es aber, eine allgemeine Modellgleichung für ein Item \\(i\\) zu einem Zeitpunkt \\(t\\) zu erhalten.\n\nBezeichnen Sie Items mit \\(i\\) und Zeitpunkte mit \\(t\\). Verallgemeinern Sie die Modellgleichung des LST Modells.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\[y_{it} = \\lambda_{it} \\cdot (\\gamma_t \\cdot \\xi + \\zeta_t) + \\epsilon_{it}\\]\n\n\n\nWie Sie aus einer vorherigen Aufgabe bereits wissen, sind einige der Gleichungskomponenten personenspezifisch. Da drei Indices schnell unübersichtlich würden, wurde das \\(m\\) für Personen hier fallengelassen. Im Prinzip könnte man es aber noch hinzufügen.\n\nFügen Sie überall wo es sinnvoll ist einen Personenindex \\(m\\) zur LST-Gleichung hinzu.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\[y_{mit} = \\lambda_{it} \\cdot (\\gamma_{t} \\cdot \\xi_m + \\zeta_{mt}) + \\epsilon_{mit}\\]\n\n\n\nIm Folgenden geht es aber ohne den Index \\(m\\) weiter.\n\n\n\nNimmt man die Modellgleichung\n\\[y_{it} = \\lambda_{it} \\cdot (\\gamma_t \\cdot \\xi + \\zeta_t) + \\epsilon_{it}\\]\nan, folgt daraus eine spezifische Varianzzerlegung für jeden Messwert. Man kann diese Varianzzerlegung herleiten. Das ist aber schon etwas fortgeschritten. Wenn Sie kein Interesse daran haben, können Sie die folgende Aufgabe getrost überspringen. Ich finde aber, es lohnt sich. :)\n\nSei\n\\[y_{it} = \\lambda_{it} \\cdot (\\gamma_t \\cdot \\xi + \\zeta_t) + \\epsilon_{it}\\]\n\\[= \\lambda_{it} \\cdot \\gamma_t \\cdot \\xi + \\lambda_{it} \\cdot \\zeta_t + \\epsilon_{it}\\]\n\\[= \\textcolor{red}{(\\lambda_{it} \\cdot \\gamma_t \\cdot \\xi)} + \\textcolor{blue}{(\\lambda_{it} \\cdot \\zeta_t)} + \\textcolor{green}{\\epsilon_{it}}\\]\neine Zufallsvariable. Berechnen Sie \\(Var(y_{it})\\).\nNutzen Sie dafür die folgenden allgemeinen Zusammenhänge der Stochastik:\nVarianz der Summe von drei Zufallsvariablen\n\\[Var(\\textcolor{red}{X} + \\textcolor{blue}{Y} + \\textcolor{green}{Z})\\]\n\\[= Var(X) + Var(Y) + Var(Z)\\]\n\\[+ 2 \\cdot Cov(X, Y) + 2 \\cdot Cov(X, Z) + 2 \\cdot Cov(Y, Z)\\]\nKonstanten in Varianzen\n\\[Var(a \\cdot X) = a^2 \\cdot Var(X)\\]\nHier verstehen wir alles als “konstant”, was nicht personenspezifisch ist, also die \\(\\lambda\\)- und \\(\\gamma\\)-Parameter.\nKonstanten in Kovarianzen\n\\[Cov(a \\cdot X, b \\cdot Y) = a \\cdot b \\cdot Cov(X, Y)\\]\nNehmen Sie außerdem an, dass alle Kovarianzen nach Annahme Null sind.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEs ist\n\\[y_{it} = (\\lambda_{it} \\cdot \\gamma_t \\cdot \\xi) + (\\lambda_{it} \\cdot \\zeta_t) + \\epsilon_{it}\\]\nMit der angegebenen Formel für die Varianz der Summe von drei Zufallsvariablen gilt\n\\[Var(y_{it})\\]\n\\[= Var(\\lambda_{it} \\cdot \\gamma_t \\cdot \\xi) + Var(\\lambda_{it} \\cdot \\zeta_t) + Var(\\epsilon_{it})\\]\n\\[+ 2 \\cdot Cov(\\lambda_{it} \\cdot \\gamma_t \\cdot \\xi, \\lambda_{it} \\cdot \\zeta_t)\\]\n\\[+ 2 \\cdot Cov(\\lambda_{it} \\cdot \\gamma_t \\cdot \\xi, \\epsilon_{it})\\]\n\\[+ 2 \\cdot Cov(\\lambda_{it} \\cdot \\zeta_t, \\epsilon_{it})\\]\nParameter, die sich nicht zwischen Personen unterscheiden (für die Formeln “Konstanten”), kann man quadrieren und als Faktor vor die Varianzen schreiben. Bei Kovarianzen muss man nicht quadrieren:\n\\[Var(y_{it})\\]\n\\[= \\lambda_{it}^2 \\cdot \\gamma_t^2 \\cdot Var(\\xi) + \\lambda_{it}^2 \\cdot Var(\\zeta_t) + Var(\\epsilon_{it})\\]\n\\[+ 2 \\cdot \\lambda_{it}^2 \\cdot \\gamma_t \\cdot Cov(\\xi, \\zeta_t)\\]\n\\[+ 2 \\cdot \\lambda_{it} \\cdot \\gamma_t \\cdot Cov(\\xi, \\epsilon_{it})\\]\n\\[+ 2 \\cdot \\lambda_{it} \\cdot Cov(\\zeta_t, \\epsilon_{it})\\]\nNun folgen allehand Annahmen.\n\nDer stabile Trait und das State-spezifische Residuum sind unabhängig voneinander und daher ist \\(Cov(\\xi, \\zeta_t) = 0\\).\nDer stabile Trait und das Item- und Zeitpunkt-spezifische Residuum sind unabhängig voneinander und daher ist \\(Cov(\\xi, \\epsilon_{it}) = 0\\).\nDas State-spezifische Residuum und das Item- und Zeitpunkt-spezifische Residuum sind unabhängig voneinander und daher ist \\(Cov(\\zeta_t, \\epsilon_{it}) = 0\\).\n\nUnter diesen Annahmen würde man für alle Kovarianzen Nullen einsetzen, sodass folgt:\n\\[Var(y_{it}) = \\lambda_{it}^2 \\cdot \\gamma_t^2 \\cdot Var(\\xi) + \\lambda_{it}^2 \\cdot Var(\\zeta_t) + Var(\\epsilon_{it})\\]\nNun sind wir schon am Ziel. Diese Varianzzerlegung finden Sie auf den Vorlesungsfolien wieder.\n\n\n\nDas Ergebnis der letzten Aufgabe ist, dass sich die Varianz einer Variablen im LST Modell wie folgt zerlegen lässt:\n\\[Var(y_{it}) = \\lambda_{it}^2 \\cdot \\gamma_t^2 \\cdot Var(\\xi) + \\lambda_{it}^2 \\cdot Var(\\zeta_t) + Var(\\epsilon_{it})\\]\nDas heißt, die Varianz der Antworten auf ein Item zu einem Zeitpunkt setzt sich additiv aus drei Komponenten zusammen.\n\naus einem Varianzanteil, der auf den stabilen Trait zurückzuführen ist:\n\n\\[\\lambda_{it}^2 \\cdot \\gamma_t^2 \\cdot Var(\\cdot \\xi)\\]\n\naus einem Varianzanteil, der auf das State-Residuum zurückzuführen ist:\n\n\\[\\lambda_{it}^2 \\cdot Var(\\zeta_t)\\]\n\naus einem Varianzanteil, der auf den Messfehler zurückzuführen ist:\n\n\\[Var(\\epsilon_{it})\\]\nDie Anteile 1., 2. und 3. kann man jeweils durch die Gesamtvarianz der Variable teilen und erhält so eine Statistik darüber, welcher Anteil der Varianz eines Items auf den stabilen Trait, das State-Residuum oder den Messfehler zurückzuführen ist.\n\nSetzen Sie die Formeln für diese Varianzanteile selbst zusammen, ohne auf den Folien nachzusehen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nIch setze voraus, dass\n\\[\nVar(y_{it}) = \\lambda_{it}^2 \\cdot \\gamma_t^2 \\cdot Var(\\cdot \\xi) + \\lambda_{it}^2 \\cdot Var(\\zeta_t) + Var(\\epsilon_{it})\n\\]\nMan könnte \\(Var(y_{it})\\) im Nenner aller Formeln auch in aufgelöster Form einsetzen. Das macht die Formeln aber schnell unübersichtlich.\n1. Varianzanteil aufgrund des stabilen Traits\nDiesen Anteil nennt man auch Konsistenz. Daher wird er hier mit \\(Con(y_{it})\\) bezeichnet.\n\\[\nCon(y_{it}) = \\frac{\n    \\lambda_{it}^2 \\cdot \\gamma_t^2 \\cdot Var(\\cdot \\xi)\n}{\n    Var(y_{it})\n}\n\\]\n2. Varianzanteil aufgrund des State-Residuums\nDiesen Anteil nennt man auch Messgelegenheitsspezifität oder abgekürzt \\(OSpe(y_{it})\\):\n\\[\nOSpe(y_{it}) = \\frac{\n    \\lambda_{it}^2 \\cdot Var(\\zeta_t)\n}{\n    Var(y_{it})\n}\n\\]\n3. Varianzanteil aufgrund des Messfehlers\nMan kann entsprechend auch einen Varianzanteil berechnen, der auf den Messfehler zurückzuführen ist:\n\\[\n\\frac{\n    Var(\\epsilon_{it})\n}{\n    Var(y_{it})\n}\n\\]\nÜblicherweise arbeitet man aber eher mit dem komplementären Varianzanteil. Diesen nennt man im LST-Kontext Reliabilität des Items \\(i\\) zur Messgelegenheit \\(t\\):\n\\[\nRel(y_{it}) = 1 - \\frac{\n    Var(\\epsilon_{it})\n}{\n    Var(y_{it})\n}\n\\]\n\n\n\n\n\n\nEin Test mit fünf Items wurde zu vier Messzeitpunkten an jeweils \\(784\\) Personen erhoben. Im Folgenden wird ein LST Modell auf die resultierenden Daten geschätzt.\n\nlibrary(lavaan)\n\nThis is lavaan 0.6-19\nlavaan is FREE software! Please report any bugs.\n\nlst &lt;- '\nstate1 =~ y_11 + y_21 + y_31 + y_41 + y_51\nstate2 =~ y_12 + y_22 + y_32 + y_42 + y_52\nstate3 =~ y_13 + y_23 + y_33 + y_43 + y_53\nstate4 =~ y_14 + y_24 + y_34 + y_44 + y_54\n\ntrait =~ state1 + state2 + state3 + state4\n'\n\nlst_fit &lt;- cfa(lst, data = dat, estimator = \"MLR\")\n\nsummary(lst_fit, standardize = TRUE, rsquare = TRUE, fit.measures = TRUE)\n\nlavaan 0.6-19 ended normally after 156 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        44\n\n  Number of observations                           784\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               177.185     176.092\n  Degrees of freedom                               166         166\n  P-value (Chi-square)                           0.262       0.281\n  Scaling correction factor                                  1.006\n    Yuan-Bentler correction (Mplus variant)                       \n\nModel Test Baseline Model:\n\n  Test statistic                              8716.493    8673.003\n  Degrees of freedom                               190         190\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.005\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.999       0.999\n  Tucker-Lewis Index (TLI)                       0.998       0.999\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.999\n  Robust Tucker-Lewis Index (TLI)                            0.999\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)                710.621     710.621\n  Scaling correction factor                                  1.022\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)        799.214     799.214\n  Scaling correction factor                                  1.009\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                               -1333.243   -1333.243\n  Bayesian (BIC)                             -1128.009   -1128.009\n  Sample-size adjusted Bayesian (SABIC)      -1267.731   -1267.731\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.009       0.009\n  90 Percent confidence interval - lower         0.000       0.000\n  90 Percent confidence interval - upper         0.019       0.019\n  P-value H_0: RMSEA &lt;= 0.050                    1.000       1.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.000       0.000\n                                                                  \n  Robust RMSEA                                               0.009\n  90 Percent confidence interval - lower                     0.000\n  90 Percent confidence interval - upper                     0.019\n  P-value H_0: Robust RMSEA &lt;= 0.050                         1.000\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.023       0.023\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  state1 =~                                                             \n    y_11              1.000                               0.181    0.653\n    y_21              0.914    0.060   15.190    0.000    0.166    0.642\n    y_31              0.891    0.063   14.213    0.000    0.162    0.622\n    y_41              0.702    0.056   12.588    0.000    0.127    0.524\n    y_51              1.138    0.076   15.013    0.000    0.206    0.719\n  state2 =~                                                             \n    y_12              1.000                               0.366    0.886\n    y_22              1.160    0.034   34.148    0.000    0.424    0.904\n    y_32              1.121    0.033   34.003    0.000    0.410    0.905\n    y_42              1.303    0.034   37.951    0.000    0.477    0.920\n    y_52              1.250    0.036   34.968    0.000    0.457    0.916\n  state3 =~                                                             \n    y_13              1.000                               0.277    0.813\n    y_23              0.728    0.034   21.145    0.000    0.201    0.719\n    y_33              0.797    0.034   23.541    0.000    0.220    0.744\n    y_43              0.706    0.035   20.127    0.000    0.195    0.700\n    y_53              0.524    0.031   17.172    0.000    0.145    0.609\n  state4 =~                                                             \n    y_14              1.000                               0.116    0.503\n    y_24              1.469    0.134   10.972    0.000    0.171    0.660\n    y_34              1.200    0.121    9.949    0.000    0.140    0.577\n    y_44              1.184    0.123    9.656    0.000    0.138    0.567\n    y_54              1.010    0.106    9.554    0.000    0.117    0.514\n  trait =~                                                              \n    state1            1.000                               0.742    0.742\n    state2            2.627    0.175   14.998    0.000    0.966    0.966\n    state3            1.816    0.135   13.453    0.000    0.883    0.883\n    state4            0.594    0.065    9.175    0.000    0.687    0.687\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .y_11              0.044    0.003   16.239    0.000    0.044    0.573\n   .y_21              0.039    0.002   16.727    0.000    0.039    0.588\n   .y_31              0.041    0.003   16.229    0.000    0.041    0.614\n   .y_41              0.043    0.002   18.435    0.000    0.043    0.725\n   .y_51              0.040    0.002   15.944    0.000    0.040    0.483\n   .y_12              0.037    0.002   16.451    0.000    0.037    0.215\n   .y_22              0.040    0.003   15.194    0.000    0.040    0.183\n   .y_32              0.037    0.002   16.767    0.000    0.037    0.180\n   .y_42              0.042    0.003   15.867    0.000    0.042    0.154\n   .y_52              0.040    0.002   16.365    0.000    0.040    0.162\n   .y_13              0.039    0.003   15.573    0.000    0.039    0.339\n   .y_23              0.038    0.002   18.156    0.000    0.038    0.483\n   .y_33              0.039    0.002   16.543    0.000    0.039    0.446\n   .y_43              0.040    0.002   17.951    0.000    0.040    0.510\n   .y_53              0.036    0.002   17.327    0.000    0.036    0.629\n   .y_14              0.040    0.002   16.607    0.000    0.040    0.747\n   .y_24              0.038    0.003   14.319    0.000    0.038    0.565\n   .y_34              0.039    0.002   16.415    0.000    0.039    0.667\n   .y_44              0.040    0.002   17.513    0.000    0.040    0.679\n   .y_54              0.038    0.002   17.359    0.000    0.038    0.736\n   .state1            0.015    0.002    7.767    0.000    0.449    0.449\n   .state2            0.009    0.004    2.547    0.011    0.067    0.067\n   .state3            0.017    0.002    7.041    0.000    0.219    0.219\n   .state4            0.007    0.001    6.113    0.000    0.528    0.528\n    trait             0.018    0.002    7.442    0.000    1.000    1.000\n\nR-Square:\n                   Estimate\n    y_11              0.427\n    y_21              0.412\n    y_31              0.386\n    y_41              0.275\n    y_51              0.517\n    y_12              0.785\n    y_22              0.817\n    y_32              0.820\n    y_42              0.846\n    y_52              0.838\n    y_13              0.661\n    y_23              0.517\n    y_33              0.554\n    y_43              0.490\n    y_53              0.371\n    y_14              0.253\n    y_24              0.435\n    y_34              0.333\n    y_44              0.321\n    y_54              0.264\n    state1            0.551\n    state2            0.933\n    state3            0.781\n    state4            0.472\n\n# Modellimplizierte Varianz-Kovarianz-Matrix\nfitted(lst_fit)\n\n$cov\n      y_11  y_21  y_31  y_41  y_51  y_12  y_22  y_32  y_42  y_52  y_13  y_23\ny_11 0.077                                                                  \ny_21 0.030 0.067                                                            \ny_31 0.029 0.027 0.068                                                      \ny_41 0.023 0.021 0.021 0.059                                                \ny_51 0.037 0.034 0.033 0.026 0.082                                          \ny_12 0.048 0.043 0.042 0.033 0.054 0.171                                    \ny_22 0.055 0.050 0.049 0.039 0.063 0.155 0.220                              \ny_32 0.053 0.049 0.048 0.037 0.061 0.150 0.174 0.205                        \ny_42 0.062 0.057 0.055 0.043 0.071 0.175 0.202 0.196 0.269                  \ny_52 0.059 0.054 0.053 0.042 0.068 0.167 0.194 0.188 0.218 0.250            \ny_13 0.033 0.030 0.029 0.023 0.037 0.086 0.100 0.097 0.113 0.108 0.116      \ny_23 0.024 0.022 0.021 0.017 0.027 0.063 0.073 0.070 0.082 0.079 0.056 0.078\ny_33 0.026 0.024 0.023 0.018 0.030 0.069 0.080 0.077 0.090 0.086 0.061 0.044\ny_43 0.023 0.021 0.021 0.016 0.026 0.061 0.071 0.068 0.079 0.076 0.054 0.039\ny_53 0.017 0.016 0.015 0.012 0.020 0.045 0.052 0.051 0.059 0.057 0.040 0.029\ny_14 0.011 0.010 0.010 0.008 0.012 0.028 0.033 0.032 0.037 0.035 0.020 0.014\ny_24 0.016 0.014 0.014 0.011 0.018 0.041 0.048 0.046 0.054 0.052 0.029 0.021\ny_34 0.013 0.012 0.011 0.009 0.015 0.034 0.039 0.038 0.044 0.042 0.023 0.017\ny_44 0.013 0.012 0.011 0.009 0.014 0.033 0.039 0.037 0.044 0.042 0.023 0.017\ny_54 0.011 0.010 0.010 0.008 0.012 0.029 0.033 0.032 0.037 0.036 0.020 0.014\n      y_33  y_43  y_53  y_14  y_24  y_34  y_44  y_54\ny_11                                                \ny_21                                                \ny_31                                                \ny_41                                                \ny_51                                                \ny_12                                                \ny_22                                                \ny_32                                                \ny_42                                                \ny_52                                                \ny_13                                                \ny_23                                                \ny_33 0.088                                          \ny_43 0.043 0.078                                    \ny_53 0.032 0.028 0.057                              \ny_14 0.016 0.014 0.010 0.054                        \ny_24 0.023 0.020 0.015 0.020 0.067                  \ny_34 0.019 0.017 0.012 0.016 0.024 0.059            \ny_44 0.018 0.016 0.012 0.016 0.023 0.019 0.059      \ny_54 0.016 0.014 0.010 0.014 0.020 0.016 0.016 0.052\n\n\n\nBeurteilen Sie den Modellfit anhand des CFI, SRMR, RMSEA und \\(\\chi^2\\)-Tests.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nMan kann CFI, SRMR und RMSEA anhand gängiger, aber arbiträrer Cutoffs beurteilen:\n\\(CFI = .999 &gt; .95\\)\n\\(SRMR = .023 &lt; 0.08\\)\n\\(RMSEA = .009 &lt; 0.08\\)\nDiese sprechen alle für einen sehr guten fit. Falls Ihnen in der Vorlesung andere Cutoffs mitgeteilt wurden, sollten Sie natürlich diese verwenden.\nDer p-Wert des \\(\\chi^2\\)-Tests ist \\(.262\\) und damit bei \\(\\alpha = 0.05\\) nicht signifikant. Die H0, dass die modellbasierte und beobachtete Varianz-Kovarianz-Matrix identisch sind, kann also nicht verworfen werden. Das spricht für einen sehr guten Modellfit.\nInsbesondere ein nicht signifikanter \\(\\chi^2\\)-Test ist bei \\(N = 784\\) Personen ungewöhnlich gut. In diesem Fall liegt das daran, dass die Daten nicht empirisch, sondern simuliert sind.\n\n\n\n\nZeichnen Sie eine Pfaddarstellung des Modells. Zeichnen Sie dort auch alle Parameter ein.\n\n\nSuchen Sie im Output die\n\nunstandardisierten State-Ladungen \\(\\lambda_{it}\\)\nunstandardisierten Trait-Ladungen \\(\\gamma_t\\)\nunstandardisierte Trait-Varianz \\(Var(\\xi)\\)\nunstandardisierte State-Varianz \\(Var(\\tau_t)\\)\nunstandardisierten State-Residuen \\(Var(\\zeta_t)\\)\nunstandardisierten Item-Residuen \\(\\epsilon_{it}\\)\nItem Varianzen \\(y_{it}\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nunstandardisierten State-Ladungen \\(\\lambda_{it}\\)\n\nz.B. bei state1 =~ y_11 in der Spalte Estimate\n\nunstandardisierten Trait-Ladungen \\(\\gamma_t\\)\n\nz.B. bei trait =~ state1 in der Spalte Estimate\n\nunstandardisierte Trait-Varianz \\(Var(\\xi)\\)\n\nUnter Variances in der Zeile trait und der Spalte Estimate\n\nunstandardisierte State-Varianz \\(Var(\\tau_t)\\)\n\nDiesen Wert findet man nicht im Output, da \\(\\tau_t\\) im Modell in einen stabilen Trait und ein State-spezifisches Residuum dekomponiert wird. Man könnte ihn aber berechnen.\n\nunstandardisierten State-Residuen \\(Var(\\zeta_t)\\)\n\nUnter Variances, z.B. in der Zeile state1 in der Spalte Estimate\n\nunstandardisierten Item-Residuen \\(\\epsilon_{it}\\)\n\nDie unstandardisierten Item-Residuen findet man nicht im Output. Sie sind personenspezifisch und würden \\(N\\) Zeilen Output erfordern. Man findet aber die Residualvarianzen, nämlich unter Variances bei den Itemnamen.\n\nItem Varianzen \\(Var(y_{it})\\)\n\nDie Itemvarianzen finden Sie auf der Hauptdiagonale der modellimplizierten Varianz-Kovarianz-Matrix. Man könnte sie aber auch aus den Parametern ausrechnen, wenn die Matrix nicht gegeben ist (siehe Formel oben).\n\n\n\n\nBerechnen Sie anhand des Outputs die Konsistenz, Messgelegenheitspezifität und Reliabilität von Item \\(4\\) zu Zeitpunkt \\(3\\).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGesucht\n\\[\nCon(y_{43}) = \\frac{\n    \\lambda_{43}^2 \\cdot \\gamma_3^2 \\cdot Var(\\xi)\n}{\n    Var(y_{43})\n}\n\\]\n\\[\nOSpe(y_{43}) = \\frac{\n    \\lambda_{43}^2 \\cdot Var(\\zeta_3)\n}{\n    Var(y_{43})\n}\n\\]\n\\[\nRel(y_{43}) = 1 - \\frac{\n    Var(\\epsilon_{43})\n}{\n    Var(y_{43})\n}\n\\]\nGegeben\nAus dem Output und der modellimplizierten Varianz-Kovarianz-Matrix:\n\\(\\lambda_{43} = 0.706\\)\n\\(\\gamma_3 = 1.816\\)\n\\(Var(\\xi) = 0.018\\)\n\\(Var(\\zeta_3) = 0.017\\)\n\\(Var(\\epsilon_{43}) = 0.040\\)\n\\(Var(y_{43}) = 0.078\\)\nEinsetzen\n\\[\nCon(y_{43})\n=\\frac{0.706^2\\cdot 1.816^2\\cdot 0.018}{0.078}\n\\approx 0.38\n\\]\n\\[\nOSpe(y_{43})\n=\\frac{0.706^2\\cdot 0.017}{0.078}\n\\approx 0.11\n\\]\n\\[\nRel(y_{43})\n=1-\\frac{0.040}{0.078}\n\\approx 0.49\n\\]\nZur Überprüfung kann man noch einmal schauen, ob der berechnete Wert von \\(Rel(y_{43})\\) dem Wert bei R-Square im Output entspricht. Das ist hier der Fall.\n\n\n\n\nZum Weiterüben finden Sie hier die Konsistenzen und Messgelegenheitsspezifitäten aller Items zu allen Zeitpunkten. Die Reliabilitäten können Sie unter R-Square im Output ablesen.\nBeachten Sie, dass es zu Rundungsabweichungen kommen kann, da die Lösungen mit ungerundeten Parameterschätzungen berechnet wurden.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\n[1] \"Item: 1 Zeitpunkt: 1 Konsistenz: 0.24 M.Spezifität: 0.19\"\n[1] \"Item: 1 Zeitpunkt: 2 Konsistenz: 0.73 M.Spezifität: 0.05\"\n[1] \"Item: 1 Zeitpunkt: 3 Konsistenz: 0.52 M.Spezifität: 0.15\"\n[1] \"Item: 1 Zeitpunkt: 4 Konsistenz: 0.12 M.Spezifität: 0.13\"\n[1] \"Item: 2 Zeitpunkt: 1 Konsistenz: 0.23 M.Spezifität: 0.18\"\n[1] \"Item: 2 Zeitpunkt: 2 Konsistenz: 0.76 M.Spezifität: 0.06\"\n[1] \"Item: 2 Zeitpunkt: 3 Konsistenz: 0.4 M.Spezifität: 0.11\"\n[1] \"Item: 2 Zeitpunkt: 4 Konsistenz: 0.21 M.Spezifität: 0.23\"\n[1] \"Item: 3 Zeitpunkt: 1 Konsistenz: 0.21 M.Spezifität: 0.17\"\n[1] \"Item: 3 Zeitpunkt: 2 Konsistenz: 0.76 M.Spezifität: 0.06\"\n[1] \"Item: 3 Zeitpunkt: 3 Konsistenz: 0.43 M.Spezifität: 0.12\"\n[1] \"Item: 3 Zeitpunkt: 4 Konsistenz: 0.16 M.Spezifität: 0.18\"\n[1] \"Item: 4 Zeitpunkt: 1 Konsistenz: 0.15 M.Spezifität: 0.12\"\n[1] \"Item: 4 Zeitpunkt: 2 Konsistenz: 0.79 M.Spezifität: 0.06\"\n[1] \"Item: 4 Zeitpunkt: 3 Konsistenz: 0.38 M.Spezifität: 0.11\"\n[1] \"Item: 4 Zeitpunkt: 4 Konsistenz: 0.15 M.Spezifität: 0.17\"\n[1] \"Item: 5 Zeitpunkt: 1 Konsistenz: 0.28 M.Spezifität: 0.23\"\n[1] \"Item: 5 Zeitpunkt: 2 Konsistenz: 0.78 M.Spezifität: 0.06\"\n[1] \"Item: 5 Zeitpunkt: 3 Konsistenz: 0.29 M.Spezifität: 0.08\"\n[1] \"Item: 5 Zeitpunkt: 4 Konsistenz: 0.12 M.Spezifität: 0.14\""
  },
  {
    "objectID": "sections/lst/lst.html#pfaddarstellung-von-lst-modellen",
    "href": "sections/lst/lst.html#pfaddarstellung-von-lst-modellen",
    "title": "Latent State-Trait Modelle",
    "section": "",
    "text": "Sie haben in der Vorlesung Pfaddarstellungen von LST Modellen, wie die folgende kennengelernt:\n\n\nBeschreiben Sie die Datensituation, auf die das gezeigte LST Modell passen würde, genauer:\n\nWie viele Messzeitpunkte liegen vor?\nWie viele Items gibt es zu jedem Messzeitpunkt?\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDas Modell passt zu einer Situation, in der drei Items zu jeweils drei Messzeitpunkten erhoben wurden.\n\n\n\n\nWelche der \\(y\\)-Variablen beziehen sich jeweils auf das gleiche Item?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nItem 1: \\(y_{11}\\), \\(y_{12}\\), \\(y_{13}\\)\nItem 2: \\(y_{21}\\), \\(y_{22}\\), \\(y_{23}\\)\nItem 3: \\(y_{31}\\), \\(y_{32}\\), \\(y_{33}\\)\n\n\n\n\nWelche der \\(y\\)-Variablen beziehen sich jeweils auf den gleichen Messzeitpunkt?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nMesszeitpunkt 1: \\(y_{11}\\), \\(y_{21}\\), \\(y_{31}\\)\nMesszeitpunkt 2: \\(y_{12}\\), \\(y_{22}\\), \\(y_{32}\\)\nMesszeitpunkt 3: \\(y_{13}\\), \\(y_{23}\\), \\(y_{33}\\)\n\n\n\n\nWelche Bedeutung haben die folgenden Parameter jeweils?\n\n\\(\\epsilon_{21}\\) (“epsilon”)\n\\(\\lambda_{32}\\) (“lambda”)\n\\(\\tau_3\\) (“tau”)\n\\(\\zeta_2\\) (“zeta”)\n\\(\\gamma_1\\) (“gamma”)\n\\(\\xi\\) (“xi”)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(\\epsilon_{21}\\): Residuum auf Item \\(2\\) zu Zeitpunkt \\(1\\). Dieser Term nimmt wie ein Residuum in der Regression alles auf, was das Modell in Variable \\(y_{21}\\) nicht vorhersagen kann.\n\\(\\lambda_{32}\\): Faktorladung von Item \\(3\\) zu Zeitpunkt \\(2\\) auf dem latenten State \\(\\tau_2\\). Der latente State beeinflusst das Item \\(y_{32}\\) gewichtet um \\(\\lambda_{32}\\).\n\\(\\tau_3\\): Die latente State-Variable für Zeitpunkt \\(3\\). Diese Variable erfasst Varianzanteile, die den Items zum Zeitpunkt \\(3\\) gemeinsam sind.\n\\(\\zeta_2\\): State-spezifisches Residuum zu Zeitpunkt \\(2\\). Dieser Term enthält die Anteile am latenten State, die durch die den stabilen Trait nicht erklärt werden können.\n\\(\\gamma_1\\): Faktorladung von State \\(1\\) auf der stabilen Trait-Variable \\(\\xi\\). Der stabile Trait beeinflusst den latenten State zu Zeitpunkt \\(1\\) gewichtet um \\(\\gamma_1\\).\n\\(\\xi\\): Stabile Trait-Variable. Diese Variable erfasst Varianzanteile, die den drei latenten States gemeinsam sind.\n\n\n\nDer Übersicht halber wurde der Personenindex \\(m\\) in der Übersicht ignoriert. Das kommt manchmal vor, wenn aus dem Kontext ersichtlich ist, welche Variablen und Parameter personenspezifisch geschätzt werden.\n\nWelche Variablen und Parameter sind personenspezifisch?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nAlle \\(\\epsilon\\)-Parameter\nAlle \\(y\\)-Variablen\nDie \\(\\lambda\\)-Parameter nicht\nAlle \\(\\tau\\)-Parameter\nAlle \\(\\zeta\\)-Parameter\nDie \\(\\gamma\\)-Parameter nicht\nDer \\(\\xi\\)-Parameter"
  },
  {
    "objectID": "sections/lst/lst.html#von-der-pfaddarstellung-zu-modellgleichungen",
    "href": "sections/lst/lst.html#von-der-pfaddarstellung-zu-modellgleichungen",
    "title": "Latent State-Trait Modelle",
    "section": "",
    "text": "Die Pfaddarstellung des Modells sehr nützlich, um schnell einen Überblick über das Modell zu bekommen. Hinter der Pfaddarstellung steckt aber, wie bei den Messmodellen auch, ein System linearer Modellgleichungen. In der folgenden Aufgabe werden Sie gebeten, die Modellgleichung für ein Item zu einem Zeitpunkt aufzuschreiben. Das wird vielen vermutlich nicht leicht fallen. Das ist nicht schlimm. Versuchen Sie es trotzdem einmal. Auch wenn Sie falsch liegen, haben Sie danach noch Gelegenheit zu üben.\n\nWas ist die Modellgleichung für Item \\(2\\) zu Zeitpunkt \\(3\\)?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nAuf Basis der KTT setzt sich die Antwort aus den Komponenten \\(\\tau_{3}\\) und \\(\\epsilon_{23}\\) zusammen. \\(\\tau_3\\) ist für jedes Item zu Zeitpunkt \\(3\\) identisch, wird aber für jedes Item anders gewichtet, hier mit \\(\\lambda_{23}\\):\n\\(y_{23} = \\lambda_{23} \\cdot \\tau_{3} + \\epsilon_{23}\\)\nDer latente State zu Zeitpunkt \\(3\\) setzt sich zusammen aus dem stabilen Trait \\(\\xi\\) und einem messgelegenheitsspezifischen Residuum \\(\\zeta_3\\). Der stabile Trait ist für jeden Messzeitpunkt identisch, wird aber für jeden Zeitpunkt anders gewichtet, hier mit \\(\\gamma_3\\):\n\\(\\tau_{3} = \\gamma_3 \\cdot \\xi + \\zeta_3\\)\nNun muss man nurnoch \\(\\tau_3\\) in die erste Gleichung einsetzen:\n\\(y_{23} = \\lambda_{23} \\cdot (\\gamma_3 \\cdot \\xi + \\zeta_3) + \\epsilon_{23}\\)\nWenn man das lieber mag, kann man natürlich auch noch ausmultiplizieren:\n\\(y_{23} = \\lambda_{23} \\cdot \\gamma_3 \\cdot \\xi + \\lambda_{23} \\cdot \\zeta_3 + \\epsilon_{23}\\)\n\n\n\nWie versprochen der zweite Versuch:\n\nWas ist die Modellgleichung für Item \\(1\\) zu Zeitpunkt \\(2\\)?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(y_{12} = \\lambda_{12} \\cdot \\tau_{2} + \\epsilon_{12}\\)\n\\(\\tau_{2} = \\gamma_2 \\cdot \\xi + \\zeta_2\\)\n\\(y_{12} = \\lambda_{12} \\cdot (\\gamma_2 \\cdot \\xi + \\zeta_2) + \\epsilon_{12}\\)\n\n\n\nUnd noch einmal\n\nWas ist die Modellgleichung für Item \\(3\\) zu Zeitpunkt \\(3\\)?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\(y_{33} = \\lambda_{33} \\cdot \\tau_{3} + \\epsilon_{33}\\)\n\\(\\tau_{3} = \\gamma_3 \\cdot \\xi + \\zeta_3\\)\n\\(y_{33} = \\lambda_{33} \\cdot (\\gamma_3 \\cdot \\xi + \\zeta_3) + \\epsilon_{33}\\)\n\n\n\nDie letzten drei Aufgaben sind meiner Meinung nach zentral für das tiefere Verständnis, denn die Pfaddarstellung ist nicht das Modell, sondern eine nützliche Darstellungsweise. Um tiefer mit einem Modell arbeiten zu können, sollte man auch mit der Gleichungsebene umgehen können. Diesen Umgang vertiefen wir nun noch einmal.\nIch nehme noch einmal ein Item zu einem Zeitpunkt heraus. Zum Beispiel Item \\(3\\) zum Zeitpunkt \\(1\\). Aufgrund der vorherigen Aufgaben wissen Sie, dass die Grafik die folgende Modellgleichung für dieses Item impliziert:\n\\[y_{31} = \\lambda_{31} \\cdot (\\gamma_3 \\cdot \\xi + \\zeta_3) + \\epsilon_{31}\\]\nDiese Darstellungsform ist schon sehr nützlich. Noch besser wäre es aber, eine allgemeine Modellgleichung für ein Item \\(i\\) zu einem Zeitpunkt \\(t\\) zu erhalten.\n\nBezeichnen Sie Items mit \\(i\\) und Zeitpunkte mit \\(t\\). Verallgemeinern Sie die Modellgleichung des LST Modells.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\[y_{it} = \\lambda_{it} \\cdot (\\gamma_t \\cdot \\xi + \\zeta_t) + \\epsilon_{it}\\]\n\n\n\nWie Sie aus einer vorherigen Aufgabe bereits wissen, sind einige der Gleichungskomponenten personenspezifisch. Da drei Indices schnell unübersichtlich würden, wurde das \\(m\\) für Personen hier fallengelassen. Im Prinzip könnte man es aber noch hinzufügen.\n\nFügen Sie überall wo es sinnvoll ist einen Personenindex \\(m\\) zur LST-Gleichung hinzu.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\\[y_{mit} = \\lambda_{it} \\cdot (\\gamma_{t} \\cdot \\xi_m + \\zeta_{mt}) + \\epsilon_{mit}\\]\n\n\n\nIm Folgenden geht es aber ohne den Index \\(m\\) weiter."
  },
  {
    "objectID": "sections/lst/lst.html#varianzzerlegung",
    "href": "sections/lst/lst.html#varianzzerlegung",
    "title": "Latent State-Trait Modelle",
    "section": "",
    "text": "Nimmt man die Modellgleichung\n\\[y_{it} = \\lambda_{it} \\cdot (\\gamma_t \\cdot \\xi + \\zeta_t) + \\epsilon_{it}\\]\nan, folgt daraus eine spezifische Varianzzerlegung für jeden Messwert. Man kann diese Varianzzerlegung herleiten. Das ist aber schon etwas fortgeschritten. Wenn Sie kein Interesse daran haben, können Sie die folgende Aufgabe getrost überspringen. Ich finde aber, es lohnt sich. :)\n\nSei\n\\[y_{it} = \\lambda_{it} \\cdot (\\gamma_t \\cdot \\xi + \\zeta_t) + \\epsilon_{it}\\]\n\\[= \\lambda_{it} \\cdot \\gamma_t \\cdot \\xi + \\lambda_{it} \\cdot \\zeta_t + \\epsilon_{it}\\]\n\\[= \\textcolor{red}{(\\lambda_{it} \\cdot \\gamma_t \\cdot \\xi)} + \\textcolor{blue}{(\\lambda_{it} \\cdot \\zeta_t)} + \\textcolor{green}{\\epsilon_{it}}\\]\neine Zufallsvariable. Berechnen Sie \\(Var(y_{it})\\).\nNutzen Sie dafür die folgenden allgemeinen Zusammenhänge der Stochastik:\nVarianz der Summe von drei Zufallsvariablen\n\\[Var(\\textcolor{red}{X} + \\textcolor{blue}{Y} + \\textcolor{green}{Z})\\]\n\\[= Var(X) + Var(Y) + Var(Z)\\]\n\\[+ 2 \\cdot Cov(X, Y) + 2 \\cdot Cov(X, Z) + 2 \\cdot Cov(Y, Z)\\]\nKonstanten in Varianzen\n\\[Var(a \\cdot X) = a^2 \\cdot Var(X)\\]\nHier verstehen wir alles als “konstant”, was nicht personenspezifisch ist, also die \\(\\lambda\\)- und \\(\\gamma\\)-Parameter.\nKonstanten in Kovarianzen\n\\[Cov(a \\cdot X, b \\cdot Y) = a \\cdot b \\cdot Cov(X, Y)\\]\nNehmen Sie außerdem an, dass alle Kovarianzen nach Annahme Null sind.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nEs ist\n\\[y_{it} = (\\lambda_{it} \\cdot \\gamma_t \\cdot \\xi) + (\\lambda_{it} \\cdot \\zeta_t) + \\epsilon_{it}\\]\nMit der angegebenen Formel für die Varianz der Summe von drei Zufallsvariablen gilt\n\\[Var(y_{it})\\]\n\\[= Var(\\lambda_{it} \\cdot \\gamma_t \\cdot \\xi) + Var(\\lambda_{it} \\cdot \\zeta_t) + Var(\\epsilon_{it})\\]\n\\[+ 2 \\cdot Cov(\\lambda_{it} \\cdot \\gamma_t \\cdot \\xi, \\lambda_{it} \\cdot \\zeta_t)\\]\n\\[+ 2 \\cdot Cov(\\lambda_{it} \\cdot \\gamma_t \\cdot \\xi, \\epsilon_{it})\\]\n\\[+ 2 \\cdot Cov(\\lambda_{it} \\cdot \\zeta_t, \\epsilon_{it})\\]\nParameter, die sich nicht zwischen Personen unterscheiden (für die Formeln “Konstanten”), kann man quadrieren und als Faktor vor die Varianzen schreiben. Bei Kovarianzen muss man nicht quadrieren:\n\\[Var(y_{it})\\]\n\\[= \\lambda_{it}^2 \\cdot \\gamma_t^2 \\cdot Var(\\xi) + \\lambda_{it}^2 \\cdot Var(\\zeta_t) + Var(\\epsilon_{it})\\]\n\\[+ 2 \\cdot \\lambda_{it}^2 \\cdot \\gamma_t \\cdot Cov(\\xi, \\zeta_t)\\]\n\\[+ 2 \\cdot \\lambda_{it} \\cdot \\gamma_t \\cdot Cov(\\xi, \\epsilon_{it})\\]\n\\[+ 2 \\cdot \\lambda_{it} \\cdot Cov(\\zeta_t, \\epsilon_{it})\\]\nNun folgen allehand Annahmen.\n\nDer stabile Trait und das State-spezifische Residuum sind unabhängig voneinander und daher ist \\(Cov(\\xi, \\zeta_t) = 0\\).\nDer stabile Trait und das Item- und Zeitpunkt-spezifische Residuum sind unabhängig voneinander und daher ist \\(Cov(\\xi, \\epsilon_{it}) = 0\\).\nDas State-spezifische Residuum und das Item- und Zeitpunkt-spezifische Residuum sind unabhängig voneinander und daher ist \\(Cov(\\zeta_t, \\epsilon_{it}) = 0\\).\n\nUnter diesen Annahmen würde man für alle Kovarianzen Nullen einsetzen, sodass folgt:\n\\[Var(y_{it}) = \\lambda_{it}^2 \\cdot \\gamma_t^2 \\cdot Var(\\xi) + \\lambda_{it}^2 \\cdot Var(\\zeta_t) + Var(\\epsilon_{it})\\]\nNun sind wir schon am Ziel. Diese Varianzzerlegung finden Sie auf den Vorlesungsfolien wieder.\n\n\n\nDas Ergebnis der letzten Aufgabe ist, dass sich die Varianz einer Variablen im LST Modell wie folgt zerlegen lässt:\n\\[Var(y_{it}) = \\lambda_{it}^2 \\cdot \\gamma_t^2 \\cdot Var(\\xi) + \\lambda_{it}^2 \\cdot Var(\\zeta_t) + Var(\\epsilon_{it})\\]\nDas heißt, die Varianz der Antworten auf ein Item zu einem Zeitpunkt setzt sich additiv aus drei Komponenten zusammen.\n\naus einem Varianzanteil, der auf den stabilen Trait zurückzuführen ist:\n\n\\[\\lambda_{it}^2 \\cdot \\gamma_t^2 \\cdot Var(\\cdot \\xi)\\]\n\naus einem Varianzanteil, der auf das State-Residuum zurückzuführen ist:\n\n\\[\\lambda_{it}^2 \\cdot Var(\\zeta_t)\\]\n\naus einem Varianzanteil, der auf den Messfehler zurückzuführen ist:\n\n\\[Var(\\epsilon_{it})\\]\nDie Anteile 1., 2. und 3. kann man jeweils durch die Gesamtvarianz der Variable teilen und erhält so eine Statistik darüber, welcher Anteil der Varianz eines Items auf den stabilen Trait, das State-Residuum oder den Messfehler zurückzuführen ist.\n\nSetzen Sie die Formeln für diese Varianzanteile selbst zusammen, ohne auf den Folien nachzusehen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nIch setze voraus, dass\n\\[\nVar(y_{it}) = \\lambda_{it}^2 \\cdot \\gamma_t^2 \\cdot Var(\\cdot \\xi) + \\lambda_{it}^2 \\cdot Var(\\zeta_t) + Var(\\epsilon_{it})\n\\]\nMan könnte \\(Var(y_{it})\\) im Nenner aller Formeln auch in aufgelöster Form einsetzen. Das macht die Formeln aber schnell unübersichtlich.\n1. Varianzanteil aufgrund des stabilen Traits\nDiesen Anteil nennt man auch Konsistenz. Daher wird er hier mit \\(Con(y_{it})\\) bezeichnet.\n\\[\nCon(y_{it}) = \\frac{\n    \\lambda_{it}^2 \\cdot \\gamma_t^2 \\cdot Var(\\cdot \\xi)\n}{\n    Var(y_{it})\n}\n\\]\n2. Varianzanteil aufgrund des State-Residuums\nDiesen Anteil nennt man auch Messgelegenheitsspezifität oder abgekürzt \\(OSpe(y_{it})\\):\n\\[\nOSpe(y_{it}) = \\frac{\n    \\lambda_{it}^2 \\cdot Var(\\zeta_t)\n}{\n    Var(y_{it})\n}\n\\]\n3. Varianzanteil aufgrund des Messfehlers\nMan kann entsprechend auch einen Varianzanteil berechnen, der auf den Messfehler zurückzuführen ist:\n\\[\n\\frac{\n    Var(\\epsilon_{it})\n}{\n    Var(y_{it})\n}\n\\]\nÜblicherweise arbeitet man aber eher mit dem komplementären Varianzanteil. Diesen nennt man im LST-Kontext Reliabilität des Items \\(i\\) zur Messgelegenheit \\(t\\):\n\\[\nRel(y_{it}) = 1 - \\frac{\n    Var(\\epsilon_{it})\n}{\n    Var(y_{it})\n}\n\\]"
  },
  {
    "objectID": "sections/lst/lst.html#datenbeispiel",
    "href": "sections/lst/lst.html#datenbeispiel",
    "title": "Latent State-Trait Modelle",
    "section": "",
    "text": "Ein Test mit fünf Items wurde zu vier Messzeitpunkten an jeweils \\(784\\) Personen erhoben. Im Folgenden wird ein LST Modell auf die resultierenden Daten geschätzt.\n\nlibrary(lavaan)\n\nThis is lavaan 0.6-19\nlavaan is FREE software! Please report any bugs.\n\nlst &lt;- '\nstate1 =~ y_11 + y_21 + y_31 + y_41 + y_51\nstate2 =~ y_12 + y_22 + y_32 + y_42 + y_52\nstate3 =~ y_13 + y_23 + y_33 + y_43 + y_53\nstate4 =~ y_14 + y_24 + y_34 + y_44 + y_54\n\ntrait =~ state1 + state2 + state3 + state4\n'\n\nlst_fit &lt;- cfa(lst, data = dat, estimator = \"MLR\")\n\nsummary(lst_fit, standardize = TRUE, rsquare = TRUE, fit.measures = TRUE)\n\nlavaan 0.6-19 ended normally after 156 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        44\n\n  Number of observations                           784\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               177.185     176.092\n  Degrees of freedom                               166         166\n  P-value (Chi-square)                           0.262       0.281\n  Scaling correction factor                                  1.006\n    Yuan-Bentler correction (Mplus variant)                       \n\nModel Test Baseline Model:\n\n  Test statistic                              8716.493    8673.003\n  Degrees of freedom                               190         190\n  P-value                                        0.000       0.000\n  Scaling correction factor                                  1.005\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.999       0.999\n  Tucker-Lewis Index (TLI)                       0.998       0.999\n                                                                  \n  Robust Comparative Fit Index (CFI)                         0.999\n  Robust Tucker-Lewis Index (TLI)                            0.999\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)                710.621     710.621\n  Scaling correction factor                                  1.022\n      for the MLR correction                                      \n  Loglikelihood unrestricted model (H1)        799.214     799.214\n  Scaling correction factor                                  1.009\n      for the MLR correction                                      \n                                                                  \n  Akaike (AIC)                               -1333.243   -1333.243\n  Bayesian (BIC)                             -1128.009   -1128.009\n  Sample-size adjusted Bayesian (SABIC)      -1267.731   -1267.731\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.009       0.009\n  90 Percent confidence interval - lower         0.000       0.000\n  90 Percent confidence interval - upper         0.019       0.019\n  P-value H_0: RMSEA &lt;= 0.050                    1.000       1.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.000       0.000\n                                                                  \n  Robust RMSEA                                               0.009\n  90 Percent confidence interval - lower                     0.000\n  90 Percent confidence interval - upper                     0.019\n  P-value H_0: Robust RMSEA &lt;= 0.050                         1.000\n  P-value H_0: Robust RMSEA &gt;= 0.080                         0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.023       0.023\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  state1 =~                                                             \n    y_11              1.000                               0.181    0.653\n    y_21              0.914    0.060   15.190    0.000    0.166    0.642\n    y_31              0.891    0.063   14.213    0.000    0.162    0.622\n    y_41              0.702    0.056   12.588    0.000    0.127    0.524\n    y_51              1.138    0.076   15.013    0.000    0.206    0.719\n  state2 =~                                                             \n    y_12              1.000                               0.366    0.886\n    y_22              1.160    0.034   34.148    0.000    0.424    0.904\n    y_32              1.121    0.033   34.003    0.000    0.410    0.905\n    y_42              1.303    0.034   37.951    0.000    0.477    0.920\n    y_52              1.250    0.036   34.968    0.000    0.457    0.916\n  state3 =~                                                             \n    y_13              1.000                               0.277    0.813\n    y_23              0.728    0.034   21.145    0.000    0.201    0.719\n    y_33              0.797    0.034   23.541    0.000    0.220    0.744\n    y_43              0.706    0.035   20.127    0.000    0.195    0.700\n    y_53              0.524    0.031   17.172    0.000    0.145    0.609\n  state4 =~                                                             \n    y_14              1.000                               0.116    0.503\n    y_24              1.469    0.134   10.972    0.000    0.171    0.660\n    y_34              1.200    0.121    9.949    0.000    0.140    0.577\n    y_44              1.184    0.123    9.656    0.000    0.138    0.567\n    y_54              1.010    0.106    9.554    0.000    0.117    0.514\n  trait =~                                                              \n    state1            1.000                               0.742    0.742\n    state2            2.627    0.175   14.998    0.000    0.966    0.966\n    state3            1.816    0.135   13.453    0.000    0.883    0.883\n    state4            0.594    0.065    9.175    0.000    0.687    0.687\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .y_11              0.044    0.003   16.239    0.000    0.044    0.573\n   .y_21              0.039    0.002   16.727    0.000    0.039    0.588\n   .y_31              0.041    0.003   16.229    0.000    0.041    0.614\n   .y_41              0.043    0.002   18.435    0.000    0.043    0.725\n   .y_51              0.040    0.002   15.944    0.000    0.040    0.483\n   .y_12              0.037    0.002   16.451    0.000    0.037    0.215\n   .y_22              0.040    0.003   15.194    0.000    0.040    0.183\n   .y_32              0.037    0.002   16.767    0.000    0.037    0.180\n   .y_42              0.042    0.003   15.867    0.000    0.042    0.154\n   .y_52              0.040    0.002   16.365    0.000    0.040    0.162\n   .y_13              0.039    0.003   15.573    0.000    0.039    0.339\n   .y_23              0.038    0.002   18.156    0.000    0.038    0.483\n   .y_33              0.039    0.002   16.543    0.000    0.039    0.446\n   .y_43              0.040    0.002   17.951    0.000    0.040    0.510\n   .y_53              0.036    0.002   17.327    0.000    0.036    0.629\n   .y_14              0.040    0.002   16.607    0.000    0.040    0.747\n   .y_24              0.038    0.003   14.319    0.000    0.038    0.565\n   .y_34              0.039    0.002   16.415    0.000    0.039    0.667\n   .y_44              0.040    0.002   17.513    0.000    0.040    0.679\n   .y_54              0.038    0.002   17.359    0.000    0.038    0.736\n   .state1            0.015    0.002    7.767    0.000    0.449    0.449\n   .state2            0.009    0.004    2.547    0.011    0.067    0.067\n   .state3            0.017    0.002    7.041    0.000    0.219    0.219\n   .state4            0.007    0.001    6.113    0.000    0.528    0.528\n    trait             0.018    0.002    7.442    0.000    1.000    1.000\n\nR-Square:\n                   Estimate\n    y_11              0.427\n    y_21              0.412\n    y_31              0.386\n    y_41              0.275\n    y_51              0.517\n    y_12              0.785\n    y_22              0.817\n    y_32              0.820\n    y_42              0.846\n    y_52              0.838\n    y_13              0.661\n    y_23              0.517\n    y_33              0.554\n    y_43              0.490\n    y_53              0.371\n    y_14              0.253\n    y_24              0.435\n    y_34              0.333\n    y_44              0.321\n    y_54              0.264\n    state1            0.551\n    state2            0.933\n    state3            0.781\n    state4            0.472\n\n# Modellimplizierte Varianz-Kovarianz-Matrix\nfitted(lst_fit)\n\n$cov\n      y_11  y_21  y_31  y_41  y_51  y_12  y_22  y_32  y_42  y_52  y_13  y_23\ny_11 0.077                                                                  \ny_21 0.030 0.067                                                            \ny_31 0.029 0.027 0.068                                                      \ny_41 0.023 0.021 0.021 0.059                                                \ny_51 0.037 0.034 0.033 0.026 0.082                                          \ny_12 0.048 0.043 0.042 0.033 0.054 0.171                                    \ny_22 0.055 0.050 0.049 0.039 0.063 0.155 0.220                              \ny_32 0.053 0.049 0.048 0.037 0.061 0.150 0.174 0.205                        \ny_42 0.062 0.057 0.055 0.043 0.071 0.175 0.202 0.196 0.269                  \ny_52 0.059 0.054 0.053 0.042 0.068 0.167 0.194 0.188 0.218 0.250            \ny_13 0.033 0.030 0.029 0.023 0.037 0.086 0.100 0.097 0.113 0.108 0.116      \ny_23 0.024 0.022 0.021 0.017 0.027 0.063 0.073 0.070 0.082 0.079 0.056 0.078\ny_33 0.026 0.024 0.023 0.018 0.030 0.069 0.080 0.077 0.090 0.086 0.061 0.044\ny_43 0.023 0.021 0.021 0.016 0.026 0.061 0.071 0.068 0.079 0.076 0.054 0.039\ny_53 0.017 0.016 0.015 0.012 0.020 0.045 0.052 0.051 0.059 0.057 0.040 0.029\ny_14 0.011 0.010 0.010 0.008 0.012 0.028 0.033 0.032 0.037 0.035 0.020 0.014\ny_24 0.016 0.014 0.014 0.011 0.018 0.041 0.048 0.046 0.054 0.052 0.029 0.021\ny_34 0.013 0.012 0.011 0.009 0.015 0.034 0.039 0.038 0.044 0.042 0.023 0.017\ny_44 0.013 0.012 0.011 0.009 0.014 0.033 0.039 0.037 0.044 0.042 0.023 0.017\ny_54 0.011 0.010 0.010 0.008 0.012 0.029 0.033 0.032 0.037 0.036 0.020 0.014\n      y_33  y_43  y_53  y_14  y_24  y_34  y_44  y_54\ny_11                                                \ny_21                                                \ny_31                                                \ny_41                                                \ny_51                                                \ny_12                                                \ny_22                                                \ny_32                                                \ny_42                                                \ny_52                                                \ny_13                                                \ny_23                                                \ny_33 0.088                                          \ny_43 0.043 0.078                                    \ny_53 0.032 0.028 0.057                              \ny_14 0.016 0.014 0.010 0.054                        \ny_24 0.023 0.020 0.015 0.020 0.067                  \ny_34 0.019 0.017 0.012 0.016 0.024 0.059            \ny_44 0.018 0.016 0.012 0.016 0.023 0.019 0.059      \ny_54 0.016 0.014 0.010 0.014 0.020 0.016 0.016 0.052\n\n\n\nBeurteilen Sie den Modellfit anhand des CFI, SRMR, RMSEA und \\(\\chi^2\\)-Tests.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nMan kann CFI, SRMR und RMSEA anhand gängiger, aber arbiträrer Cutoffs beurteilen:\n\\(CFI = .999 &gt; .95\\)\n\\(SRMR = .023 &lt; 0.08\\)\n\\(RMSEA = .009 &lt; 0.08\\)\nDiese sprechen alle für einen sehr guten fit. Falls Ihnen in der Vorlesung andere Cutoffs mitgeteilt wurden, sollten Sie natürlich diese verwenden.\nDer p-Wert des \\(\\chi^2\\)-Tests ist \\(.262\\) und damit bei \\(\\alpha = 0.05\\) nicht signifikant. Die H0, dass die modellbasierte und beobachtete Varianz-Kovarianz-Matrix identisch sind, kann also nicht verworfen werden. Das spricht für einen sehr guten Modellfit.\nInsbesondere ein nicht signifikanter \\(\\chi^2\\)-Test ist bei \\(N = 784\\) Personen ungewöhnlich gut. In diesem Fall liegt das daran, dass die Daten nicht empirisch, sondern simuliert sind.\n\n\n\n\nZeichnen Sie eine Pfaddarstellung des Modells. Zeichnen Sie dort auch alle Parameter ein.\n\n\nSuchen Sie im Output die\n\nunstandardisierten State-Ladungen \\(\\lambda_{it}\\)\nunstandardisierten Trait-Ladungen \\(\\gamma_t\\)\nunstandardisierte Trait-Varianz \\(Var(\\xi)\\)\nunstandardisierte State-Varianz \\(Var(\\tau_t)\\)\nunstandardisierten State-Residuen \\(Var(\\zeta_t)\\)\nunstandardisierten Item-Residuen \\(\\epsilon_{it}\\)\nItem Varianzen \\(y_{it}\\)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nunstandardisierten State-Ladungen \\(\\lambda_{it}\\)\n\nz.B. bei state1 =~ y_11 in der Spalte Estimate\n\nunstandardisierten Trait-Ladungen \\(\\gamma_t\\)\n\nz.B. bei trait =~ state1 in der Spalte Estimate\n\nunstandardisierte Trait-Varianz \\(Var(\\xi)\\)\n\nUnter Variances in der Zeile trait und der Spalte Estimate\n\nunstandardisierte State-Varianz \\(Var(\\tau_t)\\)\n\nDiesen Wert findet man nicht im Output, da \\(\\tau_t\\) im Modell in einen stabilen Trait und ein State-spezifisches Residuum dekomponiert wird. Man könnte ihn aber berechnen.\n\nunstandardisierten State-Residuen \\(Var(\\zeta_t)\\)\n\nUnter Variances, z.B. in der Zeile state1 in der Spalte Estimate\n\nunstandardisierten Item-Residuen \\(\\epsilon_{it}\\)\n\nDie unstandardisierten Item-Residuen findet man nicht im Output. Sie sind personenspezifisch und würden \\(N\\) Zeilen Output erfordern. Man findet aber die Residualvarianzen, nämlich unter Variances bei den Itemnamen.\n\nItem Varianzen \\(Var(y_{it})\\)\n\nDie Itemvarianzen finden Sie auf der Hauptdiagonale der modellimplizierten Varianz-Kovarianz-Matrix. Man könnte sie aber auch aus den Parametern ausrechnen, wenn die Matrix nicht gegeben ist (siehe Formel oben).\n\n\n\n\nBerechnen Sie anhand des Outputs die Konsistenz, Messgelegenheitspezifität und Reliabilität von Item \\(4\\) zu Zeitpunkt \\(3\\).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nGesucht\n\\[\nCon(y_{43}) = \\frac{\n    \\lambda_{43}^2 \\cdot \\gamma_3^2 \\cdot Var(\\xi)\n}{\n    Var(y_{43})\n}\n\\]\n\\[\nOSpe(y_{43}) = \\frac{\n    \\lambda_{43}^2 \\cdot Var(\\zeta_3)\n}{\n    Var(y_{43})\n}\n\\]\n\\[\nRel(y_{43}) = 1 - \\frac{\n    Var(\\epsilon_{43})\n}{\n    Var(y_{43})\n}\n\\]\nGegeben\nAus dem Output und der modellimplizierten Varianz-Kovarianz-Matrix:\n\\(\\lambda_{43} = 0.706\\)\n\\(\\gamma_3 = 1.816\\)\n\\(Var(\\xi) = 0.018\\)\n\\(Var(\\zeta_3) = 0.017\\)\n\\(Var(\\epsilon_{43}) = 0.040\\)\n\\(Var(y_{43}) = 0.078\\)\nEinsetzen\n\\[\nCon(y_{43})\n=\\frac{0.706^2\\cdot 1.816^2\\cdot 0.018}{0.078}\n\\approx 0.38\n\\]\n\\[\nOSpe(y_{43})\n=\\frac{0.706^2\\cdot 0.017}{0.078}\n\\approx 0.11\n\\]\n\\[\nRel(y_{43})\n=1-\\frac{0.040}{0.078}\n\\approx 0.49\n\\]\nZur Überprüfung kann man noch einmal schauen, ob der berechnete Wert von \\(Rel(y_{43})\\) dem Wert bei R-Square im Output entspricht. Das ist hier der Fall.\n\n\n\n\nZum Weiterüben finden Sie hier die Konsistenzen und Messgelegenheitsspezifitäten aller Items zu allen Zeitpunkten. Die Reliabilitäten können Sie unter R-Square im Output ablesen.\nBeachten Sie, dass es zu Rundungsabweichungen kommen kann, da die Lösungen mit ungerundeten Parameterschätzungen berechnet wurden.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n\n[1] \"Item: 1 Zeitpunkt: 1 Konsistenz: 0.24 M.Spezifität: 0.19\"\n[1] \"Item: 1 Zeitpunkt: 2 Konsistenz: 0.73 M.Spezifität: 0.05\"\n[1] \"Item: 1 Zeitpunkt: 3 Konsistenz: 0.52 M.Spezifität: 0.15\"\n[1] \"Item: 1 Zeitpunkt: 4 Konsistenz: 0.12 M.Spezifität: 0.13\"\n[1] \"Item: 2 Zeitpunkt: 1 Konsistenz: 0.23 M.Spezifität: 0.18\"\n[1] \"Item: 2 Zeitpunkt: 2 Konsistenz: 0.76 M.Spezifität: 0.06\"\n[1] \"Item: 2 Zeitpunkt: 3 Konsistenz: 0.4 M.Spezifität: 0.11\"\n[1] \"Item: 2 Zeitpunkt: 4 Konsistenz: 0.21 M.Spezifität: 0.23\"\n[1] \"Item: 3 Zeitpunkt: 1 Konsistenz: 0.21 M.Spezifität: 0.17\"\n[1] \"Item: 3 Zeitpunkt: 2 Konsistenz: 0.76 M.Spezifität: 0.06\"\n[1] \"Item: 3 Zeitpunkt: 3 Konsistenz: 0.43 M.Spezifität: 0.12\"\n[1] \"Item: 3 Zeitpunkt: 4 Konsistenz: 0.16 M.Spezifität: 0.18\"\n[1] \"Item: 4 Zeitpunkt: 1 Konsistenz: 0.15 M.Spezifität: 0.12\"\n[1] \"Item: 4 Zeitpunkt: 2 Konsistenz: 0.79 M.Spezifität: 0.06\"\n[1] \"Item: 4 Zeitpunkt: 3 Konsistenz: 0.38 M.Spezifität: 0.11\"\n[1] \"Item: 4 Zeitpunkt: 4 Konsistenz: 0.15 M.Spezifität: 0.17\"\n[1] \"Item: 5 Zeitpunkt: 1 Konsistenz: 0.28 M.Spezifität: 0.23\"\n[1] \"Item: 5 Zeitpunkt: 2 Konsistenz: 0.78 M.Spezifität: 0.06\"\n[1] \"Item: 5 Zeitpunkt: 3 Konsistenz: 0.29 M.Spezifität: 0.08\"\n[1] \"Item: 5 Zeitpunkt: 4 Konsistenz: 0.12 M.Spezifität: 0.14\""
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Übungsheft zur Vorlesung Diagnostik",
    "section": "",
    "text": "Herzlich Willkommen! Im Folgenden finden Sie Antworten auf eine Reihe von FAQs zum Übungsheft der Veranstaltung M.B.2. Wenn Sie sich gleich in die Aufgaben stürzen wollen, finden Sie diese unter dem Reiter Themenabschnitte.\n\n\nDiese Webseite (“Das Übungsheft”) ist eine Sammlung von Aufgaben, die wir im Laufe des Semesters parallel zur Vorlesung bearbeiten. Die Aufgaben unterstützen Sie dabei, komplexere Sachverhalte aus der Vorlesung zu verstehen und Ihren Lernerfolg zu überprüfen. Die Aufgaben in diesem Heft dienen also dem Ziel, Sie möglichst direkt auf besonders herausfordernde Teilaspekte der Prüfung vorzubereiten. Wir empfehlen Ihnen entsprechend dringend, das Heft im Laufe des Semesters zu bearbeiten und aktiv in der Übung mitzuarbeiten.\nDie Übung ist so strukturiert, dass Sie die Aufgaben eines Abschnitts in Ruhe zuhause bearbeiten und anschließend in der Sitzung Fragen stellen können. Wenn es in den Sitzungen keine Fragen zum Übungsheft gibt, beschäftigen wir uns mit weiteren Übungsaufgaben oder darüber hinausgehenden Inhalten.\n\n\n\n\nDas Übungsheft ist nicht wichtiger als die Vorlesung. Es behandelt nur eine Teilmenge der Vorlesungsinhalte. Wir fokussieren uns dabei auf Themen, die Studierenden erfahrungsgemäß eher schwerfallen. Themen der Vorlesung, die nicht im Übungsheft behandelt werden, werden ebenfalls Teil der Prüfung sein.\nDas Übungsheft ist kein Lehrbuch. An einigen Stellen enthält das Heft Erklärungen des Stoffs. Es ist aber nicht der Anspruch, dass das notwendige Wissen, um die Aufgaben zu lösen, im Heft enthalten ist. Diesen Zweck erfüllen die Präsenzveranstaltungen (Vorlesung und Übung).\n\n\n\n\nDie erste Anlaufstelle ist die Präsenzveranstaltung der Übung. Alle anderen Fragen können Sie in das OLAT-Forum der Veranstaltung posten. So können alle Teilnehmer:innen von den Antworten profitieren. Unsere Vorstellung der Übung sieht vor, dass das Wissen zu den Aufgaben für alle Studierenden gleichermaßen verfügbar ist. Bitte stellen Sie Ihre Fragen daher auch nur über das Forum und nicht via Mail. Sie sind natürlich herzlich eingeladen, auch selbst Fragen Ihrer Kommiliton:innen im Forum zu beantworten.\n\n\n\nAuch wenn das die Idealvorstellung wäre, kann es passieren, dass Sie es im Semester nicht schaffen, alle Aufgaben parallel zur Vorlesung zu bearbeiten. Davon geht die Welt nicht unter. Wir raten Ihnen in diesem Fall dazu, in dem Rahmen, der für Sie schaffbar ist, Teile der wöchentlichen Aufgaben zu erledigen. Das funktioniert erfahrungsgemäß viel besser, als sich vorzunehmen, das Heft in den Semesterferien alleine durchzuarbeiten.\n\n\n\nNein, das Bearbeiten des Übungshefts ist keine Voraussetzung, um die Übung M.B.2 zu bestehen. Es gibt auch keine Anwesenheitspflicht. Analysen der Prüfungsnoten und Übungsbeteiligung aus früheren Semestern haben aber gezeigt, dass Studierende, die die Übungsaufgaben bearbeiten deutlich besser in der Prüfung abschneiden als diejenigen, die das nicht tun.\n\n\n\nBitte schauen Sie erst in die Lösungen, wenn Sie die Aufgabe fertig bearbeitet haben oder überhaupt keinen Ansatz finden. Der Lerneffekt durch das Lösen von Aufgaben entsteht nicht vorrangig dadurch, dass Sie eine spezifische Aufgabe lösen können, sondern darin, Lösungsansätze auszuprobieren und auf diesem Weg den Stoff durch den Blickwinkel der Aufgabe neu zu betrachten.\n\n\n\nKlar! Zu allerletzt wünschen wir Ihnen viel Erfolg bei der Bearbeitung der Aufgaben und hoffen, im Laufe des Semesters auch etwas Interesse an den Themen der Testtheorie und Diagnostik wecken zu können. : -)"
  },
  {
    "objectID": "index.html#was-ist-das-übungsheft",
    "href": "index.html#was-ist-das-übungsheft",
    "title": "Übungsheft zur Vorlesung Diagnostik",
    "section": "",
    "text": "Diese Webseite (“Das Übungsheft”) ist eine Sammlung von Aufgaben, die wir im Laufe des Semesters parallel zur Vorlesung bearbeiten. Die Aufgaben unterstützen Sie dabei, komplexere Sachverhalte aus der Vorlesung zu verstehen und Ihren Lernerfolg zu überprüfen. Die Aufgaben in diesem Heft dienen also dem Ziel, Sie möglichst direkt auf besonders herausfordernde Teilaspekte der Prüfung vorzubereiten. Wir empfehlen Ihnen entsprechend dringend, das Heft im Laufe des Semesters zu bearbeiten und aktiv in der Übung mitzuarbeiten.\nDie Übung ist so strukturiert, dass Sie die Aufgaben eines Abschnitts in Ruhe zuhause bearbeiten und anschließend in der Sitzung Fragen stellen können. Wenn es in den Sitzungen keine Fragen zum Übungsheft gibt, beschäftigen wir uns mit weiteren Übungsaufgaben oder darüber hinausgehenden Inhalten."
  },
  {
    "objectID": "index.html#was-ist-das-übungsheft-nicht",
    "href": "index.html#was-ist-das-übungsheft-nicht",
    "title": "Übungsheft zur Vorlesung Diagnostik",
    "section": "",
    "text": "Das Übungsheft ist nicht wichtiger als die Vorlesung. Es behandelt nur eine Teilmenge der Vorlesungsinhalte. Wir fokussieren uns dabei auf Themen, die Studierenden erfahrungsgemäß eher schwerfallen. Themen der Vorlesung, die nicht im Übungsheft behandelt werden, werden ebenfalls Teil der Prüfung sein.\nDas Übungsheft ist kein Lehrbuch. An einigen Stellen enthält das Heft Erklärungen des Stoffs. Es ist aber nicht der Anspruch, dass das notwendige Wissen, um die Aufgaben zu lösen, im Heft enthalten ist. Diesen Zweck erfüllen die Präsenzveranstaltungen (Vorlesung und Übung)."
  },
  {
    "objectID": "index.html#wo-bekomme-ich-hilfe-zu-den-aufgaben",
    "href": "index.html#wo-bekomme-ich-hilfe-zu-den-aufgaben",
    "title": "Übungsheft zur Vorlesung Diagnostik",
    "section": "",
    "text": "Die erste Anlaufstelle ist die Präsenzveranstaltung der Übung. Alle anderen Fragen können Sie in das OLAT-Forum der Veranstaltung posten. So können alle Teilnehmer:innen von den Antworten profitieren. Unsere Vorstellung der Übung sieht vor, dass das Wissen zu den Aufgaben für alle Studierenden gleichermaßen verfügbar ist. Bitte stellen Sie Ihre Fragen daher auch nur über das Forum und nicht via Mail. Sie sind natürlich herzlich eingeladen, auch selbst Fragen Ihrer Kommiliton:innen im Forum zu beantworten."
  },
  {
    "objectID": "index.html#was-soll-ich-tun-wenn-ich-mit-den-aufgaben-nicht-hinterherkomme",
    "href": "index.html#was-soll-ich-tun-wenn-ich-mit-den-aufgaben-nicht-hinterherkomme",
    "title": "Übungsheft zur Vorlesung Diagnostik",
    "section": "",
    "text": "Auch wenn das die Idealvorstellung wäre, kann es passieren, dass Sie es im Semester nicht schaffen, alle Aufgaben parallel zur Vorlesung zu bearbeiten. Davon geht die Welt nicht unter. Wir raten Ihnen in diesem Fall dazu, in dem Rahmen, der für Sie schaffbar ist, Teile der wöchentlichen Aufgaben zu erledigen. Das funktioniert erfahrungsgemäß viel besser, als sich vorzunehmen, das Heft in den Semesterferien alleine durchzuarbeiten."
  },
  {
    "objectID": "index.html#muss-ich-das-übungsheft-bearbeiten-um-die-übung-m.b.2-zu-bestehen",
    "href": "index.html#muss-ich-das-übungsheft-bearbeiten-um-die-übung-m.b.2-zu-bestehen",
    "title": "Übungsheft zur Vorlesung Diagnostik",
    "section": "",
    "text": "Nein, das Bearbeiten des Übungshefts ist keine Voraussetzung, um die Übung M.B.2 zu bestehen. Es gibt auch keine Anwesenheitspflicht. Analysen der Prüfungsnoten und Übungsbeteiligung aus früheren Semestern haben aber gezeigt, dass Studierende, die die Übungsaufgaben bearbeiten deutlich besser in der Prüfung abschneiden als diejenigen, die das nicht tun."
  },
  {
    "objectID": "index.html#wie-sollte-man-mit-den-lösungen-umgehen",
    "href": "index.html#wie-sollte-man-mit-den-lösungen-umgehen",
    "title": "Übungsheft zur Vorlesung Diagnostik",
    "section": "",
    "text": "Bitte schauen Sie erst in die Lösungen, wenn Sie die Aufgabe fertig bearbeitet haben oder überhaupt keinen Ansatz finden. Der Lerneffekt durch das Lösen von Aufgaben entsteht nicht vorrangig dadurch, dass Sie eine spezifische Aufgabe lösen können, sondern darin, Lösungsansätze auszuprobieren und auf diesem Weg den Stoff durch den Blickwinkel der Aufgabe neu zu betrachten."
  },
  {
    "objectID": "index.html#geht-es-jetzt-endlich-los",
    "href": "index.html#geht-es-jetzt-endlich-los",
    "title": "Übungsheft zur Vorlesung Diagnostik",
    "section": "",
    "text": "Klar! Zu allerletzt wünschen wir Ihnen viel Erfolg bei der Bearbeitung der Aufgaben und hoffen, im Laufe des Semesters auch etwas Interesse an den Themen der Testtheorie und Diagnostik wecken zu können. : -)"
  }
]